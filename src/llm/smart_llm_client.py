"""
Smart LLM Router –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –∑–∞—Ç—Ä–∞—Ç –Ω–∞ API
–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤—ã–±–∏—Ä–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—É—é LLM –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
"""

import os
import logging
import asyncio
from typing import Optional, Dict, List
from openai import AsyncOpenAI
from anthropic import AsyncAnthropic
from dotenv import load_dotenv
from src.validation.content_validator import ContentValidator
from src.llm.schemas import PRODUCT_CONTENT_SCHEMA

load_dotenv()
logger = logging.getLogger(__name__)

class SmartLLMClient:
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∫–ª–∏–µ–Ω—Ç —Å —É–º–Ω–æ–π –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–µ–π
    
    –°—Ç—Ä–∞—Ç–µ–≥–∏—è:
    - GPT-4o-mini –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (–±—ã—Å—Ç—Ä–æ, –¥—ë—à–µ–≤–æ)
    - Claude 3.5 Sonnet –¥–ª—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤ (–Ω–∞–¥—ë–∂–Ω–æ, –¥–æ—Ä–æ–≥–æ)
    """
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤
    SENSITIVE_KEYWORDS = {
        'ru': [
            '–¥–µ–ø–∏–ª—è—Ü–∏—è', '–¥–µ–ø–∏–ª—è—Ü–∏', '–≤–æ—Å–∫', '–≤–æ—Å–∫–æ–≤–∞—è',
            '—É–¥–∞–ª–µ–Ω–∏–µ –≤–æ–ª–æ—Å', '—ç–ø–∏–ª—è—Ü–∏—è', '—ç–ø–∏–ª—è—Ü–∏',
            '–∏–Ω—Ç–∏–º', '–±–∏–∫–∏–Ω–∏', '—à—É–≥–∞—Ä–∏–Ω–≥'
        ],
        'ua': [
            '–¥–µ–ø—ñ–ª—è—Ü—ñ—è', '–¥–µ–ø—ñ–ª—è—Ü—ñ', '–≤—ñ—Å–∫', '–≤–æ—Å–∫–æ–≤–∞',
            '–≤–∏–¥–∞–ª–µ–Ω–Ω—è –≤–æ–ª–æ—Å—Å—è', '–µ–ø—ñ–ª—è—Ü—ñ—è', '–µ–ø—ñ–ª—è—Ü—ñ',
            '—ñ–Ω—Ç–∏–º', '–±—ñ–∫—ñ–Ω—ñ', '—à—É–≥–∞—Ä—ñ–Ω–≥'
        ]
    }
    
    # –¶–µ–Ω—ã –∑–∞ 1M —Ç–æ–∫–µ–Ω–æ–≤ (USD)
    PRICING = {
        'gpt-4o-mini': {'input': 0.15, 'output': 0.60},
        'claude-3.5-sonnet': {'input': 3.00, 'output': 15.00}
    }
    
    def __init__(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤ LLM"""
        
        # –ö–ª–∏–µ–Ω—Ç—ã
        self.openai = AsyncOpenAI(
            api_key=os.getenv('OPENAI_API_KEY')
        )
        self.claude = AsyncAnthropic(
            api_key=os.getenv('ANTHROPIC_API_KEY')
        )
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ - –û–¢–ö–õ–Æ–ß–ê–ï–ú smart routing, –≤—Å–µ —Ç–æ–≤–∞—Ä—ã –∏–¥—É—Ç –Ω–∞ OpenAI
        self.smart_routing_enabled = False  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ –æ—Ç–∫–ª—é—á–µ–Ω–æ - –≤—Å–µ –Ω–∞ OpenAI
        self.cost_tracking_enabled = os.getenv('COST_TRACKING_ENABLED', 'true').lower() == 'true'
        
        # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π blacklist —à–∞–±–ª–æ–Ω–Ω—ã—Ö —Ñ—Ä–∞–∑
        self.template_blacklist_ru = [
            '–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç',
            '–≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ',
            '–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —É—Ö–æ–¥',
            '–æ—Ç–ª–∏—á–Ω—ã–π –≤—ã–±–æ—Ä',
            '–∏–¥–µ–∞–ª—å–Ω–æ –ø–æ–¥—Ö–æ–¥–∏—Ç',
            '–æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç',
            '—Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω —Å —É—á–µ—Ç–æ–º –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π',
            '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç',
            '–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç',
            '–ø—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ',
            '–∏–¥–µ–∞–ª—å–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç',
            '—É–¥–æ–±–Ω–æ –≤ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏'
        ]
        
        self.template_blacklist_ua = [
            '—è–∫—ñ—Å–Ω–∏–π –ø—Ä–æ–¥—É–∫—Ç',
            '–≤–∏—Å–æ–∫–∞ —è–∫—ñ—Å—Ç—å',
            '–ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π –¥–æ–≥–ª—è–¥',
            '—á—É–¥–æ–≤–∏–π –≤–∏–±—ñ—Ä',
            '—ñ–¥–µ–∞–ª—å–Ω–æ –ø—ñ–¥—Ö–æ–¥–∏—Ç—å',
            '–∑–∞–±–µ–∑–ø–µ—á—É—î –µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç',
            '—Ä–æ–∑—Ä–æ–±–ª–µ–Ω–∏–π –∑ —É—Ä–∞—Ö—É–≤–∞–Ω–Ω—è–º –æ—Å–æ–±–ª–∏–≤–æ—Å—Ç–µ–π',
            '–µ—Ñ–µ–∫—Ç–∏–≤–Ω–∏–π –ø—Ä–æ–¥—É–∫—Ç',
            '–ø—Ä–æ—Ñ–µ—Å—ñ–π–Ω–∏–π –ø—Ä–æ–¥—É–∫—Ç',
            '—á—É–¥–æ–≤–∞ —è–∫—ñ—Å—Ç—å',
            '—ñ–¥–µ–∞–ª—å–Ω–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç',
            '–∑—Ä—É—á–Ω–æ —É –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—ñ'
        ]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self.stats = {
            'openai_calls': 0,
            'openai_tokens': {'input': 0, 'output': 0},
            'openai_cost': 0.0,
            'openai_failed': 0,
            
            'claude_calls': 0,
            'claude_tokens': {'input': 0, 'output': 0},
            'claude_cost': 0.0,
            'claude_failed': 0,
            
            'total_requests': 0,
            'total_cost': 0.0
        }
        
        logger.info(f"ü§ñ SmartLLMClient initialized")
        logger.info(f"   Smart Routing: {'‚úÖ Enabled' if self.smart_routing_enabled else '‚ùå Disabled'}")
        logger.info(f"   Cost Tracking: {'‚úÖ Enabled' if self.cost_tracking_enabled else '‚ùå Disabled'}")

    async def generate(
        self,
        prompt: str,
        context: Optional[Dict] = None,
        max_tokens: int = 2000,
        temperature: float = 0.7,
        force_provider: Optional[str] = None,
        validate_content: bool = True,  # ‚úÖ –ù–û–í–û–ï
        locale: str = 'ru'  # ‚úÖ –ù–û–í–û–ï –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
    ) -> str:
        """
        –£–º–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –í–ê–õ–ò–î–ê–¶–ò–ï–ô –∏ FALLBACK
        
        –õ–æ–≥–∏–∫–∞:
        1. –ü—Ä–æ–±—É–µ–º primary LLM (OpenAI –∏–ª–∏ –ø–æ smart routing)
        2. –í–ê–õ–ò–î–ò–†–£–ï–ú —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        3. –ï—Å–ª–∏ –ø—Ä–æ–≤–∞–ª –≤–∞–ª–∏–¥–∞—Ü–∏–∏ ‚Üí fallback –Ω–∞ Claude
        4. –ï—Å–ª–∏ Claude —Ç–æ–∂–µ –ø—Ä–æ–≤–∞–ª–∏–ª—Å—è ‚Üí –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—à–∏–±–∫—É
        """
        
        self.stats['total_requests'] += 1
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º primary provider
        if force_provider:
            primary_provider = force_provider
        else:
            primary_provider = self._route_request(context)
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # –ü–û–ü–´–¢–ö–ê 1: PRIMARY LLM
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        try:
            logger.info(f"üîµ Primary attempt: {primary_provider}")
            
            if primary_provider == 'claude':
                content = await self._generate_claude(prompt, max_tokens, temperature)
            else:
                content = await self._generate_openai(prompt, max_tokens, temperature)
            
            # ‚úÖ –ù–û–í–û–ï: –í–ê–õ–ò–î–ê–¶–ò–Ø –∫–æ–Ω—Ç–µ–Ω—Ç–∞
            if validate_content:
                is_valid = self._validate_generated_content(content, locale)
                
                if not is_valid:
                    logger.warning(f"‚ö†Ô∏è {primary_provider} –ü–†–û–í–ê–õ –í–ê–õ–ò–î–ê–¶–ò–ò!")
                    raise ValueError(f"{primary_provider} content validation failed")
            
            # –ö–æ–Ω—Ç–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω—ã–π!
            self._track_usage(primary_provider, prompt, content)
            logger.info(f"‚úÖ {primary_provider} SUCCESS")
            
            return content
        
        except Exception as e:
            logger.error(f"‚ùå {primary_provider} failed: {e}")
            self.stats[f'{primary_provider}_failed'] += 1
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # –ü–û–ü–´–¢–ö–ê 2: FALLBACK –ù–ê CLAUDE
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        if primary_provider != 'claude':  # –ï—Å–ª–∏ primary –Ω–µ Claude
            try:
                logger.info(f"üü£ FALLBACK ‚Üí Claude")
                
                content = await self._generate_claude(prompt, max_tokens, temperature)
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è Claude
                if validate_content:
                    is_valid = self._validate_generated_content(content, locale)
                    
                    if not is_valid:
                        logger.error(f"üö´ Claude –¢–û–ñ–ï –ø—Ä–æ–≤–∞–ª –≤–∞–ª–∏–¥–∞—Ü–∏–∏!")
                        raise ValueError("Claude content validation failed")
                
                # Claude —Å–ø—Ä–∞–≤–∏–ª—Å—è!
                self._track_usage('claude', prompt, content)
                logger.info(f"‚úÖ Claude FALLBACK SUCCESS")
                
                return content
            
            except Exception as e:
                logger.error(f"‚ùå Claude fallback failed: {e}")
                self.stats['claude_failed'] += 1
        
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        # –û–ë–ï LLM –ü–†–û–í–ê–õ–ò–õ–ò–°–¨
        # ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
        
        logger.error(f"üö´ –í–°–ï LLM –ü–†–û–í–ê–õ–ò–õ–ò–°–¨ –¥–ª—è prompt: {prompt[:100]}...")
        raise Exception("All LLMs failed validation")

    def _validate_generated_content(self, content: str, locale: str) -> bool:
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞
        
        Returns:
            True –µ—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç –≤–∞–ª–∏–¥–Ω—ã–π, False –µ—Å–ª–∏ –ø—Ä–æ–≤–∞–ª
        """
        
        # –ü—Ä–æ—Å—Ç–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞ —É—Ä–æ–≤–Ω–µ SmartLLMClient
        # (–¥–µ—Ç–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –±—É–¥–µ—Ç –≤ ContentValidator)
        
        content_lower = content.lower()
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —à–∞–±–ª–æ–Ω—ã
        template_phrases = ContentValidator.TEMPLATE_PHRASES.get(locale, [])
        for phrase in template_phrases:
            if phrase in content_lower:
                logger.warning(f"‚ö†Ô∏è –í–∞–ª–∏–¥–∞—Ü–∏—è: –Ω–∞–π–¥–µ–Ω —à–∞–±–ª–æ–Ω '{phrase}'")
                return False
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        for forbidden in ContentValidator.FORBIDDEN_CONTENT:
            if forbidden in content_lower:
                logger.warning(f"‚ö†Ô∏è –í–∞–ª–∏–¥–∞—Ü–∏—è: –Ω–∞–π–¥–µ–Ω–æ –∑–∞–ø—Ä–µ—â—ë–Ω–Ω–æ–µ '{forbidden}'")
                return False
        
        # 3. –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
        if len(content) < 50:
            logger.warning(f"‚ö†Ô∏è –í–∞–ª–∏–¥–∞—Ü–∏—è: —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –∫–æ–Ω—Ç–µ–Ω—Ç ({len(content)} —Å–∏–º–≤–æ–ª–æ–≤)")
            return False
        
        return True

    def _route_request(self, context: Optional[Dict]) -> str:
        """
        –£–º–Ω–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞
        
        –õ–æ–≥–∏–∫–∞:
        - –ü—Ä–æ–±–ª–µ–º–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã (–¥–µ–ø–∏–ª—è—Ü–∏—è –∏ —Ç.–¥.) ‚Üí Claude
        - –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ —Ç–æ–≤–∞—Ä—ã ‚Üí GPT-4o-mini
        
        Args:
            context: –ö–æ–Ω—Ç–µ–∫—Å—Ç —Ç–æ–≤–∞—Ä–∞ —Å –ø–æ–ª—è–º–∏ 'title', 'category' –∏ —Ç.–¥.
        
        Returns:
            'openai' –∏–ª–∏ 'claude'
        """
        
        if not self.smart_routing_enabled:
            return 'openai'
        
        if not context:
            return 'openai'
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
        title = context.get('title', '').lower()
        category = context.get('category', '').lower()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –ø–æ–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        text_to_check = f"{title} {category}".lower()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ç—Ä–∏–≥–≥–µ—Ä–Ω—ã–µ —Å–ª–æ–≤–∞
        all_keywords = self.SENSITIVE_KEYWORDS['ru'] + self.SENSITIVE_KEYWORDS['ua']
        
        for keyword in all_keywords:
            if keyword in text_to_check:
                logger.info(f"üü£ Sensitive product detected ('{keyword}') ‚Üí Claude 3.5 Sonnet")
                return 'claude'
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Ç–æ–≤–∞—Ä
        logger.info("üîµ Standard product ‚Üí GPT-4o-mini")
        return 'openai'

    async def _generate_openai(
        self,
        prompt: str,
        max_tokens: int,
        temperature: float
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ GPT-4o-mini"""
        
        response = await self.openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "You are a professional e-commerce copywriter specializing in product descriptions."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        content = response.choices[0].message.content
        return content.strip()

    async def _generate_claude(
        self,
        prompt: str,
        max_tokens: int,
        temperature: float
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Claude —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –¥–æ—Å—Ç—É–ø–Ω–æ–π –º–æ–¥–µ–ª–∏"""
        
        # –°–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π –¥–ª—è –ø–æ–ø—ã—Ç–∫–∏ (–æ—Ç –ª—É—á—à–µ–π –∫ —Ö—É–¥—à–µ–π) - —Ç–æ–ª—å–∫–æ —Ä–∞–±–æ—Ç–∞—é—â–∏–µ
        claude_models = [
            "claude-3-haiku-20240307",     # –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è —Ä–∞–±–æ—Ç–∞—é—â–∞—è –º–æ–¥–µ–ª—å
        ]
        
        for model in claude_models:
            try:
                logger.info(f"üîç Trying Claude model: {model}")
                
                response = await self.claude.messages.create(
                    model=model,
                    max_tokens=max_tokens,
                    temperature=temperature,
                    messages=[
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ]
                )
                
                logger.info(f"‚úÖ Claude model {model} works!")
                content = response.content[0].text
                return content.strip()
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Claude model {model} failed: {e}")
                continue
        
        # –ï—Å–ª–∏ –Ω–∏ –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∞
        raise Exception("‚ùå No working Claude model found")

    async def generate_content_with_structured_output(
        self,
        parsed_data: dict,
        locale: str,
        system_prompt: str,
        max_retries: int = 3
    ) -> dict:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å Structured Output –∏ retry –ª–æ–≥–∏–∫–æ–π"""
        
        # –°–æ–∑–¥–∞—ë–º user prompt —Å –¥–∞–Ω–Ω—ã–º–∏
        user_prompt = self._create_user_prompt(parsed_data, locale)
        
        for attempt in range(max_retries):
            try:
                # –ü–û–ü–´–¢–ö–ê 1-2: OpenAI GPT-4o-mini —Å Structured Output
                if attempt < 2:
                    content = await self._generate_with_openai_structured(
                        system_prompt, 
                        user_prompt, 
                        locale,
                        strict_mode=(attempt == 1)  # –í—Ç–æ—Ä–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Å —É—Å–∏–ª–µ–Ω–Ω—ã–º –ø—Ä–æ–º–ø—Ç–æ–º
                    )
                # –ü–û–ü–´–¢–ö–ê 3: Claude Sonnet –∫–∞–∫ fallback
                else:
                    content = await self._generate_with_claude_structured(
                        system_prompt,
                        user_prompt,
                        locale
                    )
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
                is_valid, errors = self._validate_structured_content(content, locale)
                
                if is_valid:
                    return content
                else:
                    logger.warning(f"Attempt {attempt+1} failed validation: {errors}")
                    
            except Exception as e:
                logger.error(f"Attempt {attempt+1} error: {str(e)}")
                if attempt == max_retries - 1:
                    raise
        
        raise Exception("All attempts failed")

    async def _generate_with_openai_structured(
        self,
        system_prompt: str,
        user_prompt: str,
        locale: str,
        strict_mode: bool = False
    ) -> dict:
        """OpenAI –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å JSON Schema"""
        
        # –£—Å–∏–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≤—Ç–æ—Ä–æ–π –ø–æ–ø—ã—Ç–∫–∏
        if strict_mode:
            system_prompt = self._add_strict_warnings(system_prompt, locale)
        
        response = await self.openai.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            response_format={
                "type": "json_schema",
                "json_schema": {
                    "name": "product_content",
                    "strict": True,
                    "schema": PRODUCT_CONTENT_SCHEMA
                }
            },
            temperature=0.3,  # –°–Ω–∏–∂–∞–µ–º –∫—Ä–µ–∞—Ç–∏–≤–Ω–æ—Å—Ç—å –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            max_tokens=2000
        )
        
        import json
        return json.loads(response.choices[0].message.content)

    async def _generate_with_claude_structured(
        self,
        system_prompt: str,
        user_prompt: str,
        locale: str
    ) -> dict:
        """Claude –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å JSON Schema (fallback)"""
        
        # –£—Å–∏–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è Claude
        system_prompt = self._add_strict_warnings(system_prompt, locale)
        
        response = await self.claude.messages.create(
            model="claude-3-haiku-20240307",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—É—é –º–æ–¥–µ–ª—å
            max_tokens=2000,
            temperature=0.3,
            messages=[
                {"role": "user", "content": f"{system_prompt}\n\n{user_prompt}"}
            ]
        )
        
        import json
        content = response.content[0].text
        
        # Claude –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç structured output, –ø–∞—Ä—Å–∏–º JSON
        try:
            # –£–±–∏—Ä–∞–µ–º –≤–æ–∑–º–æ–∂–Ω—ã–µ markdown –±–ª–æ–∫–∏
            if content.startswith('```json'):
                content = content[7:]
            if content.endswith('```'):
                content = content[:-3]
            content = content.strip()
            
            return json.loads(content)
        except json.JSONDecodeError as e:
            logger.error(f"Claude JSON parsing error: {e}")
            raise

    def _add_strict_warnings(self, system_prompt: str, locale: str) -> str:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –¥–ª—è –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –ø–æ–ø—ã—Ç–æ–∫"""
        
        blacklist = (
            self.template_blacklist_ru if locale == 'ru' 
            else self.template_blacklist_ua
        )
        
        warnings = f"""

‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ü–†–ï–î–£–ü–†–ï–ñ–î–ï–ù–ò–ï ‚ö†Ô∏è‚ö†Ô∏è‚ö†Ô∏è

–ü—Ä–µ–¥—ã–¥—É—â–∞—è –ø–æ–ø—ã—Ç–∫–∞ –ø—Ä–æ–≤–∞–ª–µ–Ω–∞. –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û –∏—Å–ø—Ä–∞–≤—å:

1. –ó–ê–ü–†–ï–©–Å–ù–ù–´–ï –§–†–ê–ó–´ (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π reject):
{chr(10).join(f'   ‚ùå "{phrase}"' for phrase in blacklist)}

2. –°–¢–†–£–ö–¢–£–†–ê –û–ü–ò–°–ê–ù–ò–Ø:
   ‚úÖ –¢–û–ß–ù–û 2 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ (paragraph_1 –ò paragraph_2)
   ‚úÖ 6-10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –í–°–ï–ì–û (3-5 –≤ –∫–∞–∂–¥–æ–º)
   ‚úÖ –¢–æ–ª—å–∫–æ –§–ê–ö–¢–´ –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö

3. FAQ:
   ‚úÖ –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û 4-6 –≤–æ–ø—Ä–æ—Å–æ–≤
   ‚úÖ –ö–∞–∂–¥—ã–π –≤–æ–ø—Ä–æ—Å –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞—Ö

4. –Ø–ó–´–ö:
   {'‚úÖ –ù–ï–¢ –±—É–∫–≤: —ñ, —ó, —î, “ë' if locale == 'ru' else '‚úÖ –ù–ï–¢ –±—É–∫–≤: —ã, —ç, —ä, —ë'}

–ï–°–õ–ò –ù–ï –ò–°–ü–†–ê–í–ò–®–¨ ‚Üí –û–¢–ö–õ–û–ù–ï–ù–û
"""
        return system_prompt + warnings

    def _validate_structured_content(self, content: dict, locale: str) -> tuple[bool, list]:
        """–ñ—ë—Å—Ç–∫–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–Ω—Ç–∞"""
        errors = []
        
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è
        desc = content.get('description', {})
        p1 = desc.get('paragraph_1', '')
        p2 = desc.get('paragraph_2', '')
        
        # –°—á–∏—Ç–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        sentences_p1 = len([s for s in p1.split('.') if s.strip()])
        sentences_p2 = len([s for s in p2.split('.') if s.strip()])
        total_sentences = sentences_p1 + sentences_p2
        
        if not (6 <= total_sentences <= 10):
            errors.append(f"–û–ø–∏—Å–∞–Ω–∏–µ: {total_sentences} –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (–Ω—É–∂–Ω–æ 6-10)")
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —à–∞–±–ª–æ–Ω—ã
        blacklist = (
            self.template_blacklist_ru if locale == 'ru' 
            else self.template_blacklist_ua
        )
        
        import json
        full_text = json.dumps(content, ensure_ascii=False).lower()
        for phrase in blacklist:
            if phrase.lower() in full_text:
                errors.append(f"–®–∞–±–ª–æ–Ω–Ω–∞—è —Ñ—Ä–∞–∑–∞: '{phrase}'")
        
        # 3. –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–∑—ã–∫–æ–≤–æ–π —á–∏—Å—Ç–æ—Ç—ã
        if locale == 'ru':
            forbidden_chars = {'—ñ', '—ó', '—î', '“ë'}
            if any(char in full_text for char in forbidden_chars):
                errors.append("RU: —Å–æ–¥–µ—Ä–∂–∏—Ç —É–∫—Ä–∞–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã")
        else:
            forbidden_chars = {'—ã', '—ç', '—ä', '—ë'}
            if any(char in full_text for char in forbidden_chars):
                errors.append("UA: —Å–æ–¥–µ—Ä–∂–∏—Ç —Ä—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã")
        
        # 4. –ü—Ä–æ–≤–µ—Ä–∫–∞ FAQ
        faq = content.get('faq', [])
        if not (4 <= len(faq) <= 6):
            errors.append(f"FAQ: {len(faq)} –≤–æ–ø—Ä–æ—Å–æ–≤ (–Ω—É–∂–Ω–æ 4-6)")
        
        # 5. –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤
        benefits = content.get('benefits', [])
        if not (3 <= len(benefits) <= 6):
            errors.append(f"–ü—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞: {len(benefits)} (–Ω—É–∂–Ω–æ 3-6)")
        
        # 6. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        chars = content.get('characteristics', [])
        if len(chars) < 2:
            errors.append("–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –º–µ–Ω—å—à–µ 2")
        
        return (len(errors) == 0, errors)

    def _create_user_prompt(self, parsed_data: dict, locale: str) -> str:
        """–°–æ–∑–¥–∞—ë—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π user prompt —Å –¥–∞–Ω–Ω—ã–º–∏"""
        import json
        return f"""
–°–≥–µ–Ω–µ—Ä–∏—Ä—É–π –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è —Ç–æ–≤–∞—Ä–∞ –Ω–∞ —è–∑—ã–∫–µ: {locale.upper()}

–ò–°–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï:
–ù–∞–∑–≤–∞–Ω–∏–µ: {parsed_data.get('title', 'N/A')}
–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {json.dumps(parsed_data.get('specs', []), ensure_ascii=False, indent=2)}
–û–ø–∏—Å–∞–Ω–∏–µ –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞: {parsed_data.get('description', 'N/A')}

–û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û:
1. –ü–µ—Ä–µ–≤–µ–¥–∏ –Ω–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ {locale.upper()} —è–∑—ã–∫
2. –ò—Å–ø–æ–ª—å–∑—É–π –í–°–ï —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ –¥–∞–Ω–Ω—ã—Ö
3. –°–æ–∑–¥–∞–π 2 –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞ –æ–ø–∏—Å–∞–Ω–∏—è (6-10 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)
4. –°–≥–µ–Ω–µ—Ä–∏—Ä—É–π 4-6 FAQ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
5. –ù–ï –∏—Å–ø–æ–ª—å–∑—É–π —à–∞–±–ª–æ–Ω–Ω—ã–µ —Ñ—Ä–∞–∑—ã
6. –¢–æ–ª—å–∫–æ –§–ê–ö–¢–´ –∏–∑ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
"""

    def _is_refusal(self, content: str) -> bool:
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–∫–∞–∑–∞–ª—Å—è –ª–∏ LLM –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç
        
        –ü—Ä–∏–∑–Ω–∞–∫–∏ –æ—Ç–∫–∞–∑–∞:
        - –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç (< 50 —Å–∏–º–≤–æ–ª–æ–≤)
        - –§—Ä–∞–∑—ã –æ—Ç–∫–∞–∑–∞
        - –®–∞–±–ª–æ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        """
        
        if len(content) < 50:
            return True
        
        refusal_phrases = [
            '–∑–∞–ø—Ä–µ—â–µ–Ω–æ', '–Ω–µ –º–æ–≥—É', 'cannot', 'i cannot',
            'content policy', 'against policy', 'inappropriate',
            '–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç',  # –®–∞–±–ª–æ–Ω–Ω–∞—è —Ñ—Ä–∞–∑–∞ = –ø—Ä–æ–≤–∞–ª
            'i apologize', 'i\'m sorry'
        ]
        
        content_lower = content.lower()
        
        for phrase in refusal_phrases:
            if phrase in content_lower:
                return True
        
        return False

    def _track_usage(self, provider: str, prompt: str, content: str):
        """
        –û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –∏ –∑–∞—Ç—Ä–∞—Ç
        
        Args:
            provider: 'openai' –∏–ª–∏ 'claude'
            prompt: –ü—Ä–æ–º–ø—Ç (–¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ input —Ç–æ–∫–µ–Ω–æ–≤)
            content: –û—Ç–≤–µ—Ç (–¥–ª—è –ø–æ–¥—Å—á—ë—Ç–∞ output —Ç–æ–∫–µ–Ω–æ–≤)
        """
        
        # –ü—Ä–∏–º–µ—Ä–Ω—ã–π –ø–æ–¥—Å—á—ë—Ç —Ç–æ–∫–µ–Ω–æ–≤ (1 —Ç–æ–∫–µ–Ω ‚âà 4 —Å–∏–º–≤–æ–ª–∞)
        input_tokens = len(prompt) // 4
        output_tokens = len(content) // 4
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        if provider == 'openai':
            self.stats['openai_calls'] += 1
            self.stats['openai_tokens']['input'] += input_tokens
            self.stats['openai_tokens']['output'] += output_tokens
            
            # –°—Ç–æ–∏–º–æ—Å—Ç—å
            cost = (
                input_tokens / 1_000_000 * self.PRICING['gpt-4o-mini']['input'] +
                output_tokens / 1_000_000 * self.PRICING['gpt-4o-mini']['output']
            )
            self.stats['openai_cost'] += cost
        
        else:  # claude
            self.stats['claude_calls'] += 1
            self.stats['claude_tokens']['input'] += input_tokens
            self.stats['claude_tokens']['output'] += output_tokens
            
            # –°—Ç–æ–∏–º–æ—Å—Ç—å
            cost = (
                input_tokens / 1_000_000 * self.PRICING['claude-3.5-sonnet']['input'] +
                output_tokens / 1_000_000 * self.PRICING['claude-3.5-sonnet']['output']
            )
            self.stats['claude_cost'] += cost
        
        # –û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å
        self.stats['total_cost'] = self.stats['openai_cost'] + self.stats['claude_cost']

    def get_stats(self) -> Dict:
        """–ü–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return self.stats.copy()

    def print_stats(self):
        """–í—ã–≤–µ—Å—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É"""
        
        total_calls = self.stats['openai_calls'] + self.stats['claude_calls']
        
        if total_calls == 0:
            logger.info("üìä No LLM calls yet")
            return
        
        openai_percent = (self.stats['openai_calls'] / total_calls * 100) if total_calls > 0 else 0
        claude_percent = (self.stats['claude_calls'] / total_calls * 100) if total_calls > 0 else 0
        
        avg_cost = self.stats['total_cost'] / total_calls if total_calls > 0 else 0
        
        print("\n" + "="*80)
        print("üìä SMART ROUTING –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("="*80)
        
        print(f"\nüîµ GPT-4o-mini:")
        print(f"   –í—ã–∑–æ–≤–æ–≤: {self.stats['openai_calls']} ({openai_percent:.1f}%)")
        print(f"   –¢–æ–∫–µ–Ω–æ–≤: {self.stats['openai_tokens']['input']:,} input / {self.stats['openai_tokens']['output']:,} output")
        print(f"   –°—Ç–æ–∏–º–æ—Å—Ç—å: ${self.stats['openai_cost']:.4f}")
        print(f"   –ü—Ä–æ–≤–∞–ª–æ–≤: {self.stats['openai_failed']}")
        
        print(f"\nüü£ Claude 3.5 Sonnet:")
        print(f"   –í—ã–∑–æ–≤–æ–≤: {self.stats['claude_calls']} ({claude_percent:.1f}%)")
        print(f"   –¢–æ–∫–µ–Ω–æ–≤: {self.stats['claude_tokens']['input']:,} input / {self.stats['claude_tokens']['output']:,} output")
        print(f"   –°—Ç–æ–∏–º–æ—Å—Ç—å: ${self.stats['claude_cost']:.4f}")
        print(f"   –ü—Ä–æ–≤–∞–ª–æ–≤: {self.stats['claude_failed']}")
        
        print(f"\nüí∞ –ò–¢–û–ì–û:")
        print(f"   –í—Å–µ–≥–æ –∑–∞–ø—Ä–æ—Å–æ–≤: {total_calls}")
        print(f"   –û–±—â–∞—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${self.stats['total_cost']:.4f}")
        print(f"   –°—Ä–µ–¥–Ω—è—è —Å—Ç–æ–∏–º–æ—Å—Ç—å: ${avg_cost:.6f} –∑–∞ —Ç–æ–≤–∞—Ä")
        
        # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞–º–∏
        cost_if_all_openai = total_calls * 0.00078
        cost_if_all_claude = total_calls * 0.018
        
        print(f"\nüìà –≠–ö–û–ù–û–ú–ò–Ø:")
        print(f"   –ï—Å–ª–∏ –±—ã –≤—Å—ë —á–µ—Ä–µ–∑ OpenAI: ${cost_if_all_openai:.4f}")
        print(f"   –ï—Å–ª–∏ –±—ã –≤—Å—ë —á–µ—Ä–µ–∑ Claude: ${cost_if_all_claude:.4f}")
        print(f"   Smart Routing: ${self.stats['total_cost']:.4f}")
        
        if self.stats['total_cost'] < cost_if_all_claude:
            savings = cost_if_all_claude - self.stats['total_cost']
            print(f"   ‚úÖ –≠–∫–æ–Ω–æ–º–∏—è: ${savings:.4f} ({savings/cost_if_all_claude*100:.1f}%)")
        
        print("="*80 + "\n")
