import os
import asyncio
import logging
from typing import Optional
from openai import AsyncOpenAI
from anthropic import AsyncAnthropic

logger = logging.getLogger(__name__)

class MultiLLMClient:
    """
    –£–º–Ω—ã–π –∫–ª–∏–µ–Ω—Ç —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback:
    OpenAI ‚Üí Claude –ø—Ä–∏ –æ—Ç–∫–∞–∑–µ
    """

    def __init__(self):
        # Primary: OpenAI
        openai_key = os.getenv('OPENAI_API_KEY')
        anthropic_key = os.getenv('ANTHROPIC_API_KEY')
        
        if openai_key and openai_key != '—Ç–≤–æ–π-—Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π-openai-–∫–ª—é—á':
            self.openai = AsyncOpenAI(api_key=openai_key)
        else:
            self.openai = None
            logger.warning("‚ö†Ô∏è OpenAI API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        if anthropic_key:
            self.claude = AsyncAnthropic(api_key=anthropic_key)
        else:
            self.claude = None
            logger.warning("‚ö†Ô∏è Anthropic API –∫–ª—é—á –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        
        self.stats = {
            'openai_success': 0,
            'openai_failed': 0,
            'claude_used': 0
        }

    async def generate(
        self, 
        prompt: str,
        max_tokens: int = 2000,
        temperature: float = 0.7
    ) -> str:
        """
        –£–º–Ω–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º fallback
        
        –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–±—É–µ—Ç OpenAI, –ø—Ä–∏ –æ—Ç–∫–∞–∑–µ ‚Üí Claude
        """
        
        # –ü–û–ü–´–¢–ö–ê 1: OpenAI
        if self.openai:
            try:
                logger.info("ü§ñ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ OpenAI GPT-4o-mini")
                content = await self._generate_openai(
                    prompt, 
                    max_tokens, 
                    temperature
                )
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—Ç–∫–∞–∑
                if self._is_refusal(content):
                    logger.warning("‚ö†Ô∏è OpenAI –æ—Ç–∫–∞–∑–∞–ª—Å—è, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ Claude")
                    raise ValueError("OpenAI content policy refusal")
                
                self.stats['openai_success'] += 1
                logger.info("‚úÖ OpenAI —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∫–æ–Ω—Ç–µ–Ω—Ç")
                return content
                
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è OpenAI failed: {e}")
                self.stats['openai_failed'] += 1
        else:
            logger.warning("‚ö†Ô∏è OpenAI –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ Claude")
            self.stats['openai_failed'] += 1
        
        # –ü–û–ü–´–¢–ö–ê 2: Claude (fallback)
        if self.claude:
            logger.info("üîÑ –ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ Claude (Anthropic)")
            content = await self._generate_claude(
                prompt, 
                max_tokens, 
                temperature
            )
            
            self.stats['claude_used'] += 1
            logger.info("‚úÖ Claude —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –∫–æ–Ω—Ç–µ–Ω—Ç")
            return content
        else:
            raise ValueError("‚ùå –ù–∏ –æ–¥–∏–Ω LLM –∫–ª–∏–µ–Ω—Ç –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (OpenAI –∏ Claude)")

    async def _generate_openai(
        self, 
        prompt: str, 
        max_tokens: int, 
        temperature: float
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ OpenAI"""
        
        response = await self.openai.chat.completions.create(
            model="gpt-4o-mini",  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±–æ–ª–µ–µ –¥–µ—à–µ–≤—É—é –º–æ–¥–µ–ª—å
            messages=[
                {
                    "role": "system",
                    "content": "You are a professional copywriter for e-commerce. Generate high-quality product descriptions, advantages, and FAQ content."
                },
                {
                    "role": "user",
                    "content": prompt
                }
            ],
            max_tokens=max_tokens,
            temperature=temperature
        )
        
        content = response.choices[0].message.content
        return content.strip()

    async def _generate_claude(
        self, 
        prompt: str, 
        max_tokens: int, 
        temperature: float
    ) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —á–µ—Ä–µ–∑ Claude (Anthropic)"""
        
        response = await self.claude.messages.create(
            model="claude-instant-1",  # Latest Claude
            max_tokens=max_tokens,
            temperature=temperature,
            messages=[
                {
                    "role": "user",
                    "content": prompt
                }
            ]
        )
        
        content = response.content[0].text
        return content.strip()

    def _is_refusal(self, content: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –æ—Ç–∫–∞–∑–∞–ª—Å—è –ª–∏ LLM –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å"""
        
        refusal_phrases = [
            '–∑–∞–ø—Ä–µ—â–µ–Ω–æ',
            '–Ω–µ –º–æ–≥—É',
            'cannot',
            'i cannot',
            'content policy',
            'against policy',
            'inappropriate',
            '–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç',  # –®–∞–±–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç = –ø—Ä–æ–≤–∞–ª
            '–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —É—Ö–æ–¥',  # –ï—â–µ –æ–¥–∏–Ω —à–∞–±–ª–æ–Ω
            '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç'  # –ò –µ—â–µ –æ–¥–∏–Ω
        ]
        
        content_lower = content.lower()
        
        # –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–Ω—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π - –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
        if len(content) < 20:
            logger.warning(f"‚ö†Ô∏è –°–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: {len(content)} —Å–∏–º–≤–æ–ª–æ–≤")
            return True
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ —Ñ—Ä–∞–∑—ã –æ—Ç–∫–∞–∑–∞
        for phrase in refusal_phrases:
            if phrase in content_lower:
                logger.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω–∞ —Ñ—Ä–∞–∑–∞ –æ—Ç–∫–∞–∑–∞: '{phrase}'")
                return True
        
        return False

    def get_stats(self) -> dict:
        """–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è"""
        return self.stats.copy()
    
    def print_stats(self):
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –≤ –∫–æ–Ω—Å–æ–ª—å"""
        stats = self.get_stats()
        total = stats['openai_success'] + stats['claude_used']
        
        if total > 0:
            claude_percent = (stats['claude_used'] / total) * 100
        else:
            claude_percent = 0
        
        print("\n" + "="*80)
        print("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø LLM:")
        print("="*80)
        print(f"   ‚úÖ OpenAI —É—Å–ø–µ—à–Ω–æ: {stats['openai_success']}")
        print(f"   ‚ùå OpenAI –æ—Ç–∫–∞–∑–æ–≤: {stats['openai_failed']}")
        print(f"   üîÑ Claude fallback: {stats['claude_used']}")
        print(f"   üìà –ü—Ä–æ—Ü–µ–Ω—Ç Claude: {claude_percent:.1f}%")
        print("="*80)
