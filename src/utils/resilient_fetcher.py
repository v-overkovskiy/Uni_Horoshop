"""
–£–º–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ —Å retry –∏ fallback –ª–æ–≥–∏–∫–æ–π –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏
"""
import asyncio
import httpx
import logging
from typing import Optional, Tuple

logger = logging.getLogger(__name__)

class ResilientFetcher:
    """–£–º–Ω—ã–π –∑–∞–≥—Ä—É–∑—á–∏–∫ —Å retry –∏ fallback"""
    
    def __init__(self, timeout: int = 30, max_retries: int = 3):
        self.timeout = timeout
        self.max_retries = max_retries
    
    async def fetch_with_retry(
        self, 
        url: str, 
        max_retries: Optional[int] = None
    ) -> Optional[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å –ø–æ–≤—Ç–æ—Ä–Ω—ã–º–∏ –ø–æ–ø—ã—Ç–∫–∞–º–∏ –∏ —ç–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–º backoff"""
        
        if max_retries is None:
            max_retries = self.max_retries
            
        for attempt in range(max_retries):
            try:
                logger.info(f"üåê –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{max_retries}: {url}")
                
                async with httpx.AsyncClient(timeout=self.timeout) as client:
                    response = await client.get(url)
                    response.raise_for_status()
                    
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {url}")
                    return response.text
                    
            except (httpx.TimeoutException, httpx.ConnectError, httpx.HTTPStatusError) as e:
                logger.warning(f"‚ö†Ô∏è –ü–æ–ø—ã—Ç–∫–∞ {attempt+1}/{max_retries} –Ω–µ —É–¥–∞–ª–∞—Å—å: {e}")
                
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt  # –≠–∫—Å–ø–æ–Ω–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π backoff: 1s, 2s, 4s
                    logger.info(f"‚è≥ –û–∂–∏–¥–∞–Ω–∏–µ {wait_time}—Å –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º")
                    await asyncio.sleep(wait_time)
                else:
                    logger.error(f"‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–ª—è {url}")
                    raise Exception(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å {url} –ø–æ—Å–ª–µ {max_retries} –ø–æ–ø—ã—Ç–æ–∫: {e}")
        
        return None
    
    async def fetch_with_fallback_locale(
        self, 
        primary_url: str, 
        fallback_url: str
    ) -> Tuple[str, str]:
        """–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–π –ª–æ–∫–∞–ª–∏"""
        
        try:
            logger.info(f"üéØ –ü—Ä–æ–±—É–µ–º primary URL: {primary_url}")
            content = await self.fetch_with_retry(primary_url)
            return content, 'primary'
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Primary URL failed: {e}")
            logger.info(f"üîÑ –ü—Ä–æ–±—É–µ–º fallback URL: {fallback_url}")
            
            try:
                content = await self.fetch_with_retry(fallback_url)
                logger.info(f"‚úÖ Fallback —É—Å–ø–µ—à–µ–Ω: {fallback_url}")
                return content, 'fallback'
            except Exception as fallback_error:
                logger.error(f"‚ùå –ò primary, –∏ fallback URL –Ω–µ —Ä–∞–±–æ—Ç–∞—é—Ç:")
                logger.error(f"   Primary: {e}")
                logger.error(f"   Fallback: {fallback_error}")
                raise Exception(f"–û–±–∞ URL –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã: primary={e}, fallback={fallback_error}")
    
    async def fetch_product_with_locales(
        self, 
        base_url: str
    ) -> Tuple[str, str, str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –æ–±–µ–∏—Ö –ª–æ–∫–∞–ª–µ–π —Å fallback"""
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º URLs –¥–ª—è –æ–±–µ–∏—Ö –ª–æ–∫–∞–ª–µ–π
        if '/ru/' in base_url:
            ru_url = base_url
            ua_url = base_url.replace('/ru/', '/')
        else:
            ua_url = base_url
            ru_url = base_url.replace('prorazko.com/', 'prorazko.com/ru/')
        
        logger.info(f"üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–æ–≤–∞—Ä –¥–ª—è –æ–±–µ–∏—Ö –ª–æ–∫–∞–ª–µ–π:")
        logger.info(f"   RU: {ru_url}")
        logger.info(f"   UA: {ua_url}")
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º UA –≤–µ—Ä—Å–∏—é
        try:
            ua_content = await self.fetch_with_retry(ua_url)
            logger.info(f"‚úÖ UA –≤–µ—Ä—Å–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            logger.error(f"‚ùå UA –≤–µ—Ä—Å–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
            ua_content = None
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º RU –≤–µ—Ä—Å–∏—é
        try:
            ru_content = await self.fetch_with_retry(ru_url)
            logger.info(f"‚úÖ RU –≤–µ—Ä—Å–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
        except Exception as e:
            logger.error(f"‚ùå RU –≤–µ—Ä—Å–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: {e}")
            ru_content = None
        
        # –ï—Å–ª–∏ –æ–¥–Ω–∞ –∏–∑ –≤–µ—Ä—Å–∏–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ —á—Ç–æ –µ—Å—Ç—å
        if ua_content and ru_content:
            logger.info(f"‚úÖ –û–±–µ –ª–æ–∫–∞–ª–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã —É—Å–ø–µ—à–Ω–æ")
            return ua_content, ru_content, 'both'
        elif ua_content:
            logger.warning(f"‚ö†Ô∏è –¢–æ–ª—å–∫–æ UA –≤–µ—Ä—Å–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞")
            return ua_content, None, 'ua_only'
        elif ru_content:
            logger.warning(f"‚ö†Ô∏è –¢–æ–ª—å–∫–æ RU –≤–µ—Ä—Å–∏—è –¥–æ—Å—Ç—É–ø–Ω–∞")
            return None, ru_content, 'ru_only'
        else:
            raise Exception(f"–ù–∏ –æ–¥–Ω–∞ –∏–∑ –ª–æ–∫–∞–ª–µ–π –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞: UA={ua_url}, RU={ru_url}")
    
    def get_fallback_urls(self, url: str) -> Tuple[str, str]:
        """–ü–æ–ª—É—á–∞–µ—Ç fallback URLs –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –ª–æ–∫–∞–ª–µ–π"""
        if '/ru/' in url:
            ru_url = url
            ua_url = url.replace('/ru/', '/')
        else:
            ua_url = url
            ru_url = url.replace('prorazko.com/', 'prorazko.com/ru/')
        
        return ua_url, ru_url
