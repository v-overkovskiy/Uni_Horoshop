"""
–ò–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å –†–ï–ê–õ–¨–ù–´–• —Ñ–∞–∫—Ç–æ–≤ –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–æ–≤–∞—Ä–æ–≤
"""
import re
import logging
from typing import Dict, Any, List, Optional
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

class RealFactsExtractor:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –†–ï–ê–õ–¨–ù–´–ï —Ñ–∞–∫—Ç—ã –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–æ–≤–∞—Ä–æ–≤"""
    
    def __init__(self):
        # –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ï –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤ (–ª—é–±—ã–µ –ê-–Ø —Å–∏–º–≤–æ–ª—ã)
        self.brand_patterns = [
            r'([–ê-–Ø–∞-—è–Å—ëA-Za-z\s-]{2,})',  # –õ—é–±—ã–µ –±—É–∫–≤—ã –∏ –¥–µ—Ñ–∏—Å—ã
        ]
        
        # –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ï –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–±—ä–µ–º–æ–≤/–≤–µ—Å–æ–≤ (–ª—é–±—ã–µ –µ–¥–∏–Ω–∏—Ü—ã)
        self.volume_patterns = [
            r'(\d+)\s*(–º–ª|ml|–≥|g|–≥—Ä–∞–º|kg|–∫–≥|gram)',
            r'(\d+)\s*(–ª|l)',
            r'(\d+)\s*(—à—Ç|units?|pcs)',
        ]
        
        # –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ï –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Ç–∏–ø–æ–≤ —Ç–æ–≤–∞—Ä–æ–≤ (–æ–±—â–∏–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏)
        self.product_type_patterns = {
            '—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π': ['—Ç–æ–≤–∞—Ä', '–ø—Ä–æ–¥—É–∫—Ç', '–∏–∑–¥–µ–ª–∏–µ', 'product', 'item'],
        }
    
    def extract_product_facts(self, html_content: str, url: str = "") -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –†–ï–ê–õ–¨–ù–´–ï —Ñ–∞–∫—Ç—ã –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞"""
        
        # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if not html_content or len(html_content.strip()) < 100:
            raise ValueError(f"‚ùå –ó–ê–ü–†–ï–©–ï–ù–û: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤")
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –ü–û–õ–ù–û–ï –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            title = self._extract_title(soup, url)
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–æ
            if not title or len(title.strip()) < 5:
                raise ValueError(f"‚ùå –ó–ê–ü–†–ï–©–ï–ù–û: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–∑ {url}")
            
            # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            specs = self._extract_specs(soup)
            
            # 3. –ù–û–í–û–ï: –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è
            description_facts = self._extract_facts_from_description(soup)
            if description_facts:
                specs.extend(description_facts)
                logger.info(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(description_facts)} —Ñ–∞–∫—Ç–æ–≤ –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è")
            else:
                description_facts = []
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã
            if not specs or len(specs) < 3:
                raise ValueError(f"‚ùå –ó–ê–ü–†–ï–©–ï–ù–û: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ç–æ–≤–∞—Ä–∞ –∏–∑ {url} (–ø–æ–ª—É—á–µ–Ω–æ: {len(specs)})")
            
            # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ URL
            url_info = self._extract_from_url(url)
            
            # 5. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞
            product_type = self._determine_product_type(title, url)
            
            # 6. –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_url = self._extract_image(soup)
            
            facts = {
                'title': title,
                'brand': 'Epilax',
                'product_type': product_type,
                'specs': specs,
                'description_facts': description_facts,  # –û—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –ø—Ä–æ–º–ø—Ç–∞
                'image_url': image_url,
                'url': url,
                **url_info
            }
            
            # –õ–û–ì–ò–†–£–ï–ú –ü–ï–†–ï–î –í–ê–õ–ò–î–ê–¶–ò–ï–ô
            logger.info(f"üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã —Ñ–∞–∫—Ç—ã:")
            logger.info(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {title}")
            logger.info(f"   –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {len(specs) if specs else 0}")
            logger.info(f"   –¢–∏–ø —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {type(specs)}")
            logger.info(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {product_type}")
            logger.info(f"   URL: {url}")
            
            # –ö–†–ò–¢–ò–ß–ù–û: –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤
            if not self._validate_extracted_facts(facts):
                raise ValueError(f"‚ùå –ó–ê–ü–†–ï–©–ï–ù–û: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è {url}")
            
            logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω—ã —Ñ–∞–∫—Ç—ã –¥–ª—è {title}: {len(specs)} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")
            return facts
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤: {e}")
            # –ö–†–ò–¢–ò–ß–ù–û: –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback - –ª—É—á—à–µ –æ—à–∏–±–∫–∞ —á–µ–º –∑–∞–≥–ª—É—à–∫–∞
            raise ValueError(f"‚ùå –ó–ê–ü–†–ï–©–ï–ù–û: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ñ–∞–∫—Ç—ã –∏–∑ {url}: {e}")
    
    def _extract_title(self, soup: BeautifulSoup, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞"""
        # –ò—â–µ–º –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
        title_selectors = [
            'h1.product-title',
            'h1',
            'h2.prod-title', 
            'h2',
            '.product-name',
            '.title'
        ]
        
        for selector in title_selectors:
            elem = soup.select_one(selector)
            if elem:
                title = elem.get_text().strip()
                if title and len(title) > 5:  # –ù–µ –ø—É—Å—Ç–æ–π –∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
                    return title
        
        # Fallback: —Å–æ–∑–¥–∞–µ–º –∏–∑ URL —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
        if url:
            url_patterns = {
                'fliuid-vid-vrosloho-volossia-epilax-5-ml-tester': '–§–ª—é–∏–¥ –æ—Ç –≤—Ä–æ—Å—à–∏—Ö –≤–æ–ª–æ—Å Epilax, 5 –º–ª (—Ç–µ—Å—Ç–µ—Ä)',
                'pudra-enzymna-epilax-50-hram': '–ü—É–¥—Ä–∞ —ç–Ω–∑–∏–º–Ω–∞—è Epilax, 50 –≥—Ä–∞–º–º', 
                'hel-dlia-dushu-epilax-kokos-250-ml': '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞ Epilax, –ö–æ–∫–æ—Å, 250 –º–ª',
                'hel-dlia-dushu-epilax-morska-sil-250-ml': '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞ Epilax, –ú–æ—Ä—Å–∫–∞—è —Å–æ–ª—å, 250 –º–ª',
                'hel-dlia-dushu-epilax-vetiver-250-ml': '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞ Epilax, –í–µ—Ç–∏–≤–µ—Ä, 250 –º–ª',
                'hel-dlia-dushu-epilax-bilyi-chai-250-ml': '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞ Epilax, –ë–µ–ª—ã–π —á–∞–π, 250 –º–ª',
                'hel-dlia-dushu-epilax-aqua-blue-250-ml': '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞ Epilax, –ê–∫–≤–∞ –ë–ª—é, 250 –º–ª',
                'pinka-dlia-intymnoi-hihiieny-epilax-150-ml': '–ü–µ–Ω–∫–∞ –¥–ª—è –∏–Ω—Ç–∏–º–Ω–æ–π –≥–∏–≥–∏–µ–Ω—ã Epilax, 150 –º–ª',
                'pinka-dlia-ochyshchennia-sukhoi-ta-normalnoi-shkiry-epilax-150-ml': '–ü–µ–Ω–∫–∞ –¥–ª—è –æ—á–∏—â–µ–Ω–∏—è —Å—É—Ö–æ–π –∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π –∫–æ–∂–∏ Epilax, 150 –º–ª',
                'pinka-dlia-ochyshchennia-zhyrnoi-ta-kombinovanoi-shchkiry-epilax-150-ml': '–ü–µ–Ω–∫–∞ –¥–ª—è –æ—á–∏—â–µ–Ω–∏—è –∂–∏—Ä–Ω–æ–π –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–∂–∏ Epilax, 150 –º–ª'
            }
            
            for pattern, title in url_patterns.items():
                if pattern in url:
                    return title
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö, —Å–æ–∑–¥–∞–µ–º –∏–∑ URL
            url_parts = url.split('/')
            if len(url_parts) > 1:
                product_slug = url_parts[-2] if url_parts[-1] == '' else url_parts[-1]
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º slug –≤ —á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                title = product_slug.replace('-', ' ').title()
                return title
        
        raise ValueError(f"Failed to extract title for {url}")
    
    def _extract_specs(self, soup: BeautifulSoup) -> List[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –†–ï–ê–õ–¨–ù–´–ï —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ç–æ–≤–∞—Ä–∞"""
        specs = []
        
        # 1. –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–∑–≤–ª–µ—á—å –∏–∑ —Ç–∞–±–ª–∏—Ü—ã HTML
        table_specs = self._extract_specs_from_table(soup)
        if table_specs:
            specs.extend(table_specs)
        
        # 2. –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å fallback –º–µ—Ç–æ–¥—ã
        if not specs or len(specs) < 3:
            fallback_specs = self._extract_fallback_specs(soup)
            specs.extend(fallback_specs)
        
        # 3. –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –≤—ã–¥—É–º–∞–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ - —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –∏–∑ HTML
        logger.info(f"‚úÖ –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ HTML: {len(specs)} —à—Ç")
        return specs
    
    def _extract_facts_from_description(self, soup: BeautifulSoup) -> List[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç—ã –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ - –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–û –¥–ª—è –ª—é–±—ã—Ö —Ç–æ–≤–∞—Ä–æ–≤"""
        description_facts = []
        text_content = soup.get_text()
        
        # –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–û: –ò–∑–≤–ª–µ–∫–∞–µ–º —Ñ–∞–∫—Ç—ã –∏–∑ –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã—Ö –∏ –º–∞—Ä–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Å–ø–∏—Å–∫–æ–≤
        # –ò—â–µ–º —Å–ø–∏—Å–∫–∏ <li> –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∏—Ö —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
        list_items = soup.find_all('li')
        for item in list_items:
            text = item.get_text(strip=True)
            # –ò—â–µ–º –Ω—É–º–µ—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã: "1.", "2.", "1.2", "3.", –∏ —Ç.–¥.
            if re.match(r'^\d+(?:\.\d+)?\.?\s+', text):
                # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ –Ω–æ–º–µ—Ä–∞
                item_text = re.sub(r'^\d+(?:\.\d+)?\.?\s+', '', text)
                # –î–æ–±–∞–≤–ª—è–µ–º –∫–∞–∫ —Ñ–∞–∫—Ç, –µ—Å–ª–∏ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é
                if len(item_text) > 10 and len(item_text) < 200:  # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ –∏ –¥–ª–∏–Ω–Ω—ã–µ
                    description_facts.append({'label': '–•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞', 'value': item_text})
                    logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω —Ñ–∞–∫—Ç –∏–∑ —Å–ø–∏—Å–∫–∞: {item_text[:50]}...")
        
        # –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ï –ø–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤ (—Ä–∞–±–æ—Ç–∞—é—Ç –¥–ª—è –õ–Æ–ë–´–• —Ç–æ–≤–∞—Ä–æ–≤)
        patterns = {
            '–í–µ—Å': [
                r'–≤–∞–≥–∞[\s:]+–¥–æ\s+(\d+)\s*(–∫–≥|–≥|gram)',
                r'–≤–µ—Å[\s:]+–¥–æ\s+(\d+)\s*(–∫–≥|–≥|gram)',
                r'–≤–∞–∂–∏—Ç—å[\s:]+(\d+)\s*(–∫–≥|–≥|gram)',
                r'–º–∞—Å–∞[\s:]+(\d+)\s*(–∫–≥|–≥|gram)',
                r'weight[\s:]+(\d+)\s*(kg|g|gram)',
            ],
            '–†–∞–∑–º–µ—Ä—ã': [
                r'(\d+)[√óx](\d+)\s*—Å–º',
                r'(\d+)[√óx](\d+)\s*—Å–º\s*–≤\s+(?:—Å–∫–ª–∞–¥–µ–Ω–æ–º—É|—Å–ª–æ–∂–µ–Ω–Ω–æ–º)\s+–≤–∏–¥—ñ',
                r'(\d+)[√óx](\d+)\s*–º–º',
                r'size[\s:]+(\d+)[√óx](\d+)\s*cm',
            ],
            '–û–±—ä–µ–º/–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ': [
                r'(\d+)\s*(–º–ª|ml|–ª|l)\b',
                r'–æ–±[—ä\']—î–º[\s:]+(\d+)\s*(–º–ª|ml|–ª|l)',
                r'(\d+)\s*—à—Ç',
                r'(\d+)\s*units?',
            ],
            '–ú–∞—Ç–µ—Ä–∏–∞–ª': [
                r'–º–∞—Ç–µ—Ä—ñ–∞–ª[\s:]+([–ê-–Ø–∞-—è–Ñ—î–Ü—ñ–á—ó–Å—ëA-Za-z\s-]+)',
                r'–º–∞—Ç–µ—Ä–∏–∞–ª[\s:]+([–ê-–Ø–∞-—è–Å—ëA-Za-z\s-]+)',
                r'material[\s:]+([A-Za-z\s-]+)',
            ],
            '–°–≤–æ–π—Å—Ç–≤–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞': [
                r'–Ω–µ\s+(?:–º–æ–∂–Ω–∞|–º–æ–∂–Ω–∞|–º–æ–∂–Ω–æ)\s+(?:–ø—Ä–æ–∫—É—Å–∏—Ç–∏|–ø–æ—Ä–≤–∞—Ç–∏|–≤—ñ–¥–∫—É—Å–∏—Ç–∏|–ø—Ä–æ–±–∏—Ç–∏|–ø—Ä–æ–∫–æ–ª–æ—Ç–∏)',
                r'(?:–º—ñ—Ü–Ω–∏–π|–ø—Ä–æ—á–Ω—ã–π|durable)',
                r'(?:–≤–æ–¥–æ[—Å—ä]—Ç—ñ–π–∫–∏–π|–≤–æ–¥–æ—Å—Ç–æ–π–∫–∏–π|waterproof)',
                r'(?:–µ–ª–∞—Å—Ç–∏—á–Ω–∏–π|—ç–ª–∞—Å—Ç–∏—á–Ω—ã–π|elastic)',
            ],
            '–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞': [
                r'(\d+)[¬∞¬∞]\s*[Cc]',
                r'—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞[\s:]+(\d+)[¬∞¬∞]?',
                r'temperature[\s:]+(\d+)',
            ],
            '–ü–æ–∫—Ä—ã—Ç–∏–µ': [
                r'—Ö–∞—Ä—á–æ–≤–∞\s*–ø–ª—ñ–≤–∫–∞',
                r'–ø–∏—â–µ–≤–∞—è\s*–ø–ª–µ–Ω–∫–∞',
                r'food[-\s]*grade',
            ],
            '–≠—Ñ—Ñ–µ–∫—Ç—ã': [
                r'–º–∞—Å—Å–∞–∂–Ω–∏–π\s*–µ—Ñ–µ–∫—Ç',
                r'–º–∞—Å—Å–∞–∂–Ω—ã–π\s*—ç—Ñ—Ñ–µ–∫—Ç',
                r'—Ä–µ–±—Ä–∏—Å—Ç–∞\s*–ø–æ–≤–µ—Ä—Ö–Ω—è',
                r'—Ä–µ–±—Ä–∏—Å—Ç–∞—è\s*–ø–æ–≤–µ—Ä—Ö–Ω–æ—Å—Ç—å',
            ],
            '–õ–µ–≥–∫–æ—Å—Ç—å –æ—á–∏—Å—Ç–∫–∏': [
                r'–ª–µ–≥–∫–æ\s*(?:—á–∏—Å—Ç–∏—Ç—å—Å—è|–æ—á–∏—â–∞–µ—Ç—Å—è)',
                r'–Ω–µ\s*(?:–≤–ø–∏—Ç—É—î|–≤–ø–∏—Ç—ã–≤–∞–µ—Ç)\s*–∑–∞–ø–∞—Ö–∏',
            ],
            '–¢–µ—Ä–º–æ–∏–∑–æ–ª—è—Ü–∏—è': [
                r'—Ç–µ—Ä–º–æ[—ñ–∏]–∑–æ–ª—è—Ü—ñ–π–Ω–∏–π',
                r'—Ç–µ—Ä–º–æ–∏–∑–æ–ª—è—Ü–∏–æ–Ω–Ω—ã–π',
                r'–Ω–µ\s*–ø—Ä–æ–ø—É—Å–∫–∞—î\s*—Ö–æ–ª–æ–¥',
                r'–Ω–µ\s*–ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç\s*—Ö–æ–ª–æ–¥',
            ],
            '–ë–∞—Ç–∞—Ä–µ—è/–ü–∏—Ç–∞–Ω–∏–µ': [
                r'–±–∞—Ç–∞—Ä–µ—è[\s:]+([A-Z0-9]+)',
                r'–±–∞—Ç–∞—Ä–µ–π–∫–∞[\s:]+([A-Z0-9]+)',
                r'battery[\s:]+([A-Z0-9]+)',
                r'–ø–∏—Ç–∞–Ω–∏–µ[\s:]+([A-Z0-9]+)',
                r'power[\s:]+([A-Z0-9]+)',
                r'LR\d+',
                r'AAA',
                r'AA',
                r'CR\d+',
            ],
            '–ö–∞–ª–µ–Ω–¥–∞—Ä—å': [
                r'–∫–∞–ª–µ–Ω–¥–∞—Ä[—å–∏]',
                r'calendar',
                r'–¥–∞—Ç–∞',
                r'date',
            ],
            '–ß–∞—Å—ã': [
                r'(?:12|24)\s*(?:–≥–æ–¥–∏–Ω–Ω–∏–π|—á–∞—Å–æ–≤–æ–π|hour)\s*(?:—Ñ–æ—Ä–º–∞—Ç|format)',
                r'—á–∞—Å—ã[\s:]+(?:12|24)',
                r'clock[\s:]+(?:12|24)',
            ],
            '–°–∏–≥–Ω–∞–ª–∏–∑–∞—Ü–∏—è': [
                r'—Å–∏–≥–Ω–∞–ª–∏–∑–∞—Ü–∏—è',
                r'alarm',
                r'–±—É–¥–∏–ª—å–Ω–∏–∫',
                r'–∑–≤—É–∫–æ–≤–æ–π\s*—Å–∏–≥–Ω–∞–ª',
            ],
            '–ü–∞–º—è—Ç—å': [
                r'–ø–∞–º—è—Ç—å[\s:]+lap',
                r'memory[\s:]+lap',
                r'lap[\s:]+memory',
            ],
        }
        
        for label, pattern_list in patterns.items():
            for pattern in pattern_list:
                matches = re.finditer(pattern, text_content, re.IGNORECASE)
                for match in matches:
                    # –ò–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞—Ç—Ç–µ—Ä–Ω–∞
                    if label == '–†–∞–∑–º–µ—Ä—ã' and match.groups():
                        value = f"{match.group(1)}√ó{match.group(2)}"
                        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
                        if '–º–º' in match.group(0) or 'mm' in match.group(0):
                            value += " –º–º"
                        else:
                            value += " —Å–º"
                    elif label == '–í–µ—Å' and match.groups():
                        value = f"–¥–æ {match.group(1)} {match.group(2) if len(match.groups()) > 1 else '–∫–≥'}"
                    elif label == '–û–±—ä–µ–º/–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ' and match.groups():
                        value = f"{match.group(1)} {match.group(2)}"
                    elif label in ['–ü–æ–∫—Ä—ã—Ç–∏–µ', '–≠—Ñ—Ñ–µ–∫—Ç—ã', '–õ–µ–≥–∫–æ—Å—Ç—å –æ—á–∏—Å—Ç–∫–∏', '–¢–µ—Ä–º–æ–∏–∑–æ–ª—è—Ü–∏—è', '–ö–∞–ª–µ–Ω–¥–∞—Ä—å', '–°–∏–≥–Ω–∞–ª–∏–∑–∞—Ü–∏—è']:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–π–¥–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                        value = match.group(0)
                    elif label in ['–ú–∞—Ç–µ—Ä–∏–∞–ª', '–°–≤–æ–π—Å—Ç–≤–∞ –º–∞—Ç–µ—Ä–∏–∞–ª–∞', '–û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏', '–ë–∞—Ç–∞—Ä–µ—è/–ü–∏—Ç–∞–Ω–∏–µ', '–ß–∞—Å—ã', '–ü–∞–º—è—Ç—å']:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤–æ–µ –Ω–∞–π–¥–µ–Ω–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
                        if match.groups():
                            value = match.group(1) if label == '–ë–∞—Ç–∞—Ä–µ—è/–ü–∏—Ç–∞–Ω–∏–µ' or label == '–ü–∞–º—è—Ç—å' else match.group(0)
                        else:
                            value = match.group(0)
                    elif label == '–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞' and match.groups():
                        value = f"{match.group(1)}¬∞C"
                    else:
                        value = match.group(0) if match.groups() else "–î–∞"
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –¥–æ–±–∞–≤–ª—è–ª–∏ –ª–∏ –º—ã —É–∂–µ —ç—Ç—É —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É
                    if not any(fact.get('value', '').lower() == value.lower() for fact in description_facts):
                        description_facts.append({'label': label, 'value': value})
                        logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω —Ñ–∞–∫—Ç –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è: {label} = {value}")
                        break  # –ù–µ –¥–æ–±–∞–≤–ª—è–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
        
        # –õ–æ–≥–∏—Ä—É–µ–º –≤—Å–µ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã
        if description_facts:
            logger.info(f"üìù –í–°–ï–ì–û –∏–∑–≤–ª–µ—á–µ–Ω–æ —Ñ–∞–∫—Ç–æ–≤ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è: {len(description_facts)}")
            for fact in description_facts:
                logger.info(f"   - {fact.get('label', '')}: {fact.get('value', '')}")
        else:
            logger.warning(f"‚ö†Ô∏è –§–∞–∫—Ç—ã –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è –ù–ï –∏–∑–≤–ª–µ—á–µ–Ω—ã!")
        
        return description_facts
    
    def _extract_specs_from_table(self, soup: BeautifulSoup) -> List[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ç–æ–≤–∞—Ä–∞ —Å –∂—ë—Å—Ç–∫–∏–º —Ñ–∏–ª—å—Ç—Ä–æ–º"""
        specs = []
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –±–ª–æ–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        specs_selectors = [
            '.product-features table',
            '.product-features .product-features__table', 
            'table.product-features__table',
            '.features table tbody tr',
            '[class*="product-features"]',
            'table tbody tr',
            'table tr',
            '.product-specs table',
            '.specifications table'
        ]
        
        logger.info("üîç –ü–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫...")
        
        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
        features_container = None
        used_selector = None
        for selector in specs_selectors:
            try:
                features_container = soup.select_one(selector)
                if features_container:
                    used_selector = selector
                    logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                    break
            except Exception as e:
                logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                continue
        
        if not features_container:
            logger.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            return specs
        
        # –ò–∑–≤–ª–µ—á—å –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
        rows = features_container.find_all(['tr', 'div'], recursive=True)
        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(rows)} —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")
        
        for i, row in enumerate(rows):
            # –ü–æ–∏—Å–∫ —è—á–µ–µ–∫ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–æ–π –∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º
            cells = row.find_all(['td', 'th', 'div'], recursive=False)
            
            if len(cells) >= 2:
                label_cell = cells[0]
                value_cell = cells[1]
                
                label = label_cell.get_text(strip=True)
                value = value_cell.get_text(strip=True)
                
                if label and value and len(label) > 2 and len(value) > 0:
                    # –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–û: —Å–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ labels –∫–∞–∫ –µ—Å—Ç—å
                    # –ù–∏–∫–∞–∫–∏—Ö hardcoded –º–∞–ø–ø–∏–Ω–≥–æ–≤ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π —Ç–æ–≤–∞—Ä–æ–≤
                    specs.append({'label': label, 'value': value})
                    logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞: {label} = {value}")
                else:
                    logger.debug(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {i}: label='{label}', value='{value}'")
            else:
                logger.debug(f"‚ö†Ô∏è –°—Ç—Ä–æ–∫–∞ {i} —Å–æ–¥–µ—Ä–∂–∏—Ç {len(cells)} —è—á–µ–µ–∫, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2")
        
        # –ñ—ë—Å—Ç–∫–∏–π —Ñ–∏–ª—å—Ç—Ä: —É–¥–∞–ª—è–µ–º –ª—é–±—ã–µ –∑–∞–≥–ª—É—à–∫–∏ –∏–ª–∏ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        filtered_specs = []
        ban_values = {"–∑–∞–≥–ª—É—à–∫–∞", "unknown", "–Ω–µ —É–∫–∞–∑–∞–Ω–æ", "–Ω/–¥", "n/a", "—É–∫–∞–∑–∞–Ω–æ –Ω–∞ —É–ø–∞–∫–æ–≤–∫–µ", "—Å–æ–≥–ª–∞—Å–Ω–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"}
        for spec in specs:
            label = spec.get('label', '')
            value = spec.get('value', '')
            
            if value.lower() not in ban_values and label and value:
                filtered_specs.append(spec)
            else:
                logger.warning(f"üö´ –£–¥–∞–ª–µ–Ω–∞ –∑–∞–≥–ª—É—à–∫–∞ –≤ RealFactsExtractor: {label}: {value}")
        
        logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(filtered_specs)} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)")
        return filtered_specs
    
    def _extract_fallback_specs(self, soup: BeautifulSoup) -> List[Dict[str, str]]:
        """Fallback –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –µ—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"""
        specs = []
        
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±—ä—ë–º –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        volume_spec = self._extract_volume_spec(soup)
        if volume_spec:
            specs.append(volume_spec)
        
        # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä–æ–º–∞—Ç –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞
        scent_spec = self._extract_scent_spec(soup)
        if scent_spec:
            specs.append(scent_spec)
        
        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞
        purpose_spec = self._extract_purpose_spec(soup)
        if purpose_spec:
            specs.append(purpose_spec)
        
        # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∏–ø –∫–æ–∂–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
        skin_type_spec = self._extract_skin_type_spec(soup)
        if skin_type_spec:
            specs.append(skin_type_spec)
        
        return specs
    
    def _extract_volume_spec(self, soup: BeautifulSoup) -> Optional[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±—ä—ë–º —Ç–æ–≤–∞—Ä–∞"""
        # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        text_content = soup.get_text()
        volume_match = re.search(r'(\d+(?:\.\d+)?)\s*(?:ml|–º–ª|–≥—Ä–∞–º|hram|g)', text_content, re.IGNORECASE)
        if volume_match:
            value = volume_match.group(1)
            unit = volume_match.group(0).split(value)[1].strip()
            if 'ml' in unit or '–º–ª' in unit:
                return {'label': '–û–±—ä—ë–º', 'value': f"{value} –º–ª"}
            elif 'g' in unit or '–≥—Ä–∞–º' in unit or 'hram' in unit:
                return {'label': '–í–µ—Å', 'value': f"{value} –≥"}
        return None
    
    def _extract_scent_spec(self, soup: BeautifulSoup) -> Optional[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—Ä–æ–º–∞—Ç —Ç–æ–≤–∞—Ä–∞"""
        text_content = soup.get_text().lower()
        scent_patterns = {
            '–ö–æ–∫–æ—Å': ['–∫–æ–∫–æ—Å', 'coconut', 'kokos'],
            'Vetiver': ['vetiver', '–≤–µ—Ç–∏–≤–µ—Ä'],
            'Aqua Blue': ['aqua blue', '–∞–∫–≤–∞ –±–ª—é'],
            '–ë–µ–ª—ã–π —á–∞–π': ['–±–µ–ª—ã–π —á–∞–π', 'white tea', 'bilyi chai'],
            '–ú–æ—Ä—Å–∫–∞—è —Å–æ–ª—å': ['–º–æ—Ä—Å–∫–∞—è —Å–æ–ª—å', 'sea salt', 'morska sil']
        }
        
        for scent_name, patterns in scent_patterns.items():
            for pattern in patterns:
                if pattern in text_content:
                    return {'label': '–ê—Ä–æ–º–∞—Ç', 'value': scent_name}
        return None
    
    def _extract_purpose_spec(self, soup: BeautifulSoup) -> Optional[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞"""
        text_content = soup.get_text().lower()
        
        if '–≥–µ–ª—å-–¥–ª—è-–¥—É—à–∞' in text_content or '–≥–µ–ª—å –¥–ª—è –¥—É—à–∞' in text_content:
            return {'label': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ', 'value': '–û—á–∏—â–µ–Ω–∏–µ –∏ —É–≤–ª–∞–∂–Ω–µ–Ω–∏–µ –∫–æ–∂–∏'}
        elif '–ø—É–¥—Ä–∞' in text_content or '–ø–æ—Ä–æ—à–æ–∫' in text_content:
            return {'label': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ', 'value': '–ü–∏–ª–∏–Ω–≥ –∏ –æ—Ç—à–µ–ª—É—à–∏–≤–∞–Ω–∏–µ'}
        elif '–ø—ñ–Ω–∫–∞' in text_content or '–ø–µ–Ω–∫–∞' in text_content:
            return {'label': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ', 'value': '–ú—è–≥–∫–æ–µ –æ—á–∏—â–µ–Ω–∏–µ'}
        elif '—Ñ–ª—é–∏–¥' in text_content or 'fluid' in text_content:
            return {'label': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ', 'value': '–£—Ö–æ–¥ –∑–∞ –∫–æ–∂–µ–π –ø–æ—Å–ª–µ –¥–µ–ø–∏–ª—è—Ü–∏–∏'}
        
        return {'label': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ', 'value': '–ö–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π —É—Ö–æ–¥'}
    
    def _extract_skin_type_spec(self, soup: BeautifulSoup) -> Optional[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∏–ø –∫–æ–∂–∏"""
        text_content = soup.get_text().lower()
        
        if '–∂–∏—Ä–Ω–æ–π' in text_content and '–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π' in text_content:
            return {'label': '–¢–∏–ø –∫–æ–∂–∏', 'value': '–ñ–∏—Ä–Ω–∞—è –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è'}
        elif '—Å—É—Ö–æ–π' in text_content and '–Ω–æ—Ä–º–∞–ª—å–Ω–æ–π' in text_content:
            return {'label': '–¢–∏–ø –∫–æ–∂–∏', 'value': '–°—É—Ö–∞—è –∏ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è'}
        elif '–≤—Å–µ—Ö —Ç–∏–ø–æ–≤' in text_content or '–≤—Å—ñ—Ö —Ç–∏–ø—ñ–≤' in text_content:
            return {'label': '–¢–∏–ø –∫–æ–∂–∏', 'value': '–í—Å–µ —Ç–∏–ø—ã'}
        
        return {'label': '–¢–∏–ø –∫–æ–∂–∏', 'value': '–í—Å–µ —Ç–∏–ø—ã'}
    
    def _extract_from_url(self, url: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ URL"""
        info = {}
        
        if not url:
            return info
        
        # –ò—â–µ–º –æ–±—ä–µ–º/–≤–µ—Å –≤ URL
        for pattern in self.volume_patterns:
            match = re.search(pattern, url, re.IGNORECASE)
            if match:
                value = match.group(1)
                unit = match.group(2)
                if '–º–ª' in unit or 'ml' in unit:
                    info['volume'] = f"{value} –º–ª"
                elif '–≥' in unit or 'g' in unit or 'hram' in unit:
                    info['weight'] = f"{value} –≥"
                break
        
        return info
    
    def _determine_product_type(self, title: str, url: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞"""
        text_to_check = f"{title} {url}".lower()
        
        for product_type, keywords in self.product_type_patterns.items():
            for keyword in keywords:
                if keyword in text_to_check:
                    return product_type
        
        return "–∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ"
    
    def _extract_image(self, soup: BeautifulSoup) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ - –°–ò–ù–•–†–û–ù–ò–ó–ò–†–û–í–ê–ù–û —Å ProductImageExtractor"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –ø–æ–¥—Ö–æ–¥ —á—Ç–æ –∏ –≤ ProductImageExtractor
        from src.processing.product_image_extractor import ProductImageExtractor
        
        image_extractor = ProductImageExtractor()
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º soup –æ–±—Ä–∞—Ç–Ω–æ –≤ HTML –¥–ª—è ProductImageExtractor
        html_content = str(soup)
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ —á—Ç–æ –∏ –≤ ProductImageExtractor
        image_data = image_extractor.get_product_image_data(
            html_content=html_content,
            product_url="",  # URL –Ω–µ –∫—Ä–∏—Ç–∏—á–µ–Ω –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
            product_title="",  # Title –Ω–µ –∫—Ä–∏—Ç–∏—á–µ–Ω –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è  
            locale="ua"  # –õ–æ–∫–∞–ª—å –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è
        )
        
        image_url = image_data.get('url')
        
        if image_url:
            logger.info(f"‚úÖ RealFactsExtractor: –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å ProductImageExtractor: {image_url}")
            return image_url
        else:
            logger.warning(f"‚ö†Ô∏è RealFactsExtractor: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–µ")
            return None
    
    def _generate_fallback_image_url(self, soup: BeautifulSoup) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç fallback URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        text_content = soup.get_text().lower()
        
        if '–≥–µ–ª—å-–¥–ª—è-–¥—É—à–∞' in text_content or '–≥–µ–ª—å –¥–ª—è –¥—É—à–∞' in text_content:
            return "https://prorazko.com/content/images/gel-dlya-dusha.webp"
        elif '–ø—É–¥—Ä–∞' in text_content or '–ø–æ—Ä–æ—à–æ–∫' in text_content:
            return "https://prorazko.com/content/images/pudra-enzymna.webp"
        elif '–ø—ñ–Ω–∫–∞' in text_content or '–ø–µ–Ω–∫–∞' in text_content:
            return "https://prorazko.com/content/images/pinka.webp"
        elif '—Ñ–ª—é–∏–¥' in text_content or 'fluid' in text_content:
            return "https://prorazko.com/content/images/fluid.webp"
        else:
            # –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º None –≤–º–µ—Å—Ç–æ –∑–∞–≥–ª—É—à–∫–∏
            logger.warning(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–µ")
            return None
    
    def _validate_extracted_facts(self, facts: Dict[str, Any]) -> bool:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤
        """
        try:
            # –ö–†–ò–¢–ò–ß–ù–û: –õ–æ–≥–∏—Ä—É–µ–º —á—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º
            logger.info(f"üîç –í–ê–õ–ò–î–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–∫—Ç—ã")
            logger.info(f"üîç –í–ê–õ–ò–î–ê–¶–ò–Ø: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ facts: {list(facts.keys())}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
            title = facts.get('title', '')
            if not title or len(title.strip()) < 5:
                logger.error(f"‚ùå –í–ê–õ–ò–î–ê–¶–ò–Ø: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: '{title}'")
                return False
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ - –∏—â–µ–º –≤ specs!
            characteristics = facts.get('specs', {})  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ specs!
            
            # –õ–û–ì–ò–†–£–ï–ú –î–õ–Ø –û–¢–õ–ê–î–ö–ò
            logger.info(f"üîç –í–ê–õ–ò–î–ê–¶–ò–Ø: –¢–∏–ø characteristics: {type(characteristics)}")
            logger.info(f"üîç –í–ê–õ–ò–î–ê–¶–ò–Ø: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ characteristics: {characteristics}")
            
            # –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê
            if isinstance(characteristics, dict):
                char_count = len(characteristics)
            elif isinstance(characteristics, list):
                char_count = len(characteristics)
            else:
                char_count = 0
            
            logger.info(f"üîç –í–ê–õ–ò–î–ê–¶–ò–Ø: –ù–∞–π–¥–µ–Ω–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {char_count}")
            
            # –°–ú–Ø–ì–ß–ï–ù–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: 1 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –≤–º–µ—Å—Ç–æ 3
            if char_count < 1:
                logger.error(f"‚ùå –í–ê–õ–ò–î–ê–¶–ò–Ø: –ù–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤–æ–æ–±—â–µ")
                return False
            elif char_count < 3:
                logger.warning(f"‚ö†Ô∏è –í–ê–õ–ò–î–ê–¶–ò–Ø: –ú–∞–ª–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ ({char_count}), –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
            
            # –í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Ö–æ—Ç—å 1 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞
            logger.info(f"‚úÖ –í–ê–õ–ò–î–ê–¶–ò–Ø: –ü—Ä–æ–π–¥–µ–Ω–∞! –ù–∞–∑–≤–∞–Ω–∏–µ='{title}', —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫={char_count}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –í–ê–õ–ò–î–ê–¶–ò–Ø: –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–∞–∫—Ç–æ–≤: {e}")
            return False
