"""
–ò–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å –†–ï–ê–õ–¨–ù–´–• —Ñ–∞–∫—Ç–æ–≤ –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–æ–≤–∞—Ä–æ–≤
"""
import re
import logging
from typing import Dict, Any, List, Optional
from bs4 import BeautifulSoup

logger = logging.getLogger(__name__)

class RealFactsExtractor:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –†–ï–ê–õ–¨–ù–´–ï —Ñ–∞–∫—Ç—ã –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü —Ç–æ–≤–∞—Ä–æ–≤"""
    
    def __init__(self):
        self.brand_patterns = [
            r'Epilax',
            r'ProRazko',
            r'([–ê-–Ø–∞-—è–Å—ë]+)'
        ]
        
        self.volume_patterns = [
            r'(\d+)\s*(–º–ª|ml)',
            r'(\d+)\s*(–≥|g|–≥—Ä–∞–º|hram)',
            r'(\d+)\s*(–ª|l)'
        ]
        
        self.product_type_patterns = {
            '–ø—É–¥—Ä–∞': ['–ø—É–¥—Ä–∞', 'pudra', '–ø–æ—Ä–æ—à–æ–∫'],
            '–≥–µ–ª—å': ['–≥–µ–ª—å', 'gel', '—Ñ–ª—é–∏–¥', 'fluid'],
            '–ø—ñ–Ω–∫–∞': ['–ø—ñ–Ω–∫–∞', '–ø–µ–Ω–∫–∞', 'foam'],
            '–∫—Ä–µ–º': ['–∫—Ä–µ–º', 'cream', '–º–∞–∑—å']
        }
    
    def extract_product_facts(self, html_content: str, url: str = "") -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –†–ï–ê–õ–¨–ù–´–ï —Ñ–∞–∫—Ç—ã –∏–∑ HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞"""
        
        # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        if not html_content or len(html_content.strip()) < 100:
            raise ValueError(f"‚ùå –ó–ê–ü–†–ï–©–ï–ù–û: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤")
        
        try:
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –ü–û–õ–ù–û–ï –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
            title = self._extract_title(soup, url)
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ –Ω–∞–∑–≤–∞–Ω–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–æ
            if not title or len(title.strip()) < 5:
                raise ValueError(f"‚ùå –ó–ê–ü–†–ï–©–ï–ù–û: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞ –∏–∑ {url}")
            
            # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            specs = self._extract_specs(soup)
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑–≤–ª–µ—á–µ–Ω—ã
            if not specs or len(specs) < 3:
                raise ValueError(f"‚ùå –ó–ê–ü–†–ï–©–ï–ù–û: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ç–æ–≤–∞—Ä–∞ –∏–∑ {url} (–ø–æ–ª—É—á–µ–Ω–æ: {len(specs)})")
            
            # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ URL
            url_info = self._extract_from_url(url)
            
            # 4. –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞
            product_type = self._determine_product_type(title, url)
            
            # 5. –ò–∑–≤–ª–µ–∫–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image_url = self._extract_image(soup)
            
            facts = {
                'title': title,
                'brand': 'Epilax',
                'product_type': product_type,
                'specs': specs,
                'image_url': image_url,
                'url': url,
                **url_info
            }
            
            # –õ–û–ì–ò–†–£–ï–ú –ü–ï–†–ï–î –í–ê–õ–ò–î–ê–¶–ò–ï–ô
            logger.info(f"üì¶ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã —Ñ–∞–∫—Ç—ã:")
            logger.info(f"   –ù–∞–∑–≤–∞–Ω–∏–µ: {title}")
            logger.info(f"   –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {len(specs) if specs else 0}")
            logger.info(f"   –¢–∏–ø —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {type(specs)}")
            logger.info(f"   –ö–∞—Ç–µ–≥–æ—Ä–∏—è: {product_type}")
            logger.info(f"   URL: {url}")
            
            # –ö–†–ò–¢–ò–ß–ù–û: –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤
            if not self._validate_extracted_facts(facts):
                raise ValueError(f"‚ùå –ó–ê–ü–†–ï–©–ï–ù–û: –ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã –Ω–µ –ø—Ä–æ—à–ª–∏ –≤–∞–ª–∏–¥–∞—Ü–∏—é –¥–ª—è {url}")
            
            logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω—ã —Ñ–∞–∫—Ç—ã –¥–ª—è {title}: {len(specs)} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")
            return facts
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ñ–∞–∫—Ç–æ–≤: {e}")
            # –ö–†–ò–¢–ò–ß–ù–û: –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback - –ª—É—á—à–µ –æ—à–∏–±–∫–∞ —á–µ–º –∑–∞–≥–ª—É—à–∫–∞
            raise ValueError(f"‚ùå –ó–ê–ü–†–ï–©–ï–ù–û: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å —Ñ–∞–∫—Ç—ã –∏–∑ {url}: {e}")
    
    def _extract_title(self, soup: BeautifulSoup, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–æ–ª–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞"""
        # –ò—â–µ–º –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
        title_selectors = [
            'h1.product-title',
            'h1',
            'h2.prod-title', 
            'h2',
            '.product-name',
            '.title'
        ]
        
        for selector in title_selectors:
            elem = soup.select_one(selector)
            if elem:
                title = elem.get_text().strip()
                if title and len(title) > 5:  # –ù–µ –ø—É—Å—Ç–æ–π –∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π
                    return title
        
        # Fallback: —Å–æ–∑–¥–∞–µ–º –∏–∑ URL —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –Ω–∞–∑–≤–∞–Ω–∏—è–º–∏
        if url:
            url_patterns = {
                'fliuid-vid-vrosloho-volossia-epilax-5-ml-tester': '–§–ª—é–∏–¥ –æ—Ç –≤—Ä–æ—Å—à–∏—Ö –≤–æ–ª–æ—Å Epilax, 5 –º–ª (—Ç–µ—Å—Ç–µ—Ä)',
                'pudra-enzymna-epilax-50-hram': '–ü—É–¥—Ä–∞ —ç–Ω–∑–∏–º–Ω–∞—è Epilax, 50 –≥—Ä–∞–º–º', 
                'hel-dlia-dushu-epilax-kokos-250-ml': '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞ Epilax, –ö–æ–∫–æ—Å, 250 –º–ª',
                'hel-dlia-dushu-epilax-morska-sil-250-ml': '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞ Epilax, –ú–æ—Ä—Å–∫–∞—è —Å–æ–ª—å, 250 –º–ª',
                'hel-dlia-dushu-epilax-vetiver-250-ml': '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞ Epilax, –í–µ—Ç–∏–≤–µ—Ä, 250 –º–ª',
                'hel-dlia-dushu-epilax-bilyi-chai-250-ml': '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞ Epilax, –ë–µ–ª—ã–π —á–∞–π, 250 –º–ª',
                'hel-dlia-dushu-epilax-aqua-blue-250-ml': '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞ Epilax, –ê–∫–≤–∞ –ë–ª—é, 250 –º–ª',
                'pinka-dlia-intymnoi-hihiieny-epilax-150-ml': '–ü–µ–Ω–∫–∞ –¥–ª—è –∏–Ω—Ç–∏–º–Ω–æ–π –≥–∏–≥–∏–µ–Ω—ã Epilax, 150 –º–ª',
                'pinka-dlia-ochyshchennia-sukhoi-ta-normalnoi-shkiry-epilax-150-ml': '–ü–µ–Ω–∫–∞ –¥–ª—è –æ—á–∏—â–µ–Ω–∏—è —Å—É—Ö–æ–π –∏ –Ω–æ—Ä–º–∞–ª—å–Ω–æ–π –∫–æ–∂–∏ Epilax, 150 –º–ª',
                'pinka-dlia-ochyshchennia-zhyrnoi-ta-kombinovanoi-shchkiry-epilax-150-ml': '–ü–µ–Ω–∫–∞ –¥–ª—è –æ—á–∏—â–µ–Ω–∏—è –∂–∏—Ä–Ω–æ–π –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∫–æ–∂–∏ Epilax, 150 –º–ª'
            }
            
            for pattern, title in url_patterns.items():
                if pattern in url:
                    return title
            
            # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ –ø–∞—Ç—Ç–µ—Ä–Ω–∞—Ö, —Å–æ–∑–¥–∞–µ–º –∏–∑ URL
            url_parts = url.split('/')
            if len(url_parts) > 1:
                product_slug = url_parts[-2] if url_parts[-1] == '' else url_parts[-1]
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º slug –≤ —á–∏—Ç–∞–µ–º–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
                title = product_slug.replace('-', ' ').title()
                return title
        
        raise ValueError(f"Failed to extract title for {url}")
    
    def _extract_specs(self, soup: BeautifulSoup) -> List[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –†–ï–ê–õ–¨–ù–´–ï —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ç–æ–≤–∞—Ä–∞"""
        specs = []
        
        # 1. –°–Ω–∞—á–∞–ª–∞ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∏–∑–≤–ª–µ—á—å –∏–∑ —Ç–∞–±–ª–∏—Ü—ã HTML
        table_specs = self._extract_specs_from_table(soup)
        if table_specs:
            specs.extend(table_specs)
        
        # 2. –ï—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å fallback –º–µ—Ç–æ–¥—ã
        if not specs or len(specs) < 3:
            fallback_specs = self._extract_fallback_specs(soup)
            specs.extend(fallback_specs)
        
        # 3. –ù–ï –¥–æ–±–∞–≤–ª—è–µ–º –≤—ã–¥—É–º–∞–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ - —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ –∏–∑ HTML
        logger.info(f"‚úÖ –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ HTML: {len(specs)} —à—Ç")
        return specs
    
    def _extract_specs_from_table(self, soup: BeautifulSoup) -> List[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ —Ç–æ–≤–∞—Ä–∞ —Å –∂—ë—Å—Ç–∫–∏–º —Ñ–∏–ª—å—Ç—Ä–æ–º"""
        specs = []
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –±–ª–æ–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        specs_selectors = [
            '.product-features table',
            '.product-features .product-features__table', 
            'table.product-features__table',
            '.features table tbody tr',
            '[class*="product-features"]',
            'table tbody tr',
            'table tr',
            '.product-specs table',
            '.specifications table'
        ]
        
        logger.info("üîç –ü–æ–∏—Å–∫ —Ç–∞–±–ª–∏—Ü—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫...")
        
        # –ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–π —Å–µ–ª–µ–∫—Ç–æ—Ä
        features_container = None
        used_selector = None
        for selector in specs_selectors:
            try:
                features_container = soup.select_one(selector)
                if features_container:
                    used_selector = selector
                    logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                    break
            except Exception as e:
                logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª: {e}")
                continue
        
        if not features_container:
            logger.warning("‚ö†Ô∏è –¢–∞–±–ª–∏—Ü–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            return specs
        
        # –ò–∑–≤–ª–µ—á—å –≤—Å–µ —Å—Ç—Ä–æ–∫–∏ —Ç–∞–±–ª–∏—Ü—ã
        rows = features_container.find_all(['tr', 'div'], recursive=True)
        logger.info(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(rows)} —Å—Ç—Ä–æ–∫ –≤ —Ç–∞–±–ª–∏—Ü–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")
        
        for i, row in enumerate(rows):
            # –ü–æ–∏—Å–∫ —è—á–µ–µ–∫ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–æ–π –∏ –∑–Ω–∞—á–µ–Ω–∏–µ–º
            cells = row.find_all(['td', 'th', 'div'], recursive=False)
            
            if len(cells) >= 2:
                label_cell = cells[0]
                value_cell = cells[1]
                
                label = label_cell.get_text(strip=True)
                value = value_cell.get_text(strip=True)
                
                if label and value and len(label) > 2 and len(value) > 0:
                    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞—Ç—å —É–∫—Ä–∞–∏–Ω—Å–∫–∏–µ –Ω–∞–∑–≤–∞–Ω–∏—è –≤ —Ä—É—Å—Å–∫–∏–µ –¥–ª—è –µ–¥–∏–Ω–æ–æ–±—Ä–∞–∑–∏—è
                    label_mapping = {
                        '–¢–∏–ø –∑–∞—Å–æ–±—É –¥–ª—è –¥–µ–ø—ñ–ª—è—Ü—ñ—ó': '–¢–∏–ø —Å—Ä–µ–¥—Å—Ç–≤–∞',
                        '–ó–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è –∑–∞—Å–æ–±—É': '–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ',
                        '–û–±–ª–∞—Å—Ç—å –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è': '–û–±–ª–∞—Å—Ç—å –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è', 
                        '–ì—ñ–ø–æ–∞–ª–µ—Ä–≥–µ–Ω–Ω–æ': '–ì–∏–ø–æ–∞–ª–ª–µ—Ä–≥–µ–Ω–Ω–æ',
                        '–¢–∏–ø —à–∫—ñ—Ä–∏': '–¢–∏–ø –∫–æ–∂–∏',
                        '–¢–∏–ø –≤–æ–ª–æ—Å—Å—è': '–¢–∏–ø –≤–æ–ª–æ—Å',
                        '–ü—Ä–∏–∑–Ω–∞—á–µ–Ω–Ω—è —ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç',
                        '–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –∫–æ—Å–º–µ—Ç–∏—á–Ω–æ–≥–æ –∑–∞—Å–æ–±—É': '–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å—Ä–µ–¥—Å—Ç–≤–∞'
                    }
                    
                    # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–≤–æ–¥—ã –∏–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
                    final_label = label_mapping.get(label, label)
                    specs.append({'label': final_label, 'value': value})
                    logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞: {final_label} = {value}")
                else:
                    logger.debug(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {i}: label='{label}', value='{value}'")
            else:
                logger.debug(f"‚ö†Ô∏è –°—Ç—Ä–æ–∫–∞ {i} —Å–æ–¥–µ—Ä–∂–∏—Ç {len(cells)} —è—á–µ–µ–∫, –Ω—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 2")
        
        # –ñ—ë—Å—Ç–∫–∏–π —Ñ–∏–ª—å—Ç—Ä: —É–¥–∞–ª—è–µ–º –ª—é–±—ã–µ –∑–∞–≥–ª—É—à–∫–∏ –∏–ª–∏ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
        filtered_specs = []
        ban_values = {"–∑–∞–≥–ª—É—à–∫–∞", "unknown", "–Ω–µ —É–∫–∞–∑–∞–Ω–æ", "–Ω/–¥", "n/a", "—É–∫–∞–∑–∞–Ω–æ –Ω–∞ —É–ø–∞–∫–æ–≤–∫–µ", "—Å–æ–≥–ª–∞—Å–Ω–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"}
        for spec in specs:
            label = spec.get('label', '')
            value = spec.get('value', '')
            
            if value.lower() not in ban_values and label and value:
                filtered_specs.append(spec)
            else:
                logger.warning(f"üö´ –£–¥–∞–ª–µ–Ω–∞ –∑–∞–≥–ª—É—à–∫–∞ –≤ RealFactsExtractor: {label}: {value}")
        
        logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(filtered_specs)} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã (–ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏)")
        return filtered_specs
    
    def _extract_fallback_specs(self, soup: BeautifulSoup) -> List[Dict[str, str]]:
        """Fallback –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –µ—Å–ª–∏ —Ç–∞–±–ª–∏—Ü–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞"""
        specs = []
        
        # 1. –ò–∑–≤–ª–µ–∫–∞–µ–º –æ–±—ä—ë–º –∏–∑ —Ç–µ–∫—Å—Ç–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        volume_spec = self._extract_volume_spec(soup)
        if volume_spec:
            specs.append(volume_spec)
        
        # 2. –ò–∑–≤–ª–µ–∫–∞–µ–º –∞—Ä–æ–º–∞—Ç –∏–∑ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞
        scent_spec = self._extract_scent_spec(soup)
        if scent_spec:
            specs.append(scent_spec)
        
        # 3. –ò–∑–≤–ª–µ–∫–∞–µ–º –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞
        purpose_spec = self._extract_purpose_spec(soup)
        if purpose_spec:
            specs.append(purpose_spec)
        
        # 4. –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–∏–ø –∫–æ–∂–∏ –∏–∑ –æ–ø–∏—Å–∞–Ω–∏—è
        skin_type_spec = self._extract_skin_type_spec(soup)
        if skin_type_spec:
            specs.append(skin_type_spec)
        
        return specs
    
    def _extract_volume_spec(self, soup: BeautifulSoup) -> Optional[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±—ä—ë–º —Ç–æ–≤–∞—Ä–∞"""
        # –ò—â–µ–º –≤ —Ç–µ–∫—Å—Ç–µ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        text_content = soup.get_text()
        volume_match = re.search(r'(\d+(?:\.\d+)?)\s*(?:ml|–º–ª|–≥—Ä–∞–º|hram|g)', text_content, re.IGNORECASE)
        if volume_match:
            value = volume_match.group(1)
            unit = volume_match.group(0).split(value)[1].strip()
            if 'ml' in unit or '–º–ª' in unit:
                return {'label': '–û–±—ä—ë–º', 'value': f"{value} –º–ª"}
            elif 'g' in unit or '–≥—Ä–∞–º' in unit or 'hram' in unit:
                return {'label': '–í–µ—Å', 'value': f"{value} –≥"}
        return None
    
    def _extract_scent_spec(self, soup: BeautifulSoup) -> Optional[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—Ä–æ–º–∞—Ç —Ç–æ–≤–∞—Ä–∞"""
        text_content = soup.get_text().lower()
        scent_patterns = {
            '–ö–æ–∫–æ—Å': ['–∫–æ–∫–æ—Å', 'coconut', 'kokos'],
            'Vetiver': ['vetiver', '–≤–µ—Ç–∏–≤–µ—Ä'],
            'Aqua Blue': ['aqua blue', '–∞–∫–≤–∞ –±–ª—é'],
            '–ë–µ–ª—ã–π —á–∞–π': ['–±–µ–ª—ã–π —á–∞–π', 'white tea', 'bilyi chai'],
            '–ú–æ—Ä—Å–∫–∞—è —Å–æ–ª—å': ['–º–æ—Ä—Å–∫–∞—è —Å–æ–ª—å', 'sea salt', 'morska sil']
        }
        
        for scent_name, patterns in scent_patterns.items():
            for pattern in patterns:
                if pattern in text_content:
                    return {'label': '–ê—Ä–æ–º–∞—Ç', 'value': scent_name}
        return None
    
    def _extract_purpose_spec(self, soup: BeautifulSoup) -> Optional[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞"""
        text_content = soup.get_text().lower()
        
        if '–≥–µ–ª—å-–¥–ª—è-–¥—É—à–∞' in text_content or '–≥–µ–ª—å –¥–ª—è –¥—É—à–∞' in text_content:
            return {'label': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ', 'value': '–û—á–∏—â–µ–Ω–∏–µ –∏ —É–≤–ª–∞–∂–Ω–µ–Ω–∏–µ –∫–æ–∂–∏'}
        elif '–ø—É–¥—Ä–∞' in text_content or '–ø–æ—Ä–æ—à–æ–∫' in text_content:
            return {'label': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ', 'value': '–ü–∏–ª–∏–Ω–≥ –∏ –æ—Ç—à–µ–ª—É—à–∏–≤–∞–Ω–∏–µ'}
        elif '–ø—ñ–Ω–∫–∞' in text_content or '–ø–µ–Ω–∫–∞' in text_content:
            return {'label': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ', 'value': '–ú—è–≥–∫–æ–µ –æ—á–∏—â–µ–Ω–∏–µ'}
        elif '—Ñ–ª—é–∏–¥' in text_content or 'fluid' in text_content:
            return {'label': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ', 'value': '–£—Ö–æ–¥ –∑–∞ –∫–æ–∂–µ–π –ø–æ—Å–ª–µ –¥–µ–ø–∏–ª—è—Ü–∏–∏'}
        
        return {'label': '–ù–∞–∑–Ω–∞—á–µ–Ω–∏–µ', 'value': '–ö–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π —É—Ö–æ–¥'}
    
    def _extract_skin_type_spec(self, soup: BeautifulSoup) -> Optional[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∏–ø –∫–æ–∂–∏"""
        text_content = soup.get_text().lower()
        
        if '–∂–∏—Ä–Ω–æ–π' in text_content and '–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–æ–π' in text_content:
            return {'label': '–¢–∏–ø –∫–æ–∂–∏', 'value': '–ñ–∏—Ä–Ω–∞—è –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è'}
        elif '—Å—É—Ö–æ–π' in text_content and '–Ω–æ—Ä–º–∞–ª—å–Ω–æ–π' in text_content:
            return {'label': '–¢–∏–ø –∫–æ–∂–∏', 'value': '–°—É—Ö–∞—è –∏ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è'}
        elif '–≤—Å–µ—Ö —Ç–∏–ø–æ–≤' in text_content or '–≤—Å—ñ—Ö —Ç–∏–ø—ñ–≤' in text_content:
            return {'label': '–¢–∏–ø –∫–æ–∂–∏', 'value': '–í—Å–µ —Ç–∏–ø—ã'}
        
        return {'label': '–¢–∏–ø –∫–æ–∂–∏', 'value': '–í—Å–µ —Ç–∏–ø—ã'}
    
    def _extract_from_url(self, url: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ URL"""
        info = {}
        
        if not url:
            return info
        
        # –ò—â–µ–º –æ–±—ä–µ–º/–≤–µ—Å –≤ URL
        for pattern in self.volume_patterns:
            match = re.search(pattern, url, re.IGNORECASE)
            if match:
                value = match.group(1)
                unit = match.group(2)
                if '–º–ª' in unit or 'ml' in unit:
                    info['volume'] = f"{value} –º–ª"
                elif '–≥' in unit or 'g' in unit or 'hram' in unit:
                    info['weight'] = f"{value} –≥"
                break
        
        return info
    
    def _determine_product_type(self, title: str, url: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞"""
        text_to_check = f"{title} {url}".lower()
        
        for product_type, keywords in self.product_type_patterns.items():
            for keyword in keywords:
                if keyword in text_to_check:
                    return product_type
        
        return "–∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ"
    
    def _extract_image(self, soup: BeautifulSoup) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞"""
        # –ò—â–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ –≤ —Ä–∞–∑–Ω—ã—Ö –º–µ—Å—Ç–∞—Ö
        img_selectors = [
            '.product-photo img',
            '.product-image img', 
            '.main-image img',
            '.product-gallery img',
            'img[alt*="—Ç–æ–≤–∞—Ä"]',
            'img[alt*="product"]',
            'img[src*="product"]',
            'img[src*="—Ç–æ–≤–∞—Ä"]'
        ]
        
        for selector in img_selectors:
            img = soup.select_one(selector)
            if img and img.get('src'):
                src = img.get('src')
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ URL
                if src.startswith('/'):
                    src = f"https://prorazko.com{src}"
                elif not src.startswith('http'):
                    src = f"https://prorazko.com/{src}"
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
                if any(ext in src.lower() for ext in ['.jpg', '.jpeg', '.png', '.webp']):
                    return src
        
        # Fallback: –≥–µ–Ω–µ—Ä–∏—Ä—É–µ–º URL –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞
        return self._generate_fallback_image_url(soup)
    
    def _generate_fallback_image_url(self, soup: BeautifulSoup) -> str:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç fallback URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        text_content = soup.get_text().lower()
        
        if '–≥–µ–ª—å-–¥–ª—è-–¥—É—à–∞' in text_content or '–≥–µ–ª—å –¥–ª—è –¥—É—à–∞' in text_content:
            return "https://prorazko.com/content/images/gel-dlya-dusha.webp"
        elif '–ø—É–¥—Ä–∞' in text_content or '–ø–æ—Ä–æ—à–æ–∫' in text_content:
            return "https://prorazko.com/content/images/pudra-enzymna.webp"
        elif '–ø—ñ–Ω–∫–∞' in text_content or '–ø–µ–Ω–∫–∞' in text_content:
            return "https://prorazko.com/content/images/pinka.webp"
        elif '—Ñ–ª—é–∏–¥' in text_content or 'fluid' in text_content:
            return "https://prorazko.com/content/images/fluid.webp"
        else:
            return "https://prorazko.com/content/images/epilax-product.webp"
    
    def _validate_extracted_facts(self, facts: Dict[str, Any]) -> bool:
        """
        –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤
        """
        try:
            # –ö–†–ò–¢–ò–ß–ù–û: –õ–æ–≥–∏—Ä—É–µ–º —á—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º
            logger.info(f"üîç –í–ê–õ–ò–î–ê–¶–ò–Ø: –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–∫—Ç—ã")
            logger.info(f"üîç –í–ê–õ–ò–î–ê–¶–ò–Ø: –°—Ç—Ä—É–∫—Ç—É—Ä–∞ facts: {list(facts.keys())}")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ
            title = facts.get('title', '')
            if not title or len(title.strip()) < 5:
                logger.error(f"‚ùå –í–ê–õ–ò–î–ê–¶–ò–Ø: –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞: '{title}'")
                return False
            
            # –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ - –∏—â–µ–º –≤ specs!
            characteristics = facts.get('specs', {})  # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –≤ specs!
            
            # –õ–û–ì–ò–†–£–ï–ú –î–õ–Ø –û–¢–õ–ê–î–ö–ò
            logger.info(f"üîç –í–ê–õ–ò–î–ê–¶–ò–Ø: –¢–∏–ø characteristics: {type(characteristics)}")
            logger.info(f"üîç –í–ê–õ–ò–î–ê–¶–ò–Ø: –°–æ–¥–µ—Ä–∂–∏–º–æ–µ characteristics: {characteristics}")
            
            # –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê
            if isinstance(characteristics, dict):
                char_count = len(characteristics)
            elif isinstance(characteristics, list):
                char_count = len(characteristics)
            else:
                char_count = 0
            
            logger.info(f"üîç –í–ê–õ–ò–î–ê–¶–ò–Ø: –ù–∞–π–¥–µ–Ω–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {char_count}")
            
            # –°–ú–Ø–ì–ß–ï–ù–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: 1 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –≤–º–µ—Å—Ç–æ 3
            if char_count < 1:
                logger.error(f"‚ùå –í–ê–õ–ò–î–ê–¶–ò–Ø: –ù–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤–æ–æ–±—â–µ")
                return False
            elif char_count < 3:
                logger.warning(f"‚ö†Ô∏è –í–ê–õ–ò–î–ê–¶–ò–Ø: –ú–∞–ª–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ ({char_count}), –Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
            
            # –í–°–ï–ì–î–ê –≤–æ–∑–≤—Ä–∞—â–∞–µ–º True –µ—Å–ª–∏ –µ—Å—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ —Ö–æ—Ç—å 1 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞
            logger.info(f"‚úÖ –í–ê–õ–ò–î–ê–¶–ò–Ø: –ü—Ä–æ–π–¥–µ–Ω–∞! –ù–∞–∑–≤–∞–Ω–∏–µ='{title}', —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫={char_count}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –í–ê–õ–ò–î–ê–¶–ò–Ø: –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ñ–∞–∫—Ç–æ–≤: {e}")
            return False
