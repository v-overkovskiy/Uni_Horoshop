import asyncio
import requests
from bs4 import BeautifulSoup
from typing import List, Dict, Tuple
import logging
from .characteristics_translator import CharacteristicsTranslator
from ..validation.language_validator import LanguageValidator

logger = logging.getLogger(__name__)

class UnifiedParser:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–π –ø–∞—Ä—Å–µ—Ä –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ RU –∏ UA –≤–µ—Ä—Å–∏–π.
    –†–∞–±–æ—Ç–∞–µ—Ç –±–µ–∑ —Å–ª–æ–≤–∞—Ä–µ–π –∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–∏—Ö –ø—Ä–∞–≤–∏–ª, –∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –∫ –ª—é–±–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–µ HTML.
    """
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })
        self.translator = CharacteristicsTranslator()
        self.language_validator = LanguageValidator()
        
        # –ö–µ—à –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        self._parse_cache = {}  # URL ‚Üí parsed_data
        self._characteristics_cache = {}  # URL ‚Üí characteristics
        self._cache_hits = 0
        self._cache_misses = 0
    
    async def fetch_html(self, ua_url: str) -> Tuple[str, str]:
        """
        –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∑–∞–≥—Ä—É–∂–∞–µ—Ç UA –∏ RU –≤–µ—Ä—Å–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã (–∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –±–µ–∑ –∑–∞–¥–µ—Ä–∂–µ–∫).
        
        Args:
            ua_url: URL —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            
        Returns:
            Tuple[ua_html, ru_html]: HTML –∫–æ–Ω—Ç–µ–Ω—Ç –æ–±–µ–∏—Ö –≤–µ—Ä—Å–∏–π
        """
        ru_url = ua_url.replace('https://prorazko.com/', 'https://prorazko.com/ru/')

        async def get_html(url: str) -> str:
            try:
                loop = asyncio.get_running_loop()
                resp = await loop.run_in_executor(None, lambda: requests.get(url, timeout=10))
                return resp.text if resp.ok else ''
            except Exception as e:
                logger.warning(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
                return ''

        ua_html, ru_html = await asyncio.gather(
            get_html(ua_url),
            get_html(ru_url)
        )
        return ua_html, ru_html

    def parse_bundle(self, ua_html: str, ru_html: str) -> List[str]:
        """
        –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø–∞—Ä—Å–∏—Ç '—Å–æ—Å—Ç–∞–≤ –Ω–∞–±–æ—Ä–∞' —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ–¥–Ω–æ–∑–Ω–∞—á–Ω–æ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –æ–±–µ–∏—Ö –≤–µ—Ä—Å–∏—è—Ö.
        
        Args:
            ua_html: HTML —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏
            ru_html: HTML —Ä—É—Å—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏
            
        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞–±–æ—Ä–∞ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        """
        soup_ua = BeautifulSoup(ua_html, 'html.parser')
        soup_ru = BeautifulSoup(ru_html, 'html.parser')

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ –º–∞—Ä–∫–µ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å–æ—Å—Ç–∞–≤–∞ –Ω–∞–±–æ—Ä–∞
        ua_markers = ['—Å–∫–ª–∞–¥ –Ω–∞–±–æ—Ä', '–∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü—ñ—è', '—Å–∫–ª–∞–¥ –∫–æ–º–ø–ª–µ–∫—Ç', '—Å–∫–ª–∞–¥ –Ω–∞–±–æ—Ä—É', '–∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü—ñ—è –Ω–∞–±–æ—Ä—É', '—Å–∫–ª–∞–¥']
        ru_markers = ['—Å–æ—Å—Ç–∞–≤ –Ω–∞–±–æ—Ä', '–∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è', '—Å–æ—Å—Ç–∞–≤ –∫–æ–º–ø–ª–µ–∫—Ç', '—Å–æ—Å—Ç–∞–≤ –Ω–∞–±–æ—Ä–∞', '–∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è –Ω–∞–±–æ—Ä–∞', '—Å–æ—Å—Ç–∞–≤']
        
        ua_bundle = self._extract_bundle_list(soup_ua, ua_markers)
        ru_bundle = self._extract_bundle_list(soup_ru, ru_markers)

        # –ñ—ë—Å—Ç–∫–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: —Å–ø–∏—Å–∫–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å, —Å–æ–≤–ø–∞–¥–∞—Ç—å –ø–æ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—é/–¥–ª–∏–Ω–µ –∏ –∏–º–µ—Ç—å ‚â•2 —ç–ª–µ–º–µ–Ω—Ç–∞
        if not ua_bundle or not ru_bundle:
            logger.debug("–°–æ—Å—Ç–∞–≤ –Ω–∞–±–æ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –æ–¥–Ω–æ–π –∏–∑ –≤–µ—Ä—Å–∏–π")
            return []
            
        if len(ua_bundle) < 2 or len(ru_bundle) < 2:
            logger.debug("–°–æ—Å—Ç–∞–≤ –Ω–∞–±–æ—Ä–∞ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ–Ω–µ–µ 2 —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
            return []

        # –°–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ: –ø—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –Ω–∞–±–æ—Ä–æ–≤ (–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏, –±–µ–∑ —Ö–∞—Ä–¥–∫–æ–¥–∞)
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–µ–∫—Å—Ç—ã –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (—É–±–∏—Ä–∞–µ–º —Ä–∞–∑–ª–∏—á–∏—è –≤ —è–∑—ã–∫–µ)
        def normalize_text(text):
            # –£–±–∏—Ä–∞–µ–º —è–∑—ã–∫–æ–≤—ã–µ —Ä–∞–∑–ª–∏—á–∏—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            text_lower = text.lower()
            # –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã
            text_lower = text_lower.replace('–ø—ñ–Ω–∞', '–ø–µ–Ω–∞')
            text_lower = text_lower.replace('–¥–µ–ø—ñ–ª—è—Ü—ñ—ó', '–¥–µ–ø–∏–ª—è—Ü–∏–∏')
            text_lower = text_lower.replace('–Ω–∞–Ω–µ—Å–µ–Ω–Ω—è', '–Ω–∞–Ω–µ—Å–µ–Ω–∏—è')
            text_lower = text_lower.replace('–≤–∏–¥–∞–ª–µ–Ω–Ω—è', '—É–¥–∞–ª–µ–Ω–∏—è')
            text_lower = text_lower.replace('–≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è', '–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è')
            text_lower = text_lower.replace('—ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è', '–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è')
            text_lower = text_lower.replace('–∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è', '–ø–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é')
            text_lower = text_lower.replace('–∑', '–ø–æ')
            return text_lower.strip()
        
        ua_normalized = {normalize_text(item) for item in ua_bundle}
        ru_normalized = {normalize_text(item) for item in ru_bundle}
        
        # –ë–æ–ª–µ–µ –≥–∏–±–∫–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ - –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –º–Ω–æ–∂–µ—Å—Ç–≤
        intersection = ua_normalized.intersection(ru_normalized)
        if len(intersection) < len(ua_normalized) * 0.75:  # –ï—Å–ª–∏ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –º–µ–Ω–µ–µ 75%
            logger.debug(f"–°–æ—Å—Ç–∞–≤ –Ω–∞–±–æ—Ä–∞ –Ω–µ —Å–æ–≤–ø–∞–¥–∞–µ—Ç –º–µ–∂–¥—É –≤–µ—Ä—Å–∏—è–º–∏: UA={ua_normalized}, RU={ru_normalized}")
            return []

        logger.info(f"–ù–∞–π–¥–µ–Ω —Å–æ—Å—Ç–∞–≤ –Ω–∞–±–æ—Ä–∞: {len(ua_bundle)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        return ua_bundle  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º UA-–≤–µ—Ä—Å–∏—é (–ª–æ–∫–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—É—é)

    def _extract_bundle_list(self, soup: BeautifulSoup, markers: List[str]) -> List[str]:
        """
        –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –∏—â–µ—Ç –º–∞—Ä–∫–µ—Ä + —Å–ª–µ–¥—É—é—â–∏–π ul/li, –∞–¥–∞–ø—Ç–∏—Ä—É—è—Å—å –∫ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ.
        
        Args:
            soup: BeautifulSoup –æ–±—ä–µ–∫—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
            markers: –°–ø–∏—Å–æ–∫ –º–∞—Ä–∫–µ—Ä–æ–≤ –¥–ª—è –ø–æ–∏—Å–∫–∞
            
        Returns:
            List[str]: –°–ø–∏—Å–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏–ª–∏ –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
        """
        for tag in soup.find_all(['h2', 'h3', 'strong', 'p', 'div', 'span']):
            text = tag.get_text(strip=True).lower()
            logger.debug(f"–ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–≥: '{text}'")
            if any(marker in text for marker in markers):
                logger.debug(f"–ù–∞–π–¥–µ–Ω –º–∞—Ä–∫–µ—Ä –≤ —Ç–µ–∫—Å—Ç–µ: '{text}'")
                # –ò—â–µ–º –±–ª–∏–∂–∞–π—à–∏–π ul –∏–ª–∏ ol (—Å–ø–∏—Å–æ–∫)
                list_tag = tag.find_next(['ul', 'ol'])
                if list_tag:
                    items = [li.get_text(strip=True) for li in list_tag.find_all('li') if li.get_text(strip=True)]
                    if items:
                        logger.debug(f"–ù–∞–π–¥–µ–Ω —Å–ø–∏—Å–æ–∫ —Å–æ—Å—Ç–∞–≤–∞: {len(items)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
                        return items
        return []

    async def parse_characteristics(self, ua_html: str, ru_html: str) -> Tuple[list, list]:
        """
        –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–∞—Ä—Å–µ—Ä —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫.
        
        Args:
            ua_html: HTML —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏
            ru_html: HTML —Ä—É—Å—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏
            
        Returns:
            Tuple[Dict[str, str], Dict[str, str]]: (ru_specs, ua_specs)
        """
        # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –∫–µ—à–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ HTML
        import hashlib
        cache_key = hashlib.md5(f"{ua_html[:1000]}{ru_html[:1000]}".encode()).hexdigest()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        if cache_key in self._characteristics_cache:
            self._cache_hits += 1
            logger.info(f"‚úÖ –ö–µ—à —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {cache_key[:8]}...")
            return self._characteristics_cache[cache_key]
        
        self._cache_misses += 1
        
        soup_ua = BeautifulSoup(ua_html, 'html.parser')
        soup_ru = BeautifulSoup(ru_html, 'html.parser')

        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ –æ–±–µ–∏—Ö –≤–µ—Ä—Å–∏–π –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ
        specs_ua_raw = self._extract_characteristics_from_html(soup_ua)
        specs_ru_raw = self._extract_characteristics_from_html(soup_ru)

        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ UA: {len(specs_ua_raw)} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")
        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ –∏–∑ RU: {len(specs_ru_raw)} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫")

        # ‚úÖ –í–ö–õ–Æ–ß–ê–ï–ú –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ü–ï–†–ï–í–û–î
        specs_ua_list = [{'label': key, 'value': value} for key, value in specs_ua_raw.items()]
        specs_ru_list = [{'label': key, 'value': value} for key, value in specs_ru_raw.items()]
        
        specs_ua_translated = await self.translator.translate_characteristics_batch(specs_ua_list, 'ua')
        specs_ru_translated = await self.translator.translate_characteristics_batch(specs_ru_list, 'ru')
        
        logger.info(f"‚úÖ RU —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {len(specs_ru_translated)} (–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ LLM)")
        logger.info(f"‚úÖ UA —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {len(specs_ua_translated)} (–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ LLM)")
        
        # –ö–µ—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = (specs_ru_translated, specs_ua_translated)
        self._characteristics_cache[cache_key] = result
        
        logger.info(f"üìä –ö–µ—à —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {self._cache_hits} —Ö–∏—Ç–æ–≤, {self._cache_misses} –º–∏—Å—Å–æ–≤")
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–≤–∞ —Å–ø–∏—Å–∫–∞ —Å–ª–æ–≤–∞—Ä–µ–π (–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏)
        return result

    def _find_ua_value(self, ru_key: str, ru_specs: Dict[str, str], ua_specs: Dict[str, str]) -> str:
        """
        –ù–∞—Ö–æ–¥–∏—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ UA –≤–µ—Ä—Å–∏–∏ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ –∫–ª—é—á–∞.
        
        Args:
            ru_key: –†—É—Å—Å–∫–∏–π –∫–ª—é—á
            ru_specs: –°–ª–æ–≤–∞—Ä—å RU —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
            ua_specs: –°–ª–æ–≤–∞—Ä—å UA —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
            
        Returns:
            str: –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ UA –∏–ª–∏ RU
        """
        # –ú–µ—Ç–æ–¥ 1: –ü—Ä—è–º–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–ª—é—á–µ–π
        if ru_key in ua_specs:
            return ua_specs[ru_key]
        
        # –ú–µ—Ç–æ–¥ 2: –ü–æ–∏—Å–∫ –ø–æ –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–º—É –∫–ª—é—á—É
        translated_key = self.translator.translate(ru_key)
        if translated_key in ua_specs:
            return ua_specs[translated_key]
        
        # –ú–µ—Ç–æ–¥ 3: Fallback –ø–æ –ø–æ—Ä—è–¥–∫—É (–µ—Å–ª–∏ –∫–ª—é—á–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç)
        ru_keys = list(ru_specs.keys())
        ua_values = list(ua_specs.values())
        if ru_key in ru_keys:
            idx = ru_keys.index(ru_key)
            if idx < len(ua_values):
                return ua_values[idx]
        
        # –ú–µ—Ç–æ–¥ 4: –í–æ–∑–≤—Ä–∞—â–∞–µ–º RU –∑–Ω–∞—á–µ–Ω–∏–µ –∫–∞–∫ fallback
        return ru_specs.get(ru_key, "")

    def _extract_characteristics_from_html(self, soup: BeautifulSoup) -> Dict[str, str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –≤—Å–µ –ø–∞—Ä—ã –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ HTML –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫.
        """
        # –ò—â–µ–º —Å–∞–º—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –±–ª–æ–∫ –¥–ª—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        features_block = self._find_features_block(soup)
        if not features_block:
            logger.warning("–ë–ª–æ–∫ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return {}

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–∞—Ä—ã –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ
        pairs = self._extract_key_value_pairs(features_block)
        logger.debug(f"–ù–∞–π–¥–µ–Ω–æ –ø–∞—Ä –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ: {len(pairs)}")
        return pairs

    def _find_features_block(self, soup: BeautifulSoup):
        """
        –ò—â–µ—Ç —Å–∞–º—ã–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –±–ª–æ–∫ –¥–ª—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫.
        –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: div.product_group —Å —Ç–∞–±–ª–∏—Ü–µ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (–∫–∞–∫ –ø–æ–∫–∞–∑–∞–Ω–æ –Ω–∞ —Å–∫—Ä–∏–Ω—à–æ—Ç–µ)
        """
        # –ú–µ—Ç–æ–¥ 1: –ò—â–µ–º div.product_group —Å —Ç–∞–±–ª–∏—Ü–µ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        product_group = soup.select_one('div.product_group')
        if product_group:
            logger.debug("–ù–∞–π–¥–µ–Ω div.product_group")
            # –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤–Ω—É—Ç—Ä–∏ product_group
            table = product_group.find('table')
            if table:
                logger.debug("–ù–∞–π–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –≤–Ω—É—Ç—Ä–∏ product_group")
                return table
            # –ò—â–µ–º ul —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –≤–Ω—É—Ç—Ä–∏ product_group (–Ω–æ –Ω–µ –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ)
            ul = product_group.find('ul')
            if ul:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                li_items = ul.find_all('li')
                if li_items:
                    first_li_text = li_items[0].get_text(strip=True).lower()
                    # –ï—Å–ª–∏ –ø–µ—Ä–≤—ã–π li —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã - —ç—Ç–æ –Ω–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
                    nav_keywords = ['–≥—Ä–Ω', '–æ—Ç–∑—ã–≤', '—Å—Ä–∞–≤–Ω–µ–Ω–∏—é', '—à—Ç', '–Ω–∞–ª–∏—á–∏–∏', '–∞—Ä—Ç–∏–∫—É–ª']
                    if not any(keyword in first_li_text for keyword in nav_keywords):
                        logger.debug("–ù–∞–π–¥–µ–Ω ul —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ –≤–Ω—É—Ç—Ä–∏ product_group")
                        return ul
        
        # –ú–µ—Ç–æ–¥ 2: –ò—â–µ–º —Ç–∞–±–ª–∏—Ü—É —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –Ω–∞–ø—Ä—è–º—É—é
        table_selectors = [
            '.product-features__table',  # –û—Å–Ω–æ–≤–Ω–æ–π —Å–µ–ª–µ–∫—Ç–æ—Ä –ø–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            '.product-features table',
            'table.specs',
            '.characteristics table',
            '.product-specs table'
        ]
        
        for selector in table_selectors:
            table = soup.select_one(selector)
            if table:
                logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–∞ —Ç–∞–±–ª–∏—Ü–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                return table
            else:
                logger.debug(f"‚ùå –°–µ–ª–µ–∫—Ç–æ—Ä {selector} –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ú–µ—Ç–æ–¥ 3: –ò—â–µ–º ul —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ (–Ω–æ –Ω–µ –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ)
        ul_selectors = [
            'ul.specs',
            '.characteristics ul',
            '.product-specs ul'
        ]
        
        for selector in ul_selectors:
            ul = soup.select_one(selector)
            if ul:
                li_items = ul.find_all('li')
                if li_items:
                    first_li_text = li_items[0].get_text(strip=True).lower()
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–æ –Ω–µ –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                    nav_keywords = ['–≥—Ä–Ω', '–æ—Ç–∑—ã–≤', '—Å—Ä–∞–≤–Ω–µ–Ω–∏—é', '—à—Ç', '–Ω–∞–ª–∏—á–∏–∏', '–∞—Ä—Ç–∏–∫—É–ª']
                    if not any(keyword in first_li_text for keyword in nav_keywords):
                        logger.debug(f"–ù–∞–π–¥–µ–Ω ul —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                        return ul
        
        logger.warning("–ë–ª–æ–∫ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –Ω–µ –Ω–∞–π–¥–µ–Ω")
        return None

    def _extract_key_value_pairs(self, container) -> Dict[str, str]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–∞—Ä—ã –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–∞.
        –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã HTML —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –º—É—Å–æ—Ä–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö.
        """
        pairs = {}
        if not container:
            return pairs

        # –°–ø–∏—Å–æ–∫ "–º—É—Å–æ—Ä–Ω—ã—Ö" –∫–ª—é—á–µ–π, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å
        garbage_keywords = [
            '–≥–ª–∞–≤–Ω–∞—è', '—Ç–æ–≤–∞—Ä—ã', '–¥–µ–ø–∏–ª—è—Ü–∏—è', '—à—É–≥–∞—Ä–∏–Ω–≥', '—Å—Ä–µ–¥—Å—Ç–≤–∞', 'epilax',
            '–∫—Ä–µ–º', '–ø–æ—Å–ª–µ', '–¥–µ–ø–∏–ª—è—Ü–∏–∏', '—ç–∫—Å—Ç—Ä–∞–∫—Ç', '–∫–∏–≤–∏', '—Ç–µ—Å—Ç–µ—Ä',
            '–Ω–∞–ª–∏—á–∏–∏', '–∞—Ä—Ç–∏–∫—É–ª', '–æ—Ç–∑—ã–≤', '–≥—Ä–Ω', '—à—Ç', '—Å—Ä–∞–≤–Ω–µ–Ω–∏—é', '–∂–µ–ª–∞–Ω–∏—è',
            '–≤–æ–π–¥–∏—Ç–µ', '—Å–∞–π—Ç', '–¥–æ–±–∞–≤–∏—Ç—å', '—Ç–æ–≤–∞—Ä', '—Å–ø–∏—Å–æ–∫', '–Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–æ–π',
            '—Å–∫–∏–¥–∫–∏', '–∫—É–ø–∏—Ç—å', '—Å—Ä–∞–≤–Ω–µ–Ω–∏–µ', '–∂–µ–ª–∞–Ω–∏—è', '–≤–æ–π–¥–∏—Ç–µ', '—Å–∞–π—Ç',
            '–¥–æ–±–∞–≤–∏—Ç—å', '—Ç–æ–≤–∞—Ä', '—Å–ø–∏—Å–æ–∫', '–Ω–∞–∫–æ–ø–∏—Ç–µ–ª—å–Ω–æ–π', '—Å–∫–∏–¥–∫–∏', '–∫—É–ø–∏—Ç—å'
        ]

        def is_garbage_key(key: str) -> bool:
            """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∫–ª—é—á –º—É—Å–æ—Ä–Ω—ã–º"""
            key_lower = key.lower()
            # –ï—Å–ª–∏ –∫–ª—é—á —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π (–±–æ–ª—å—à–µ 100 —Å–∏–º–≤–æ–ª–æ–≤) - —ç—Ç–æ –º—É—Å–æ—Ä
            if len(key) > 100:
                return True
            # –ï—Å–ª–∏ –∫–ª—é—á —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–≥–æ –º—É—Å–æ—Ä–Ω—ã—Ö —Å–ª–æ–≤
            garbage_count = sum(1 for word in garbage_keywords if word in key_lower)
            if garbage_count >= 3:
                return True
            # –ï—Å–ª–∏ –∫–ª—é—á —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–∞–≤–∏–≥–∞—Ü–∏–æ–Ω–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
            nav_elements = ['–≥–ª–∞–≤–Ω–∞—è', '—Ç–æ–≤–∞—Ä—ã', '–¥–µ–ø–∏–ª—è—Ü–∏—è', '—à—É–≥–∞—Ä–∏–Ω–≥', '—Å—Ä–µ–¥—Å—Ç–≤–∞']
            if any(nav in key_lower for nav in nav_elements):
                return True
            return False

        def is_garbage_value(val: str) -> bool:
            """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –º—É—Å–æ—Ä–Ω—ã–º"""
            val_lower = val.lower()
            # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω–æ–µ (–±–æ–ª—å—à–µ 200 —Å–∏–º–≤–æ–ª–æ–≤) - —ç—Ç–æ –º—É—Å–æ—Ä
            if len(val) > 200:
                return True
            # –ï—Å–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –º–Ω–æ–≥–æ –º—É—Å–æ—Ä–Ω—ã—Ö —Å–ª–æ–≤
            garbage_count = sum(1 for word in garbage_keywords if word in val_lower)
            if garbage_count >= 3:
                return True
            return False

        # –ú–µ—Ç–æ–¥ 1: –¢–∞–±–ª–∏—Ü–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (tr —Å th –∏ td)
        for tr in container.select('tr'):
            cells = tr.find_all(['th', 'td'])
            if len(cells) >= 2:
                key = cells[0].get_text(strip=True).replace(':', '')
                val = cells[1].get_text(strip=True)
                
                # >> –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï: –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç—ã—Ö <<
                formatted_val = ', '.join([v.strip() for v in val.split(',')])
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –º—É—Å–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if (key and formatted_val and key not in pairs and 
                    not is_garbage_key(key) and not is_garbage_value(formatted_val)):
                    pairs[key] = formatted_val

        # –ú–µ—Ç–æ–¥ 2: li —Å span —ç–ª–µ–º–µ–Ω—Ç–∞–º–∏
        for li in container.select('li'):
            spans = li.find_all('span')
            if len(spans) >= 1:
                key = spans[0].get_text(strip=True).replace(':', '')
                # –ó–Ω–∞—á–µ–Ω–∏–µ = –≤–µ—Å—å —Ç–µ–∫—Å—Ç li –º–∏–Ω—É—Å —Ç–µ–∫—Å—Ç –ø–µ—Ä–≤–æ–≥–æ span
                full_text = li.get_text(strip=True)
                key_text = spans[0].get_text(strip=True)
                val = full_text.replace(key_text, '').strip().lstrip(':').strip()
                
                # >> –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï: –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç—ã—Ö <<
                formatted_val = ', '.join([v.strip() for v in val.split(',')])
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –º—É—Å–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if key and formatted_val and not is_garbage_key(key) and not is_garbage_value(formatted_val):
                    pairs[key] = formatted_val

        # –ú–µ—Ç–æ–¥ 3: div —Å –¥–≤—É–º—è —è—á–µ–π–∫–∞–º–∏
        for row in container.select('div'):
            cells = row.find_all(['span', 'div'])
            if len(cells) >= 2:
                key = cells[0].get_text(strip=True).replace(':', '')
                val = cells[1].get_text(strip=True)
                
                # >> –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï: –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç—ã—Ö <<
                formatted_val = ', '.join([v.strip() for v in val.split(',')])
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –º—É—Å–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if (key and formatted_val and key not in pairs and 
                    not is_garbage_key(key) and not is_garbage_value(formatted_val)):
                    pairs[key] = formatted_val

        # –ú–µ—Ç–æ–¥ 3: div —Å –∫–ª–∞—Å—Å–∞–º–∏ product-block__item
        for item in container.select('div.product-block__item, div[class*="block"]'):
            title_elem = item.find(class_=lambda x: x and ('title' in x.lower() or 'label' in x.lower()))
            value_elem = item.find(class_=lambda x: x and ('value' in x.lower() or 'content' in x.lower()))
            
            if title_elem and value_elem:
                key = title_elem.get_text(strip=True).replace(':', '')
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –î–õ–Ø –ü–†–û–ë–ï–õ–û–í: –∏—Å–ø–æ–ª—å–∑—É–µ–º separator –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ–±–µ–ª–æ–≤
                val = value_elem.get_text(separator=', ', strip=True)
                
                # >> –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–û–ï –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï: –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç—ã—Ö <<
                formatted_val = ', '.join([v.strip() for v in val.split(',')])
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –º—É—Å–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if (key and formatted_val and key not in pairs and 
                    not is_garbage_key(key) and not is_garbage_value(formatted_val)):
                    pairs[key] = formatted_val

        # –ú–µ—Ç–æ–¥ 4: Fallback - –ª—é–±–æ–π —Ç–µ–∫—Å—Ç —Å –¥–≤–æ–µ—Ç–æ—á–∏–µ–º (—Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π)
        for elem in container.find_all(['div', 'span', 'p']):
            text = elem.get_text(strip=True)
            if ':' in text and len(text.split(':')) == 2:
                key, val = text.split(':', 1)
                key = key.strip()
                val = val.strip()
                
                # >> –§–û–†–ú–ê–¢–ò–†–û–í–ê–ù–ò–ï: –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–±–µ–ª—ã –ø–æ—Å–ª–µ –∑–∞–ø—è—Ç—ã—Ö <<
                formatted_val = ', '.join([v.strip() for v in val.split(',')])
                
                # –§–∏–ª—å—Ç—Ä—É–µ–º –º—É—Å–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                if (key and formatted_val and key not in pairs and 
                    not is_garbage_key(key) and not is_garbage_value(formatted_val)):
                    pairs[key] = formatted_val

            logger.info(f"‚úÖ –ò–∑–≤–ª–µ—á–µ–Ω–æ {len(pairs)} –ø–∞—Ä –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏")
            if pairs:
                logger.info(f"–ü—Ä–∏–º–µ—Ä—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {list(pairs.items())[:3]}")
            return pairs

    def _parse_characteristics_fallback(self, ua_html: str, ru_html: str) -> Dict[str, str]:
        """Fallback –º–µ—Ç–æ–¥ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º –ø–æ–¥—Ö–æ–¥–æ–º"""
        soup_ua = BeautifulSoup(ua_html, 'html.parser')
        soup_ru = BeautifulSoup(ru_html, 'html.parser')

        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ (–∞–¥–∞–ø—Ç–∏—Ä—É–µ—Ç—Å—è –∫ –∫–ª–∞—Å—Å–∞–º/—Ç–µ–≥–∞–º)
        selectors = [
            'ul.specs li',
            '.characteristics li', 
            'table.specs tr',
            '.specs li',
            '.product-specs li',
            '.specifications li',
            'ul li',
            'table tr'
        ]
        
        ua_items = []
        ru_items = []
        
        for selector in selectors:
            ua_found = soup_ua.select(selector)
            ru_found = soup_ru.select(selector)
            
            if ua_found and ru_found and len(ua_found) >= 2:
                ua_items = ua_found
                ru_items = ru_found
                logger.debug(f"Fallback: –Ω–∞–π–¥–µ–Ω—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–º: {selector}")
                break

        specs = {}
        min_len = min(len(ru_items), len(ua_items))
        
        for i in range(min_len):
            # –ò–∑ RU: –∫–ª—é—á (–ø–µ—Ä–≤—ã–π span/th –∏–ª–∏ —Ç–µ–∫—Å—Ç –¥–æ ':')
            ru_text = ru_items[i].get_text(strip=True)
            ru_key = ru_text.split(':')[0].strip() if ':' in ru_text else ru_text

            # –ò–∑ UA: –∑–Ω–∞—á–µ–Ω–∏–µ (–≤—Ç–æ—Ä–æ–π span/td –∏–ª–∏ —Ç–µ–∫—Å—Ç –ø–æ—Å–ª–µ ':')
            ua_text = ua_items[i].get_text(strip=True)
            ua_val = ua_text.split(':')[-1].strip() if ':' in ua_text else ua_text

            if ru_key and ua_val:
                specs[ru_key] = ua_val  # –ö–ª—é—á –∏–∑ RU, –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ UA

        logger.debug(f"Fallback: –∏–∑–≤–ª–µ—á–µ–Ω–æ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {len(specs)}")
        return specs

    async def parse(self, ua_url: str) -> Dict:
        """
        –ü–∞—Ä—Å–∏–Ω–≥ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤.
        
        Args:
            ua_url: URL —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
            
        Returns:
            Dict: –ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–¥—É–∫—Ç–µ
        """
        cache_key = ua_url
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–µ—à
        if cache_key in self._parse_cache:
            self._cache_hits += 1
            logger.info(f"‚úÖ –ö–µ—à —Ö–∏—Ç: {ua_url}")
            return self._parse_cache[cache_key]
        
        self._cache_misses += 1
        
        # –ü–∞—Ä—Å–∏–º
        ua_html, ru_html = await self.fetch_html(ua_url)
        parsed_data = self.parse_product_info(ua_html, ru_html)
        
        # –ö–µ—à–∏—Ä—É–µ–º
        self._parse_cache[cache_key] = parsed_data
        
        logger.info(f"üìä –ö–µ—à —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {self._cache_hits} —Ö–∏—Ç–æ–≤, {self._cache_misses} –º–∏—Å—Å–æ–≤")
        
        return parsed_data

    def parse_product_info(self, ua_html: str, ru_html: str) -> Dict:
        """
        –ü–æ–ª–Ω—ã–π –ø–∞—Ä—Å–∏–Ω–≥ –ø—Ä–æ–¥—É–∫—Ç–∞: –Ω–∞–∑–≤–∞–Ω–∏–µ, –æ–ø–∏—Å–∞–Ω–∏–µ, —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, —Å–æ—Å—Ç–∞–≤ –Ω–∞–±–æ—Ä–∞.
        
        Args:
            ua_html: HTML —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏
            ru_html: HTML —Ä—É—Å—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏
            
        Returns:
            Dict: –ü–æ–ª–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø—Ä–æ–¥—É–∫—Ç–µ
        """
        soup_ua = BeautifulSoup(ua_html, 'html.parser')
        soup_ru = BeautifulSoup(ru_html, 'html.parser')
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –Ω–∞–∑–≤–∞–Ω–∏—è
        title_ua = self._extract_title(soup_ua)
        title_ru = self._extract_title(soup_ru)
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –æ–ø–∏—Å–∞–Ω–∏—è
        description_ua = self._extract_description(soup_ua)
        description_ru = self._extract_description(soup_ru)
        
        # –ü–∞—Ä—Å–∏–Ω–≥ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏ —Å–æ—Å—Ç–∞–≤–∞
        specs = self.parse_characteristics(ua_html, ru_html)
        bundle = self.parse_bundle(ua_html, ru_html)
        
        return {
            'title_ua': title_ua,
            'title_ru': title_ru,
            'description_ua': description_ua,
            'description_ru': description_ru,
            'specs': specs,
            'bundle': bundle
        }
    
    def _extract_title(self, soup: BeautifulSoup) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞."""
        selectors = ['h1', '.product-title', '.title', '.product-name']
        for selector in selectors:
            title_tag = soup.select_one(selector)
            if title_tag:
                return title_tag.get_text(strip=True)
        return ''
    
    def _extract_description(self, soup: BeautifulSoup) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–æ–¥—É–∫—Ç–∞."""
        selectors = ['.description', '.product-description', '.content', 'p']
        for selector in selectors:
            desc_tag = soup.select_one(selector)
            if desc_tag:
                return desc_tag.get_text(strip=True)
        return ''
    
    async def _translate_title_if_needed(self, title: str, target_locale: str) -> str:
        """
        –ü–µ—Ä–µ–≤–æ–¥–∏—Ç –Ω–∞–∑–≤–∞–Ω–∏–µ –µ—Å–ª–∏ —è–∑—ã–∫–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç
        
        Args:
            title: –ò—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
            target_locale: –¶–µ–ª–µ–≤–∞—è –ª–æ–∫–∞–ª—å ('ru' –∏–ª–∏ 'ua')
            
        Returns:
            str: –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–µ –∏–ª–∏ –∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ
        """
        if not title:
            return title
            
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è
        detected_lang = self.language_validator.detect_language(title)
        logger.info(f"üîç –Ø–∑—ã–∫ –∏—Å—Ö–æ–¥–Ω–æ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏—è: {detected_lang}")
        
        # –ü–µ—Ä–µ–≤–æ–¥–∏–º –µ—Å–ª–∏ —è–∑—ã–∫–∏ –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç
        if target_locale == 'ru' and detected_lang == 'ua':
            logger.info(f"üîÑ –ü–ï–†–ï–í–û–î –ù–ê–ó–í–ê–ù–ò–Ø: UA ‚Üí RU")
            logger.info(f"   –ò—Å—Ö–æ–¥–Ω–æ–µ: {title}")
            
            try:
                translated_title = await self.translator.translate_text(title, target_lang='ru')
                logger.info(f"   –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated_title}")
                
                # ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—é
                if translated_title and len(translated_title) > 0:
                    if translated_title[0].islower():
                        logger.warning(f"‚ö†Ô∏è –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã: {translated_title}")
                        translated_title = translated_title[0].upper() + translated_title[1:]
                        logger.info(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {translated_title}")
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞
                translated_lang = self.language_validator.detect_language(translated_title)
                if translated_lang != 'ru':
                    logger.error(f"‚ùå –ü–µ—Ä–µ–≤–æ–¥ –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é: —è–∑—ã–∫ {translated_lang}")
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è
                    return title
                
                return translated_title
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏—è: {e}")
                return title
                
        elif target_locale == 'ua' and detected_lang == 'ru':
            logger.info(f"üîÑ –ü–ï–†–ï–í–û–î –ù–ê–ó–í–ê–ù–ò–Ø: RU ‚Üí UA")
            logger.info(f"   –ò—Å—Ö–æ–¥–Ω–æ–µ: {title}")
            
            try:
                translated_title = await self.translator.translate_text(title, target_lang='ua')
                logger.info(f"   –ü–µ—Ä–µ–≤–µ–¥–µ–Ω–æ: {translated_title}")
                
                # ‚ö†Ô∏è –ö–†–ò–¢–ò–ß–ù–û: –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏ –∏—Å–ø—Ä–∞–≤–ª—è–µ–º –∫–∞–ø–∏—Ç–∞–ª–∏–∑–∞—Ü–∏—é
                if translated_title and len(translated_title) > 0:
                    if translated_title[0].islower():
                        logger.warning(f"‚ö†Ô∏è –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è —Å –º–∞–ª–µ–Ω—å–∫–æ–π –±—É–∫–≤—ã: {translated_title}")
                        translated_title = translated_title[0].upper() + translated_title[1:]
                        logger.info(f"‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ: {translated_title}")
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞
                translated_lang = self.language_validator.detect_language(translated_title)
                if translated_lang != 'ua':
                    logger.error(f"‚ùå –ü–µ—Ä–µ–≤–æ–¥ –Ω–µ –ø—Ä–æ—à–µ–ª –≤–∞–ª–∏–¥–∞—Ü–∏—é: —è–∑—ã–∫ {translated_lang}")
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –µ—Å–ª–∏ –ø–µ—Ä–µ–≤–æ–¥ –Ω–µ —É–¥–∞–ª—Å—è
                    return title
                
                return translated_title
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–µ—Ä–µ–≤–æ–¥–∞ –Ω–∞–∑–≤–∞–Ω–∏—è: {e}")
                return title
        else:
            logger.info(f"‚úÖ –ù–∞–∑–≤–∞–Ω–∏–µ —É–∂–µ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —è–∑—ã–∫–µ ({detected_lang})")
            return title
    
    async def get_translated_title(self, ua_html: str, ru_html: str, locale: str) -> str:
        """
        –ü–æ–ª—É—á–∞–µ—Ç –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –ª–æ–∫–∞–ª–∏
        
        Args:
            ua_html: HTML —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏
            ru_html: HTML —Ä—É—Å—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏  
            locale: –¶–µ–ª–µ–≤–∞—è –ª–æ–∫–∞–ª—å ('ru' –∏–ª–∏ 'ua')
            
        Returns:
            str: –ù–∞–∑–≤–∞–Ω–∏–µ –Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —è–∑—ã–∫–µ
        """
        if locale == 'ru':
            # –î–ª—è —Ä—É—Å—Å–∫–æ–π –ª–æ–∫–∞–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ä—É—Å—Å–∫—É—é –≤–µ—Ä—Å–∏—é –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º —É–∫—Ä–∞–∏–Ω—Å–∫—É—é
            soup_ru = BeautifulSoup(ru_html, 'html.parser')
            title_ru = self._extract_title(soup_ru)
            
            if title_ru:
                return await self._translate_title_if_needed(title_ru, 'ru')
            else:
                # –ï—Å–ª–∏ —Ä—É—Å—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏ –Ω–µ—Ç, –ø–µ—Ä–µ–≤–æ–¥–∏–º —É–∫—Ä–∞–∏–Ω—Å–∫—É—é
                soup_ua = BeautifulSoup(ua_html, 'html.parser')
                title_ua = self._extract_title(soup_ua)
                return await self._translate_title_if_needed(title_ua, 'ru')
                
        else:  # locale == 'ua'
            # –î–ª—è —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π –ª–æ–∫–∞–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ–º —É–∫—Ä–∞–∏–Ω—Å–∫—É—é –≤–µ—Ä—Å–∏—é –∏–ª–∏ –ø–µ—Ä–µ–≤–æ–¥–∏–º —Ä—É—Å—Å–∫—É—é
            soup_ua = BeautifulSoup(ua_html, 'html.parser')
            title_ua = self._extract_title(soup_ua)
            
            if title_ua:
                return await self._translate_title_if_needed(title_ua, 'ua')
            else:
                # –ï—Å–ª–∏ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–π –≤–µ—Ä—Å–∏–∏ –Ω–µ—Ç, –ø–µ—Ä–µ–≤–æ–¥–∏–º —Ä—É—Å—Å–∫—É—é
                soup_ru = BeautifulSoup(ru_html, 'html.parser')
                title_ru = self._extract_title(soup_ru)
                return await self._translate_title_if_needed(title_ru, 'ua')
