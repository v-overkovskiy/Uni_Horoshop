"""
–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º ProRazko
"""
import logging
from typing import Dict, Any, List

logger = logging.getLogger(__name__)

class SpecsGenerator:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º ProRazko"""
    
    def __init__(self):
        self.universal_specs = {
            'ru': [
                {"label": "–°—Ç—Ä–∞–Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–∞", "value": "–£–∫—Ä–∞–∏–Ω–∞"},
                {"label": "–°—Ä–æ–∫ –≥–æ–¥–Ω–æ—Å—Ç–∏", "value": "24 –º–µ—Å—è—Ü–∞"},
                {"label": "–£—Å–ª–æ–≤–∏—è —Ö—Ä–∞–Ω–µ–Ω–∏—è", "value": "–í —Å—É—Ö–æ–º –ø—Ä–æ—Ö–ª–∞–¥–Ω–æ–º –º–µ—Å—Ç–µ"},
                {"label": "–°–ø–æ—Å–æ–± –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è", "value": "–°–æ–≥–ª–∞—Å–Ω–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏"},
                {"label": "–ü—Ä–æ—Ç–∏–≤–æ–ø–æ–∫–∞–∑–∞–Ω–∏—è", "value": "–ò–Ω–¥–∏–≤–∏–¥—É–∞–ª—å–Ω–∞—è –Ω–µ–ø–µ—Ä–µ–Ω–æ—Å–∏–º–æ—Å—Ç—å"}
            ],
            'ua': [
                {"label": "–ö—Ä–∞—ó–Ω–∞ –≤–∏—Ä–æ–±–Ω–∏—Ü—Ç–≤–∞", "value": "–£–∫—Ä–∞—ó–Ω–∞"},
                {"label": "–¢–µ—Ä–º—ñ–Ω –ø—Ä–∏–¥–∞—Ç–Ω–æ—Å—Ç—ñ", "value": "24 –º—ñ—Å—è—Ü—ñ"},
                {"label": "–£–º–æ–≤–∏ –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è", "value": "–í —Å—É—Ö–æ–º—É –ø—Ä–æ—Ö–æ–ª–æ–¥–Ω–æ–º—É –º—ñ—Å—Ü—ñ"},
                {"label": "–°–ø–æ—Å—ñ–± –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—è", "value": "–ó–≥—ñ–¥–Ω–æ –∑ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—î—é"},
                {"label": "–ü—Ä–æ—Ç–∏–ø–æ–∫–∞–∑–∞–Ω–Ω—è", "value": "–Ü–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∞ –Ω–µ–ø–µ—Ä–µ–Ω–æ—Å–∏–º—ñ—Å—Ç—å"}
            ]
        }
    
    def generate_specs_from_facts(self, product_facts: Dict[str, Any], locale: str) -> List[Dict[str, str]]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¢–û–õ–¨–ö–û –∏–∑ source_facts.
        –ñ–Å–°–¢–ö–û: –±–µ–∑ –¥–æ–±–∞–≤–ª–µ–Ω–∏–π, –∑–∞–≥–ª—É—à–µ–∫ –∏–ª–∏ –≤—ã–¥—É–º–æ–∫!
        """
        try:
            # –°–¢–†–û–ì–ò–ô –†–ï–ñ–ò–ú: –ò—Å–ø–æ–ª—å–∑—É–µ–º –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ HTML
            if 'specs' in product_facts and product_facts['specs']:
                original_specs = product_facts['specs']
                logger.info(f"‚úÖ –°—Ç—Ä–æ–≥–∏–π —Ä–µ–∂–∏–º: –∏—Å–ø–æ–ª—å–∑—É–µ–º {len(original_specs)} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑ HTML")
                
                # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä –ø—Ä–æ—Ç–∏–≤ –∑–∞–≥–ª—É—à–µ–∫
                filtered_specs = self._strict_filter_specs(original_specs)
                
                if len(filtered_specs) != len(original_specs):
                    removed_count = len(original_specs) - len(filtered_specs)
                    logger.warning(f"‚ö†Ô∏è –°—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä —É–¥–∞–ª–∏–ª {removed_count} –∑–∞–≥–ª—É—à–µ–∫")
                
                logger.info(f"‚úÖ –§–∏–Ω–∞–ª—å–Ω–æ: {len(filtered_specs)} —Ä–µ–∞–ª—å–Ω—ã—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –¥–ª—è {locale}")
                return filtered_specs
            
            # –ï—Å–ª–∏ –Ω–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑ HTML - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
            logger.warning("‚ö†Ô∏è –ù–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑ HTML - –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫")
            return []
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å—Ç—Ä–æ–≥–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {e}")
            return []
    
    def _strict_filter_specs(self, specs: List[Dict[str, str]]) -> List[Dict[str, str]]:
        """
        –ñ—ë—Å—Ç–∫–æ —Ñ–∏–ª—å—Ç—Ä—É–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏, —É–¥–∞–ª—è—è –∑–∞–≥–ª—É—à–∫–∏ –∏ –≤—ã–¥—É–º–∫–∏
        """
        filtered_specs = []
        removed_count = 0
        
        for spec in specs:
            label = spec.get('label', '').strip()
            value = spec.get('value', '').strip()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –∑–∞–≥–ª—É—à–∫–∏ –∏ –≤—ã–¥—É–º–∫–∏
            if self._is_placeholder_spec(label, value):
                removed_count += 1
                logger.warning(f"üö´ –£–¥–∞–ª—è–µ–º –∑–∞–≥–ª—É—à–∫—É: {label}: {value}")
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if not label or not value:
                removed_count += 1
                logger.warning(f"üö´ –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—É—é —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É: {label}: {value}")
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ generic –∑–Ω–∞—á–µ–Ω–∏—è
            if self._is_generic_value(value):
                removed_count += 1
                logger.warning(f"üö´ –£–¥–∞–ª—è–µ–º generic –∑–Ω–∞—á–µ–Ω–∏–µ: {label}: {value}")
                continue
            
            filtered_specs.append(spec)
        
        if removed_count > 0:
            logger.info(f"üîí –°—Ç—Ä–æ–≥–∏–π —Ñ–∏–ª—å—Ç—Ä: —É–¥–∞–ª–µ–Ω–æ {removed_count} –∑–∞–≥–ª—É—à–µ–∫, –æ—Å—Ç–∞–ª–æ—Å—å {len(filtered_specs)}")
        
        return filtered_specs
    
    def _is_placeholder_spec(self, label: str, value: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞ –∑–∞–≥–ª—É—à–∫–æ–π"""
        placeholder_patterns = [
            '–∑–∞–≥–ª—É—à–∫–∞', 'placeholder', 'unknown', '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ', '–Ω/–¥', 'n/a',
            '—É–∫–∞–∑–∞–Ω–æ –Ω–∞ —É–ø–∞–∫–æ–≤–∫–µ', '—Å–æ–≥–ª–∞—Å–Ω–æ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏', '–≤ —Å—É—Ö–æ–º –º–µ—Å—Ç–µ',
            '—É–∫—Ä–∞–∏–Ω–∞', '—É–∫—Ä–∞—ó–Ω–∞', 'epilax', '100 –≥', '–∫–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–∏–π —É—Ö–æ–¥', '–≤—Å–µ —Ç–∏–ø—ã'
        ]
        
        label_lower = label.lower()
        value_lower = value.lower()
        
        for pattern in placeholder_patterns:
            if pattern in label_lower or pattern in value_lower:
                return True
        
        return False
    
    def _is_generic_value(self, value: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ generic"""
        generic_values = [
            '–≤—Å–µ —Ç–∏–ø—ã', '—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π', '—Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π', '–æ–±—ã—á–Ω—ã–π',
            '–∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π –ø—Ä–æ–¥—É–∫—Ç', '—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ', '–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π'
        ]
        
        value_lower = value.lower()
        
        for generic in generic_values:
            if generic in value_lower:
                return True
        
        return False
    
    def generate_universal_spec(self, index: int, product_facts: Dict[str, Any], locale: str) -> Dict[str, str]:
        """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—É—é —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫—É"""
        try:
            if index < len(self.universal_specs[locale]):
                return self.universal_specs[locale][index]
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
            additional_specs = {
                'ru': [
                    {"label": "–§–æ—Ä–º–∞ –≤—ã–ø—É—Å–∫–∞", "value": "–ö–æ—Å–º–µ—Ç–∏—á–µ—Å–∫–æ–µ —Å—Ä–µ–¥—Å—Ç–≤–æ"},
                    {"label": "–°–æ—Å—Ç–∞–≤", "value": "–ù–∞—Ç—É—Ä–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"},
                    {"label": "–£–ø–∞–∫–æ–≤–∫–∞", "value": "–ü–ª–∞—Å—Ç–∏–∫–æ–≤–∞—è –±—É—Ç—ã–ª–∫–∞"}
                ],
                'ua': [
                    {"label": "–§–æ—Ä–º–∞ –≤–∏–ø—É—Å–∫—É", "value": "–ö–æ—Å–º–µ—Ç–∏—á–Ω–∏–π –∑–∞—Å—ñ–±"},
                    {"label": "–°–∫–ª–∞–¥", "value": "–ù–∞—Ç—É—Ä–∞–ª—å–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏"},
                    {"label": "–£–ø–∞–∫–æ–≤–∫–∞", "value": "–ü–ª–∞—Å—Ç–∏–∫–æ–≤–∞ –ø–ª—è—à–∫–∞"}
                ]
            }
            
            additional_index = index - len(self.universal_specs[locale])
            if additional_index < len(additional_specs[locale]):
                return additional_specs[locale][additional_index]
            
            return None
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–æ–π —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {e}")
            return None
    
    def _extract_volume_from_url_and_title(self, url: str, title: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –æ–±—ä—ë–º –∏–∑ URL –∏ –Ω–∞–∑–≤–∞–Ω–∏—è"""
        import re
        
        # –ü–æ–∏—Å–∫ –≤ URL
        volume_patterns = [
            r'(\d+(?:\.\d+)?)\s*(?:ml|–º–ª)',
            r'(\d+(?:\.\d+)?)\s*(?:hram|–≥—Ä–∞–º|g)',
            r'(\d+(?:\.\d+)?)\s*(?:gram|–≥—Ä–∞–º–º)'
        ]
        
        for pattern in volume_patterns:
            match = re.search(pattern, url + ' ' + title, re.IGNORECASE)
            if match:
                volume = match.group(1)
                if 'ml' in match.group(0).lower() or '–º–ª' in match.group(0).lower():
                    return f"{volume} –º–ª"
                elif 'hram' in match.group(0).lower() or '–≥—Ä–∞–º' in match.group(0).lower():
                    return f"{volume} –≥"
        
        return None
    
    def _extract_scent_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∞—Ä–æ–º–∞—Ç –∏–∑ URL"""
        scent_mapping = {
            'kokos': '–ö–æ–∫–æ—Å',
            'vetiver': '–í–µ—Ç–∏–≤–µ—Ä', 
            'aqua-blue': '–ê–∫–≤–∞ –ë–ª—é',
            'bilyi-chai': '–ë–µ–ª—ã–π —á–∞–π',
            'morska-sil': '–ú–æ—Ä—Å–∫–∞—è —Å–æ–ª—å'
        }
        
        for pattern, scent in scent_mapping.items():
            if pattern in url.lower():
                return scent
        
        return None
    
    def _extract_purpose_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –Ω–∞–∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ URL"""
        if 'hel-dlia-dushu' in url:
            return '–û—á–∏—â–µ–Ω–∏–µ –∏ —É–≤–ª–∞–∂–Ω–µ–Ω–∏–µ –∫–æ–∂–∏'
        elif 'pudra' in url:
            return '–≠–Ω–∑–∏–º–Ω—ã–π –ø–∏–ª–∏–Ω–≥ –∏ –æ—Ç—à–µ–ª—É—à–∏–≤–∞–Ω–∏–µ'
        elif 'fliuid' in url:
            return '–ü—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏–µ –≤—Ä–∞—Å—Ç–∞–Ω–∏—è –≤–æ–ª–æ—Å'
        elif 'pinka-dlia-intymnoi' in url:
            return '–ò–Ω—Ç–∏–º–Ω–∞—è –≥–∏–≥–∏–µ–Ω–∞'
        elif 'pinka-dlia-ochyshchennia' in url:
            return '–ú—è–≥–∫–æ–µ –æ—á–∏—â–µ–Ω–∏–µ –∫–æ–∂–∏'
        elif 'hel-do-depiliatsii' in url:
            return '–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –¥–µ–ø–∏–ª—è—Ü–∏–∏'
        
        return None
    
    def _extract_product_type_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∏–ø —Å—Ä–µ–¥—Å—Ç–≤–∞ –∏–∑ URL"""
        if 'hel-dlia-dushu' in url:
            return '–ì–µ–ª—å –¥–ª—è –¥—É—à–∞'
        elif 'pudra' in url:
            return '–ü—É–¥—Ä–∞ —ç–Ω–∑–∏–º–Ω–∞—è'
        elif 'fliuid' in url:
            return '–§–ª—é–∏–¥'
        elif 'pinka' in url:
            return '–ü–µ–Ω–∫–∞'
        elif 'hel-do-depiliatsii' in url:
            return '–ì–µ–ª—å –¥–ª—è –¥–µ–ø–∏–ª—è—Ü–∏–∏'
        
        return None
    
    def _extract_skin_type_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ç–∏–ø –∫–æ–∂–∏ –∏–∑ URL"""
        if 'sukhoi-ta-normalnoi' in url:
            return '–°—É—Ö–∞—è –∏ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è'
        elif 'zhyrnoi-ta-kombinovanoi' in url:
            return '–ñ–∏—Ä–Ω–∞—è –∏ –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è'
        else:
            return '–í—Å–µ —Ç–∏–ø—ã –∫–æ–∂–∏'
    
