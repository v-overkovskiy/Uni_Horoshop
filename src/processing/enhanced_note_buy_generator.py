"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä note_buy —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Å–∫–ª–æ–Ω–µ–Ω–∏–µ–º –∏ —à–∞–±–ª–æ–Ω–∞–º–∏
"""
import re
import logging
from typing import Dict, Any, Tuple

logger = logging.getLogger(__name__)

class EnhancedNoteBuyGenerator:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä note_buy —Å —Å–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–º–∏ —à–∞–±–ª–æ–Ω–∞–º–∏ –∏ —Å–∫–ª–æ–Ω–µ–Ω–∏–µ–º"""
    
    def __init__(self):
        # –®–∞–±–ª–æ–Ω—ã –¥–ª—è RU –∏ UA —Å –¥–≤—É–º—è –æ—Ç–¥–µ–ª—å–Ω—ã–º–∏ <strong> —Ç–µ–≥–∞–º–∏
        self.templates = {
            'ru': "–í –Ω–∞—à–µ–º –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–µ ProRazko –º–æ–∂–Ω–æ <strong>–∫—É–ø–∏—Ç—å {np_acc_lowercased_first}</strong> —Å –±—ã—Å—Ç—Ä–æ–π –¥–æ—Å—Ç–∞–≤–∫–æ–π –ø–æ –£–∫—Ä–∞–∏–Ω–µ –∏ –≥–∞—Ä–∞–Ω—Ç–∏–µ–π –∫–∞—á–µ—Å—Ç–≤–∞.",
            'ua': "–£ –Ω–∞—à–æ–º—É —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω—ñ ProRazko –º–æ–∂–Ω–∞ <strong>–∫—É–ø–∏—Ç–∏ {np_acc_lowercased_first}</strong> –∑ —à–≤–∏–¥–∫–æ—é –¥–æ—Å—Ç–∞–≤–∫–æ—é –ø–æ –£–∫—Ä–∞—ó–Ω—ñ —Ç–∞ –≥–∞—Ä–∞–Ω—Ç—ñ—î—é —è–∫–æ—Å—Ç—ñ."
        }
        
        # –ü—Ä–∞–≤–∏–ª–∞ —Å–∫–ª–æ–Ω–µ–Ω–∏—è –¥–ª—è RU (–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã–π –ø–∞–¥–µ–∂)
        self.ru_declension_rules = {
            # –ñ–µ–Ω—Å–∫–∏–π —Ä–æ–¥ –Ω–∞ -–∞—è/-—è—è
            '–∞—è': '—É—é',  # –∞—Ä–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è ‚Üí –∞—Ä–æ–º–∞—Ç–∏—á–µ—Å–∫—É—é
            '—è—è': '—é—é',  # –º–∞—Å—Å–∞–∂–Ω–∞—è ‚Üí –º–∞—Å—Å–∞–∂–Ω—É—é
            # –ü—Ä–æ—Å—Ç—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è
            '–∞': '—É',  # –∫—Ä–∞—Å–æ—Ç–∞ ‚Üí –∫—Ä–∞—Å–æ—Ç—É
            '—è': '—é',  # –∑–µ–º–ª—è ‚Üí –∑–µ–º–ª—é
        }
        
        # –ü—Ä–∞–≤–∏–ª–∞ —Å–∫–ª–æ–Ω–µ–Ω–∏—è –¥–ª—è UA (–∑–Ω–∞—Ö—ñ–¥–Ω–∏–π –≤—ñ–¥–º—ñ–Ω–æ–∫)
        self.ua_declension_rules = {
            # –ñ—ñ–Ω–æ—á–∏–π —Ä—ñ–¥ –Ω–∞ -–∞/-—è
            '–∞': '—É',  # –∞—Ä–æ–º–∞—Ç–∏—á–Ω–∞ ‚Üí –∞—Ä–æ–º–∞—Ç–∏—á–Ω—É
            '—è': '—é',  # –º–∞—Å–∞–∂–Ω–∞ ‚Üí –º–∞—Å–∞–∂–Ω—É
            # –í–∏–Ω—è—Ç–∫–∏ –¥–ª—è —Å–∫–ª–∞–¥–Ω–∏—Ö –≤–∏–ø–∞–¥–∫—ñ–≤
            '–∞—è': '—É—é',  # –∫—Ä–∞—Å–∏–≤–∞ ‚Üí –∫—Ä–∞—Å–∏–≤—É
            '—è—è': '—é—é',  # —Å–∏–Ω—è ‚Üí —Å–∏–Ω—é
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–æ–¥–∞ –∏ —Å–∫–ª–æ–Ω–µ–Ω–∏—è
        self.gender_patterns = {
            'ru': {
                'feminine': [r'–∞—è\b', r'—è—è\b', r'–∞\b', r'—è\b'],
                'masculine': [r'—ã–π\b', r'–∏–π\b', r'–æ–π\b', r'—ã–π\b'],
                'neuter': [r'–æ–µ\b', r'–µ–µ\b', r'–æ–µ\b']
            },
            'ua': {
                'feminine': [r'–∞\b', r'—è\b'],
                'masculine': [r'–∏–π\b', r'–∏–π\b'],
                'neuter': [r'–µ\b', r'–µ\b']
            }
        }

    def generate_enhanced_note_buy(self, title: str, locale: str) -> Dict[str, Any]:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —É–ª—É—á—à–µ–Ω–Ω—ã–π note_buy —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º —Å–∫–ª–æ–Ω–µ–Ω–∏–µ–º –∏ –Ω–æ–≤—ã–º —à–∞–±–ª–æ–Ω–æ–º
        """
        logger.info(f"üîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ note_buy –¥–ª—è {locale}")
        
        if not title or not title.strip():
            return {
                'content': '',
                'has_kupit_kupyty': False,
                'declined': False,
                'two_strongs': False,
                'first_char_lowered': False,
                'declension_debug': {
                    'first_adj': '',
                    'first_noun': '',
                    'rules_applied': []
                },
                'lowercase_debug': {
                    'position': -1,
                    'original_char': '',
                    'lowercased_char': ''
                }
            }
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –ø–µ—Ä–≤–æ–µ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ –∏ –ø–µ—Ä–≤–æ–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ
        first_adj, first_noun = self._extract_first_words(title)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å–∫–ª–æ–Ω–µ–Ω–∏–µ
        declined_title, declension_info = self._apply_declension(title, first_adj, first_noun, locale)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø–æ–Ω–∏–∂–µ–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ —Å–∏–º–≤–æ–ª–∞
        np_acc_lowercased_first, lowercase_debug = self._lowercase_first_grapheme(declined_title)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å –Ω–æ–≤—ã–º —à–∞–±–ª–æ–Ω–æ–º
        template = self.templates[locale]
        content = template.format(np_acc_lowercased_first=np_acc_lowercased_first)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ "–∫—É–ø–∏—Ç—å/–∫—É–ø–∏—Ç–∏" –∏ –æ–¥–Ω–æ–≥–æ <strong> —Ç–µ–≥–∞
        has_kupit = '–∫—É–ø–∏—Ç—å' in content if locale == 'ru' else '–∫—É–ø–∏—Ç–∏' in content
        single_strong = content.count('<strong>') == 1
        first_char_lowered = lowercase_debug['position'] >= 0
        
        return {
            'content': content,
            'has_kupit_kupyty': has_kupit,
            'declined': declension_info['rules_applied'],
            'single_strong': single_strong,
            'range_from': '–∫—É–ø–∏—Ç—å' if locale == 'ru' else '–∫—É–ø–∏—Ç–∏',
            'range_to': 'end_of_product_name',
            'first_char_lowered': first_char_lowered,
            'declension_debug': {
                'first_adj': first_adj,
                'first_noun': first_noun,
                'rules_applied': declension_info['rules_applied']
            },
            'lowercase_debug': lowercase_debug
        }

    def _extract_first_words(self, title: str) -> Tuple[str, str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø–µ—Ä–≤–æ–µ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ –∏ –ø–µ—Ä–≤–æ–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ"""
        words = title.split()
        
        first_adj = ''
        first_noun = ''
        
        for i, word in enumerate(words):
            # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–æ –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
            clean_word = re.sub(r'[^\w]', '', word)
            
            if not clean_word:
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª–æ–∫–∞–ª—å –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
            locale = 'ru' if any(char in title for char in '—ã—ä—å—ç') else 'ua'
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–º
            if self._is_adjective(clean_word, locale):
                if not first_adj:
                    first_adj = clean_word
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º
            elif self._is_noun(clean_word, locale):
                if not first_noun:
                    first_noun = clean_word
                    break  # –ë–µ—Ä–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤–æ–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ
        
        return first_adj, first_noun

    def _is_adjective(self, word: str, locale: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–º"""
        # –ò—Å–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥–ª–æ–≥–∏ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
        excluded_words = ['–¥–ª—è', '–ø–æ', '–Ω–∞', '–≤', '—Å', '–æ—Ç', '–¥–æ', '–∑–∞', '–ø–æ–¥', '–Ω–∞–¥', '–ø—Ä–∏', '–±–µ–∑', '–∏–∑', '–∫', '–æ', '–æ–±', '–ø—Ä–æ', '—Å–æ', '–≤–æ']
        if word.lower() in excluded_words:
            return False
        
        if locale == 'ru':
            # –†—É—Å—Å–∫–∏–µ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ
            adjective_endings = ['—ã–π', '–∏–π', '–æ–π', '–∞—è', '—è—è', '–æ–µ', '–µ–µ']
        else:
            # –£–∫—Ä–∞–∏–Ω—Å–∫–∏–µ –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω—ã–µ
            adjective_endings = ['–∏–π', '–∞', '—è', '–µ', '–µ']
        
        return any(word.endswith(ending) for ending in adjective_endings)

    def _is_noun(self, word: str, locale: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–º"""
        # –ò—Å–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥–ª–æ–≥–∏ –∏ —Å–ª—É–∂–µ–±–Ω—ã–µ —Å–ª–æ–≤–∞
        excluded_words = ['–¥–ª—è', '–ø–æ', '–Ω–∞', '–≤', '—Å', '–æ—Ç', '–¥–æ', '–∑–∞', '–ø–æ–¥', '–Ω–∞–¥', '–ø—Ä–∏', '–±–µ–∑', '–∏–∑', '–∫', '–æ', '–æ–±', '–ø—Ä–æ', '—Å–æ', '–≤–æ']
        if word.lower() in excluded_words:
            return False
        
        if locale == 'ru':
            # –†—É—Å—Å–∫–∏–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ
            noun_endings = ['–∞', '—è', '–æ', '–µ', '—å', '–∏', '—ã']
        else:
            # –£–∫—Ä–∞–∏–Ω—Å–∫–∏–µ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ
            noun_endings = ['–∞', '—è', '–æ', '–µ', '—å', '–∏', '–∏']
        
        return any(word.endswith(ending) for ending in noun_endings)

    def _apply_declension(self, title: str, first_adj: str, first_noun: str, locale: str) -> Tuple[str, Dict[str, Any]]:
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç —Å–∫–ª–æ–Ω–µ–Ω–∏–µ –∫ –∑–∞–≥–æ–ª–æ–≤–∫—É —Å –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ª–µ–º–º—ã"""
        if not first_adj and not first_noun:
            return title, {'rules_applied': []}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω—É–∂–Ω–æ –ª–∏ —Å–∫–ª–æ–Ω—è—Ç—å
        if not self._should_decline(first_adj, first_noun, locale):
            return title, {'rules_applied': []}
        
        words = title.split()
        rules_applied = []
        
        # –°–∫–ª–æ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –¥–≤–∞ —Å–ª–æ–≤–∞ (–ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ + —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ)
        # —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ª–µ–º–º—ã
        for i, word in enumerate(words[:2]):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –ø–µ—Ä–≤—ã–º–∏ –¥–≤—É–º—è —Å–ª–æ–≤–∞–º–∏
            clean_word = re.sub(r'[^\w]', '', word)
            
            if not clean_word:
                continue
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–ª–æ–≤–∞
            is_adj = self._is_adjective(clean_word, locale)
            is_noun = self._is_noun(clean_word, locale)
            
            if (is_adj or is_noun) and self._is_feminine(clean_word, locale):
                if is_adj:
                    declined_word = self._decline_adjective(clean_word, locale)
                    word_type = 'adj'
                else:
                    declined_word = self._decline_noun(clean_word, locale)
                    word_type = 'noun'
                
                if declined_word != clean_word:
                    # –ó–∞–º–µ–Ω—è–µ–º —Å–ª–æ–≤–æ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º —Ç–µ–∫—Å—Ç–µ, —Å–æ—Ö—Ä–∞–Ω—è—è –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
                    original_word = words[i]
                    # –ù–∞—Ö–æ–¥–∏–º –ø–æ–∑–∏—Ü–∏—é —á–∏—Å—Ç–æ–≥–æ —Å–ª–æ–≤–∞ –≤ –∏—Å—Ö–æ–¥–Ω–æ–º
                    clean_start = original_word.find(clean_word)
                    if clean_start >= 0:
                        # –ó–∞–º–µ–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —á–∏—Å—Ç—É—é —á–∞—Å—Ç—å, —Å–æ—Ö—Ä–∞–Ω—è—è –∑–Ω–∞–∫–∏ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
                        new_word = original_word[:clean_start] + declined_word + original_word[clean_start + len(clean_word):]
                        words[i] = new_word
                        rules_applied.append(f'{word_type}_{clean_word}‚Üí{declined_word}')
        
        return ' '.join(words), {'rules_applied': rules_applied}

    def _should_decline(self, first_adj: str, first_noun: str, locale: str) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ —Å–∫–ª–æ–Ω—è—Ç—å —Å–ª–æ–≤–∞"""
        # –°–∫–ª–æ–Ω—è–µ–º –µ—Å–ª–∏ –µ—Å—Ç—å –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ –∂–µ–Ω—Å–∫–æ–≥–æ —Ä–æ–¥–∞
        adj_feminine = self._is_feminine(first_adj, locale) if first_adj else False
        noun_feminine = self._is_feminine(first_noun, locale) if first_noun else False
        
        # –°–∫–ª–æ–Ω—è–µ–º –µ—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ —Å–ª–æ–≤–æ –∂–µ–Ω—Å–∫–æ–≥–æ —Ä–æ–¥–∞
        return adj_feminine or noun_feminine

    def _is_feminine(self, word: str, locale: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–æ–≤–æ –∂–µ–Ω—Å–∫–æ–≥–æ —Ä–æ–¥–∞"""
        patterns = self.gender_patterns[locale]['feminine']
        
        for pattern in patterns:
            if re.search(pattern, word):
                return True
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª—è —Å–ª–æ–≤, –∑–∞–∫–∞–Ω—á–∏–≤–∞—é—â–∏—Ö—Å—è –Ω–∞ -–∞, -—è
        if word.endswith(('–∞', '—è')):
            return True
        
        return False

    def _decline_adjective(self, adj: str, locale: str) -> str:
        """–°–∫–ª–æ–Ω—è–µ—Ç –ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ"""
        rules = self.ru_declension_rules if locale == 'ru' else self.ua_declension_rules
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–∞–≤–∏–ª–∞ —Å–∫–ª–æ–Ω–µ–Ω–∏—è –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è –¥–ª–∏–Ω—ã –æ–∫–æ–Ω—á–∞–Ω–∏—è
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω–Ω—ã–µ –æ–∫–æ–Ω—á–∞–Ω–∏—è, –ø–æ—Ç–æ–º –∫–æ—Ä–æ—Ç–∫–∏–µ
        sorted_rules = sorted(rules.items(), key=lambda x: len(x[0]), reverse=True)
        
        for ending, replacement in sorted_rules:
            if adj.endswith(ending):
                return adj[:-len(ending)] + replacement
        
        return adj

    def _decline_noun(self, noun: str, locale: str) -> str:
        """–°–∫–ª–æ–Ω—è–µ—Ç —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ"""
        # –î–ª—è —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã—Ö –∂–µ–Ω—Å–∫–æ–≥–æ —Ä–æ–¥–∞ –Ω–∞ -–∞/-—è
        if locale == 'ru':
            if noun.endswith('–∞'):
                return noun[:-1] + '—É'
            elif noun.endswith('—è'):
                return noun[:-1] + '—é'
        else:  # ua
            if noun.endswith('–∞'):
                return noun[:-1] + '—É'
            elif noun.endswith('—è'):
                return noun[:-1] + '—é'
        
        return noun

    def _lowercase_first_grapheme(self, text: str) -> Tuple[str, Dict[str, Any]]:
        """
        –ü—Ä–∏–≤–æ–¥–∏—Ç –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π –±—É–∫–≤–µ–Ω–Ω—ã–π —Å–∏–º–≤–æ–ª
        """
        if not text:
            return text, {'position': -1, 'original_char': '', 'lowercased_char': ''}
        
        # –ò—â–µ–º –ø–µ—Ä–≤—ã–π –±—É–∫–≤–µ–Ω–Ω—ã–π —Å–∏–º–≤–æ–ª (–∫–∏—Ä–∏–ª–ª–∏—Ü–∞/–ª–∞—Ç–∏–Ω–∏—Ü–∞)
        for i, char in enumerate(text):
            if char.isalpha():
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ –±—Ä–µ–Ω–¥–æ–º (–ª–∞—Ç–∏–Ω–∏—Ü–∞ –≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ)
                if char.isupper() and char.isascii():
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —ç—Ç–æ —á–∞—Å—Ç—å—é –±—Ä–µ–Ω–¥–∞
                    word_start = i
                    while word_start > 0 and text[word_start - 1].isalnum():
                        word_start -= 1
                    
                    word_end = i
                    while word_end < len(text) and text[word_end].isalnum():
                        word_end += 1
                    
                    word = text[word_start:word_end]
                    
                    # –ï—Å–ª–∏ —ç—Ç–æ –±—Ä–µ–Ω–¥ (–≤—Å–µ —Å–∏–º–≤–æ–ª—ã –ª–∞—Ç–∏–Ω–∏—Ü–∞ –≤ –≤–µ—Ä—Ö–Ω–µ–º —Ä–µ–≥–∏—Å—Ç—Ä–µ), –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
                    if word.isalpha() and word.isupper() and word.isascii() and len(word) > 1:
                        continue
                
                # –ü—Ä–∏–≤–æ–¥–∏–º –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É
                lowercased_text = text[:i] + char.lower() + text[i+1:]
                
                return lowercased_text, {
                    'position': i,
                    'original_char': char,
                    'lowercased_char': char.lower()
                }
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –±—É–∫–≤–µ–Ω–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
        return text, {'position': -1, 'original_char': '', 'lowercased_char': ''}

    def get_diagnostic_info(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é"""
        return {
            'note_buy_has_kupit_kupyty': result['has_kupit_kupyty'],
            'note_buy_declined': result['declined'],
            'note_buy_single_strong': result['single_strong'],
            'note_buy_range_from': result['range_from'],
            'note_buy_range_to': result['range_to'],
            'note_buy_first_char_lowered': result['first_char_lowered'],
            'note_buy_before': '',  # –ë—É–¥–µ—Ç –∑–∞–ø–æ–ª–Ω–µ–Ω–æ –≤ –≤—ã–∑—ã–≤–∞—é—â–µ–º –∫–æ–¥–µ
            'note_buy_after': result['content'],
            'declension_debug': result['declension_debug'],
            'lowercase_debug': result['lowercase_debug']
        }
    
    def generate(self, product_data: Dict[str, Any], locale: str) -> str:
        """
        –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç note_buy —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–∑ –æ–±—ä–µ–∫—Ç–∞
        """
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ –æ–±—ä–µ–∫—Ç–∞, –∞ –ù–ï –ø–∞—Ä—Å–∏–º –∑–∞–Ω–æ–≤–æ –∏–∑ HTML
            title = product_data.get('title', '')
            
            if not title:
                # Fallback: –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ —Ñ–∞–∫—Ç–æ–≤
                title = self._extract_title_from_facts(product_data, locale)
            
            if not title:
                # –ü–æ—Å–ª–µ–¥–Ω–∏–π fallback
                title = f"Epilax, 5 –º–ª" if locale == 'ru' else f"Epilax, 5 –º–ª"
                logger.warning(f"‚ö†Ô∏è –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback –∑–∞–≥–æ–ª–æ–≤–æ–∫: {title}")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º note_buy —Å –∞–∫—Ç—É–∞–ª—å–Ω—ã–º –∑–∞–≥–æ–ª–æ–≤–∫–æ–º
            result = self.generate_enhanced_note_buy(title, locale)
            return result['content']
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ note_buy: {e}")
            # Fallback note_buy
            if locale == 'ua':
                return "–£ –Ω–∞—à–æ–º—É —ñ–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω—ñ ProRazko –º–æ–∂–Ω–∞ <strong>–∫—É–ø–∏—Ç–∏ —Ç–æ–≤–∞—Ä</strong>"
            else:
                return "–í –Ω–∞—à–µ–º –∏–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω–µ ProRazko –º–æ–∂–Ω–æ <strong>–∫—É–ø–∏—Ç—å —Ç–æ–≤–∞—Ä</strong>"
    
    def _extract_title_from_facts(self, product_data: Dict[str, Any], locale: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ —Ñ–∞–∫—Ç–æ–≤ –æ —Ç–æ–≤–∞—Ä–µ"""
        try:
            facts = product_data.get('facts', {})
            brand = facts.get('brand', 'Epilax')
            volume = facts.get('volume', '')
            weight = facts.get('weight', '')
            
            size_info = volume or weight
            if size_info:
                return f"{brand}, {size_info}"
            else:
                return brand
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞ –∏–∑ —Ñ–∞–∫—Ç–æ–≤: {e}")
            return f"Epilax, 5 –º–ª" if locale == 'ru' else f"Epilax, 5 –º–ª"