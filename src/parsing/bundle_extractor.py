"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞–±–æ—Ä–æ–≤ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –ø–æ–∏—Å–∫–æ–º –∏ —Ñ–æ–ª–±—ç–∫–æ–º
"""
import re
import logging
from bs4 import BeautifulSoup
from typing import List

logger = logging.getLogger(__name__)

# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã —Å–æ—Å—Ç–∞–≤–∞ –Ω–∞–±–æ—Ä–∞ –Ω–∞ —Ä—É—Å—Å–∫–æ–º –∏ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–º
INDICATORS = [
    r"–≤\s+–∫–æ–º–ø–ª–µ–∫—Ç\s+–≤—Ö–æ–¥–∏—Ç",
    r"–∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏(—è|—è:)",
    r"—Å–æ—Å—Ç–∞–≤\s+–Ω–∞–±–æ—Ä–∞",
    r"–≤\s+—Å—Ç–∞—Ä—Ç–æ–≤—ã–π\s+–Ω–∞–±–æ—Ä\s+–≤—Ö–æ–¥–∏—Ç",
    r"–≤\s+–Ω–∞–±—ñ—Ä\s+–≤—Ö–æ–¥–∏—Ç—å",
    r"—Å–∫–ª–∞–¥\s+–Ω–∞–±–æ—Ä—É",
    r"–∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü—ñ—è",
    r"–∫–æ–º–ø–ª–µ–∫—Ç\s+–≤–∫–ª—é—á–∞–µ—Ç",
    r"–Ω–∞–±—ñ—Ä\s+–≤–∫–ª—é—á–∞—î",
    r"–≤\s+–Ω–∞–±–æ—Ä\s+–≤—Ö–æ–¥–∏—Ç",
    r"–≤\s+–∫–æ–º–ø–ª–µ–∫—Ç\s+–≤–∫–ª—é—á–µ–Ω–æ",
    r"–∫–æ–º–ø–ª–µ–∫—Ç\s+—Å–æ–¥–µ—Ä–∂–∏—Ç",
    r"–Ω–∞–±—ñ—Ä\s+–º—ñ—Å—Ç–∏—Ç—å",
    r"–≤\s+–∫–æ–º–ø–ª–µ–∫—Ç\s+–≤—Ö–æ–¥—è—Ç",
    r"–≤\s+–Ω–∞–±—ñ—Ä\s+–≤—Ö–æ–¥—è—Ç—å"
]

# –ö–æ–º–ø–∏–ª–∏—Ä—É–µ–º —Ä–µ–≥—É–ª—è—Ä–Ω–æ–µ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
INDICATOR_RE = re.compile("|".join(INDICATORS), re.I | re.U)

# –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ–∏—Å–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –≤ —Ç–µ–∫—Å—Ç–µ
COMPONENT_PAT = re.compile(r"([A-Za-z–ê-–Ø–∞-—è0-9\s\-,]+(?:\s[0-9]+(?:\s[–≥–º–ª—à—Ç–í—Ç]+)?))")

# –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ –±—Ä–µ–Ω–¥—ã –∏ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏
BRAND_FILTERS = [
    'Pro Wax', 'ItalWAX', 'Epilax', 'Coral', 'Depilax', 
    'ProRazko', 'Wax', 'Gel', 'Foam', 'Cream', '–≤–æ—Å–∫–æ–ø–ª–∞–≤',
    '–≤–æ—Å–∫', '–ø—É–¥—Ä–∞', '—Ç–∞–ª—å–∫', '—à–ø–∞—Ç–µ–ª—å', '–≥–µ–ª—å', '–ø—ñ–Ω–∫–∞',
    '—Ñ–ª—é—ó–¥', '—Ñ–ª—é–∏–¥', '–∫—Ä–µ–º', '–ª–æ—Å—å–π–æ–Ω', '–º–∞—Å–ª–æ', '—Å–ø—Ä–µ–π'
]

def filter_bundle_only_if_explicit(html: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, –µ—Å—Ç—å –ª–∏ –≤ HTML —è–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã —Å–æ—Å—Ç–∞–≤–∞ –Ω–∞–±–æ—Ä–∞
    
    Args:
        html: HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞
        
    Returns:
        True –µ—Å–ª–∏ –Ω–∞–π–¥–µ–Ω—ã —è–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã —Å–æ—Å—Ç–∞–≤–∞ –Ω–∞–±–æ—Ä–∞
    """
    explicit_phrases = [
        r"—Å–æ—Å—Ç–∞–≤[:\\-]", r"—Å–∫–ª–∞–¥[:\\-]", r"–∫–æ–º–ø–ª–µ–∫—Ç[–∞-—è]*[:\\-]",
        r"–Ω–∞–±–æ—Ä[–∞-—è]*[:\\-]", r"–∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü–∏—è[:\\-]",
        r"–≤\s+–Ω–∞–±–æ—Ä–µ\s+–≤—Ö–æ–¥—è—Ç", r"–≤\s+–∫–æ–º–ø–ª–µ–∫—Ç[–µ|–∞—Ö]?\s+–≤—Ö–æ–¥—è—Ç",
        r"–≤\s+–Ω–∞–±—ñ—Ä\s+–≤—Ö–æ–¥—è—Ç—å", r"–≤\s+–∫–æ–º–ø–ª–µ–∫—Ç\s+–≤—Ö–æ–¥–∏—Ç—å",
        r"—Å–∫–ª–∞–¥\s+–Ω–∞–±–æ—Ä—É", r"—Å–æ—Å—Ç–∞–≤\s+–Ω–∞–±–æ—Ä–∞", r"–∫–æ–º–ø–ª–µ–∫—Ç–∞—Ü—ñ—è"
    ]
    
    for phrase in explicit_phrases:
        if re.search(phrase, html, re.I | re.U):
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —è–≤–Ω—ã–π –º–∞—Ä–∫–µ—Ä —Å–æ—Å—Ç–∞–≤–∞: {phrase}")
            return True
    
    logger.info("‚ùå –Ø–≤–Ω—ã–µ –º–∞—Ä–∫–µ—Ä—ã —Å–æ—Å—Ç–∞–≤–∞ –Ω–∞–±–æ—Ä–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
    return False

def extract_bundle_components(html: str) -> List[str]:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –∏–∑–≤–ª–µ–∫–∞—Ç–µ–ª—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞–±–æ—Ä–æ–≤ —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º –ø–æ–∏—Å–∫–æ–º –∏ —Ñ–æ–ª–±—ç–∫–æ–º
    –¢–µ–ø–µ—Ä—å –∏–∑–≤–ª–µ–∫–∞–µ—Ç —Å–æ—Å—Ç–∞–≤ –¢–û–õ–¨–ö–û –ø—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ —è–≤–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤
    
    Args:
        html: HTML —Å—Ç—Ä–∞–Ω–∏—Ü—ã —Ç–æ–≤–∞—Ä–∞
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞–±–æ—Ä–∞ (–ø—É—Å—Ç–æ–π –µ—Å–ª–∏ –Ω–µ—Ç —è–≤–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤)
    """
    if not html:
        return []
    
    # –ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –ü–†–û–í–ï–†–ö–ê: –∏–∑–≤–ª–µ–∫–∞–µ–º —Å–æ—Å—Ç–∞–≤ —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —è–≤–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–∞—Ö
    if not filter_bundle_only_if_explicit(html):
        logger.info("üö´ –°–æ—Å—Ç–∞–≤ –Ω–∞–±–æ—Ä–∞ –Ω–µ –∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è - –Ω–µ—Ç —è–≤–Ω—ã—Ö –º–∞—Ä–∫–µ—Ä–æ–≤")
        return []
    
    soup = BeautifulSoup(html, "html.parser")
    items = []
    
    # 1. –ü–æ–∏—Å–∫ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º + UL/OL
    headers = soup.find_all(lambda tag: 
        tag.name in ['h2', 'h3', 'h4', 'strong', 'p', 'div'] and 
        INDICATOR_RE.search(tag.get_text(strip=True))
    )
    
    for header in headers:
        logger.debug(f"–ù–∞–π–¥–µ–Ω –∑–∞–≥–æ–ª–æ–≤–æ–∫ —Å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–º: {header.get_text()[:50]}...")
        
        # –ò—â–µ–º —Å–ø–∏—Å–æ–∫ –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        next_list = header.find_next_sibling(['ul', 'ol'])
        if next_list:
            list_items = next_list.find_all('li')
            for li in list_items:
                text = li.get_text(strip=True)
                if text and len(text) > 3:
                    items.append(text)
            if items:
                logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(items)} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Å–ø–∏—Å–æ–∫")
                return _remove_duplicates(items)
        
        # –ò—â–µ–º –∞–±–∑–∞—Ü –ø–æ—Å–ª–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞
        next_p = header.find_next_sibling('p')
        if next_p:
            text = next_p.get_text(strip=True)
            if text and len(text) > 10:
                components = re.split(r'[;,\n]', text)
                for comp in components:
                    comp = comp.strip()
                    if comp and len(comp) > 3:
                        items.append(comp)
                if items:
                    logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(items)} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ –∑–∞–≥–æ–ª–æ–≤–æ–∫ + –∞–±–∑–∞—Ü")
                    return _remove_duplicates(items)
    
    # 2. –ü–æ–∏—Å–∫ –≤ —Ç–∞–±–ª–∏—Ü–∞—Ö
    if not items:
        items = _extract_from_tables(soup)
        if items:
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(items)} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏–∑ —Ç–∞–±–ª–∏—Ü")
            return _remove_duplicates(items)
    
    # 3. –ü–æ–∏—Å–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–ª–æ–∫–∞—Ö
    if not items:
        items = _extract_from_structured_blocks(soup)
        if items:
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(items)} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤")
            return _remove_duplicates(items)
    
    # 4. –§–æ–ª–±—ç–∫: –ø–∞—Ä—Å–∏–Ω–≥ –≤—Å–µ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    if not items:
        logger.info("–ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–æ–ª–±—ç–∫-–ø–æ–∏—Å–∫ –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É")
        items = _fallback_text_search(soup)
        if items:
            logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(items)} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —á–µ—Ä–µ–∑ —Ñ–æ–ª–±—ç–∫-–ø–æ–∏—Å–∫")
            return _remove_duplicates(items)
    
    logger.info(f"–ò—Ç–æ–≥–æ –∏–∑–≤–ª–µ—á–µ–Ω–æ {len(items)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
    return _remove_duplicates(items)

def _extract_from_tables(soup: BeautifulSoup) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ —Ç–∞–±–ª–∏—Ü"""
    items = []
    tables = soup.find_all('table')
    
    for table in tables:
        for row in table.find_all('tr'):
            cells = row.find_all('td')
            if len(cells) >= 2 and INDICATOR_RE.search(cells[0].get_text(strip=True)):
                text = cells[1].get_text(strip=True)
                components = re.split(r'[;,]', text)
                for comp in components:
                    comp = comp.strip()
                    if comp and len(comp) > 3:
                        items.append(comp)
    
    return items

def _extract_from_structured_blocks(soup: BeautifulSoup) -> List[str]:
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤"""
    items = []
    
    # –ü–æ–∏—Å–∫ –≤ –±–ª–æ–∫–∞—Ö —Å –∫–ª–∞—Å—Å–∞–º–∏, —É–∫–∞–∑—ã–≤–∞—é—â–∏–º–∏ –Ω–∞ —Å–æ—Å—Ç–∞–≤
    structured_blocks = soup.find_all(['div', 'section'], 
        class_=re.compile(r'(composition|bundle|kit|set|–∫–æ–º–ø–ª–µ–∫—Ç|–Ω–∞–±–æ—Ä|—Å–æ—Å—Ç–∞–≤)', re.I))
    
    for block in structured_blocks:
        block_text = block.get_text()
        if any(indicator in block_text.lower() for indicator in ['–≤—Ö–æ–¥–∏—Ç', '–≤–∫–ª—é—á–∞–µ—Ç', '—Å–æ—Å—Ç–∞–≤', '–∫–æ–º–ø–ª–µ–∫—Ç']):
            # –ò—â–µ–º —Å–ø–∏—Å–∫–∏ –≤–Ω—É—Ç—Ä–∏ –±–ª–æ–∫–∞
            lists = block.find_all(['ul', 'ol'])
            for ul in lists:
                for li in ul.find_all('li'):
                    text = li.get_text(strip=True)
                    if text and len(text) > 3:
                        items.append(text)
    
    return items

def _fallback_text_search(soup: BeautifulSoup) -> List[str]:
    """
    –§–æ–ª–±—ç–∫-–ø–æ–∏—Å–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –ø–æ –≤—Å–µ–º—É —Ç–µ–∫—Å—Ç—É —Å—Ç—Ä–∞–Ω–∏—Ü—ã
    
    Args:
        soup: BeautifulSoup –æ–±—ä–µ–∫—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        
    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    """
    items = []
    full_text = soup.get_text()
    
    # –ò—â–µ–º —Å—Ç—Ä–æ–∫–∏ —Å –±—Ä–µ–Ω–¥–∞–º–∏/–µ–¥–∏–Ω–∏—Ü–∞–º–∏ —Ç–∏–ø–∞ "–í–æ—Å–∫–æ–ø–ª–∞–≤ ... 100 –í—Ç"
    candidates = COMPONENT_PAT.findall(full_text)
    
    for candidate in candidates:
        candidate = candidate.strip()
        # –§–∏–ª—å—Ç—Ä—É–µ–º –ø–æ –¥–ª–∏–Ω–µ –∏ –Ω–∞–ª–∏—á–∏—é –±—Ä–µ–Ω–¥–æ–≤/–∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        if (len(candidate) > 10 and 
            any(brand.lower() in candidate.lower() for brand in BRAND_FILTERS)):
            items.append(candidate)
    
    logger.info(f"–§–æ–ª–±—ç–∫-–ø–æ–∏—Å–∫ –Ω–∞—à–µ–ª {len(items)} –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤")
    return items

def _remove_duplicates(items: List[str]) -> List[str]:
    """–£–¥–∞–ª—è–µ—Ç –¥—É–±–ª–∏–∫–∞—Ç—ã, —Å–æ—Ö—Ä–∞–Ω—è—è –ø–æ—Ä—è–¥–æ–∫"""
    seen = set()
    unique_items = []
    for item in items:
        if item not in seen:
            seen.add(item)
            unique_items.append(item)
    return unique_items

def validate_bundle_components(components: List[str], description: str) -> bool:
    """
    –ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —á—Ç–æ –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
    
    Args:
        components: –°–ø–∏—Å–æ–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞–±–æ—Ä–∞
        description: HTML –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
        
    Returns:
        True –µ—Å–ª–∏ –≤—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–∞–π–¥–µ–Ω—ã –≤ –æ–ø–∏—Å–∞–Ω–∏–∏
    """
    if not components:
        return True
    
    missing_components = []
    for component in components:
        # –ò—â–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç –≤ –æ–ø–∏—Å–∞–Ω–∏–∏ (–±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞)
        if component.lower() not in description.lower():
            missing_components.append(component)
    
    if missing_components:
        logger.warning(f"–ù–µ –Ω–∞–π–¥–µ–Ω—ã –≤ –æ–ø–∏—Å–∞–Ω–∏–∏: {missing_components}")
        return False
    
    logger.info("–í—Å–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–∞–±–æ—Ä–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –æ–ø–∏—Å–∞–Ω–∏–∏")
    return True

def create_fallback_bundle_text(components: List[str], locale: str) -> str:
    """
    –°–æ–∑–¥–∞–µ—Ç —Ñ–æ–ª–±—ç–∫-—Ç–µ–∫—Å—Ç —Å –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    
    Args:
        components: –°–ø–∏—Å–æ–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞–±–æ—Ä–∞
        locale: –õ–æ–∫–∞–ª—å ('ru' –∏–ª–∏ 'ua')
        
    Returns:
        HTML —Ç–µ–∫—Å—Ç —Å –ø–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    """
    if not components:
        return ""
    
    if locale == 'ua':
        prefix = "–í –Ω–∞–±—ñ—Ä –≤—Ö–æ–¥–∏—Ç—å: "
    else:
        prefix = "–í –Ω–∞–±–æ—Ä –≤—Ö–æ–¥—è—Ç: "
    
    components_text = ", ".join(components) + "."
    return f"<p>{prefix}{components_text}</p>"

def validate_bundle_in_description(description_html: str, bundle_components: List[str], locale: str = 'ru') -> str:
    """
    –í–∞–ª–∏–¥–∞—Ü–∏—è –∏ —Ñ–æ–ª–±—ç–∫ –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    
    Args:
        description_html: HTML –æ–ø–∏—Å–∞–Ω–∏–µ —Ç–æ–≤–∞—Ä–∞
        bundle_components: –°–ø–∏—Å–æ–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞–±–æ—Ä–∞
        locale: –õ–æ–∫–∞–ª—å ('ru' –∏–ª–∏ 'ua')
        
    Returns:
        HTML –æ–ø–∏—Å–∞–Ω–∏–µ —Å –≥–∞—Ä–∞–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ–º –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
    """
    if not bundle_components:
        return description_html
    
    # –î–ª—è UA –ø–µ—Ä–µ–≤–æ–¥–∏–º –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏
    if locale == 'ua':
        translated_components = _translate_bundle_components(bundle_components)
    else:
        translated_components = bundle_components
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–∏–µ –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
    missing_components = []
    for component in translated_components:
        if component.lower() not in description_html.lower():
            missing_components.append(component)
    
    # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã, –¥–æ–±–∞–≤–ª—è–µ–º —Ñ–æ–ª–±—ç–∫
    if missing_components:
        logger.warning(f"–î–æ–±–∞–≤–ª—è–µ–º —Ñ–æ–ª–±—ç–∫ –¥–ª—è {len(missing_components)} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤")
        if locale == 'ua':
            fallback_text = f"<p>–ü–æ–≤–Ω–∏–π —Å–∫–ª–∞–¥: {'; '.join(translated_components)}</p>"
        else:
            fallback_text = f"<p>–ü–æ–ª–Ω—ã–π —Å–æ—Å—Ç–∞–≤: {'; '.join(translated_components)}</p>"
        description_html += fallback_text
    
    return description_html

def _translate_bundle_components(components: List[str]) -> List[str]:
    """
    ‚úÖ –£–ù–ò–í–ï–†–°–ê–õ–¨–ù–´–ô –ø–µ—Ä–µ–≤–æ–¥ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞–±–æ—Ä–∞ —á–µ—Ä–µ–∑ LLM
    –ë–ï–ó —Å–ª–æ–≤–∞—Ä–µ–π - —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–ª—è –õ–Æ–ë–´–• —Ç–æ–≤–∞—Ä–æ–≤
    
    Args:
        components: –°–ø–∏—Å–æ–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞ —Ä—É—Å—Å–∫–æ–º
        
    Returns:
        –°–ø–∏—Å–æ–∫ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–æ–º
    """
    if not components:
        return []
    
    # ‚úÖ –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ —á–µ—Ä–µ–∑ LLM
    try:
        import httpx
        import os
        import asyncio
        
        async def translate_with_llm():
            api_key = os.getenv('OPENAI_API_KEY')
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –ø—Ä–æ–º–ø—Ç –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞
            components_text = "\n".join([f"{i+1}. {comp}" for i, comp in enumerate(components)])
            
            prompt = f"""–ü–µ—Ä–µ–≤–µ–¥–∏ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–∞–±–æ—Ä–∞ –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π —è–∑—ã–∫:
{components_text}

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
- –¢–æ—á–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –∫–∞–∂–¥–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞
- –°–æ—Ö—Ä–∞–Ω–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –µ–¥–∏–Ω–∏—Ü—ã –∏–∑–º–µ—Ä–µ–Ω–∏—è
- –°–æ—Ö—Ä–∞–Ω–∏ –Ω–∞–∑–≤–∞–Ω–∏—è –±—Ä–µ–Ω–¥–æ–≤
- –ë–ï–ó –ø–æ—è—Å–Ω–µ–Ω–∏–π

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (–¢–û–õ–¨–ö–û —Å–ø–∏—Å–æ–∫):
1. [–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç 1]
2. [–ø–µ—Ä–µ–≤–µ–¥–µ–Ω–Ω—ã–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç 2]
..."""

            async with httpx.AsyncClient() as client:
                response = await client.post(
                    "https://api.openai.com/v1/chat/completions",
                    headers={
                        "Authorization": f"Bearer {api_key}",
                        "Content-Type": "application/json"
                    },
                    json={
                        "model": "gpt-4o-mini",
                        "messages": [
                            {"role": "user", "content": prompt}
                        ],
                        "temperature": 0.3,
                        "max_tokens": 500
                    },
                    timeout=30.0
                )
                
                if response.status_code == 200:
                    result = response.json()
                    response_text = result['choices'][0]['message']['content'].strip()
                    
                    # –ü–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
                    lines = [line.strip() for line in response_text.split('\n') if line.strip()]
                    translated = []
                    
                    for line in lines:
                        # –ò—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω "1. —Ç–µ–∫—Å—Ç" –∏–ª–∏ –ø—Ä–æ—Å—Ç–æ "—Ç–µ–∫—Å—Ç"
                        if '. ' in line:
                            translated.append(line.split('. ', 1)[1])
                        else:
                            translated.append(line)
                    
                    if len(translated) == len(components):
                        logger.info(f"‚úÖ LLM –ø–µ—Ä–µ–≤–µ–¥–µ–Ω–æ {len(translated)} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ –Ω–∞–±–æ—Ä–∞ –Ω–∞ —É–∫—Ä–∞–∏–Ω—Å–∫–∏–π")
                        return translated
                
                logger.error(f"‚ùå LLM API –æ—à–∏–±–∫–∞: {response.status_code}")
                return components
                
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥
        translated = asyncio.run(translate_with_llm())
        return translated
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM –ø–µ—Ä–µ–≤–æ–¥–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤: {e}")
        # Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
        return components
