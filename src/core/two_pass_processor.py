"""
–î–≤—É—Ö–ø—Ä–æ—Ö–æ–¥–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å retry –ª–æ–≥–∏–∫–æ–π
"""
import asyncio
import logging
from typing import List, Dict, Any, Optional

logger = logging.getLogger(__name__)

class TwoPassProcessor:
    """–î–≤—É—Ö–ø—Ä–æ—Ö–æ–¥–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ URL"""
    
    def __init__(self, progress_tracker, fallback_processor, conditional_exporter):
        self.progress_tracker = progress_tracker
        self.fallback_processor = fallback_processor
        self.conditional_exporter = conditional_exporter
        from src.processing.consistency_guard import ConsistencyGuard
        from src.processing.content_enhancer import ContentEnhancer
        self.consistency_guard = ConsistencyGuard()
        self.content_enhancer = ContentEnhancer()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –æ—á–µ—Ä–µ–¥—å —Ä–µ–º–æ–Ω—Ç–∞
        from src.repair.repair_queue import RepairQueue
        self.repair_queue = RepairQueue()
        
        # –°–ª–æ–≤–∞—Ä—å –¥–ª—è –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∏ HTML –ø–æ URL
        self.url_html_data = {}
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø—Ä–æ—Ö–æ–¥–∞ 1 (–±—ã—Å—Ç—Ä—ã–π)
        self.pass1_config = {
            'concurrency': 8,
            'rps_limit': 4,
            'timeout': 15,
            'retries': 2,
            'backoff_factor': 1.5
        }
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –ø—Ä–æ—Ö–æ–¥–∞ 2 (–¥–æ–±–∏–≤–∫–∞)
        self.pass2_config = {
            'concurrency': 4,
            'rps_limit': 2,
            'timeout': 30,
            'retries': 3,
            'backoff_factor': 2.0
        }
    
    async def process_urls_two_pass(self, urls: List[str]) -> List[Dict[str, Any]]:
        """–î–≤—É—Ö–ø—Ä–æ—Ö–æ–¥–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ URL"""
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –¥–≤—É—Ö–ø—Ä–æ—Ö–æ–¥–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É {len(urls)} URL")
        
        # –ü—Ä–æ—Ö–æ–¥ 1: –±—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞
        logger.info("üìã –ü—Ä–æ—Ö–æ–¥ 1: –±—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞")
        pass1_results = await self._process_pass1(urls)
        
        # –ü—Ä–æ—Ö–æ–¥ 2: –¥–æ–±–∏–≤–∫–∞ pending (–∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Å–ª–µ –ø—Ä–æ—Ö–æ–¥–∞ 1)
        logger.info("üîÑ –ü—Ä–æ—Ö–æ–¥ 2: –¥–æ–±–∏–≤–∫–∞ pending")
        pass2_results = await self._process_pass2()
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        all_results = pass1_results + pass2_results
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å HTML –ø–æ –ª–æ–∫–∞–ª—è–º
        self._write_final_results()
        
        # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ñ–∞–π–ª —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä–æ–π
        self.conditional_exporter.write_final_files()
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        stats = self.progress_tracker.get_stats()
        logger.info(f"üìä –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞: {stats}")
        
        return all_results
    
    async def _process_pass1(self, urls: List[str]) -> List[Dict[str, Any]]:
        """–ü—Ä–æ—Ö–æ–¥ 1: –±—ã—Å—Ç—Ä–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞"""
        results = []
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –ø–∞—Ä—ã RU/UA
        tasks = []
        for ua_url in urls:
            ru_url = self._to_ru_url(ua_url)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –ª–∏ —É–∂–µ
            if (self.progress_tracker.is_processed(ua_url, 'ua') and 
                self.progress_tracker.is_processed(ru_url, 'ru')):
                logger.info(f"‚è≠Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —É–∂–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π: {ua_url}")
                continue
            
            task = asyncio.create_task(self._process_url_pair_pass1(ua_url, ru_url))
            tasks.append(task)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏
        if tasks:
            task_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for i, result in enumerate(task_results):
                if isinstance(result, Exception):
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ö–æ–¥–µ 1: {result}")
                else:
                    results.extend(result)
        
        return results
    
    async def _process_url_pair_pass1(self, ua_url: str, ru_url: str) -> List[Dict[str, Any]]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–∞—Ä—ã URL –≤ –ø—Ä–æ—Ö–æ–¥–µ 1 —Å –∞–≤—Ç–æ-–¥–æ–±–∏–≤–∫–æ–π –ª–æ–∫–∞–ª–µ–π"""
        results = []
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º UA
        ua_result = await self._process_single_url_pass1(ua_url, 'ua')
        if ua_result:
            results.append(ua_result)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º RU
        ru_result = await self._process_single_url_pass1(ru_url, 'ru')
        if ru_result:
            results.append(ru_result)
        
        # –ê–≤—Ç–æ-–¥–æ–±–∏–≤–∫–∞ –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏—Ö –ª–æ–∫–∞–ª–µ–π
        ua_success = ua_result and ua_result.get('export_mode') == 'full'
        ru_success = ru_result and ru_result.get('export_mode') == 'full'
        
        if ua_success and not ru_success:
            # UA —É—Å–ø–µ—à–Ω–æ, RU –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ–º RU –≤ pending
            logger.info(f"üîÑ –ê–≤—Ç–æ-–¥–æ–±–∏–≤–∫–∞: UA —É—Å–ø–µ—à–Ω–æ, RU –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ–º RU –≤ pending: {ru_url}")
            self.progress_tracker.add_to_pending(ru_url, 'ru', "auto_retry_missing_locale")
        elif ru_success and not ua_success:
            # RU —É—Å–ø–µ—à–Ω–æ, UA –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ–º UA –≤ pending
            logger.info(f"üîÑ –ê–≤—Ç–æ-–¥–æ–±–∏–≤–∫–∞: RU —É—Å–ø–µ—à–Ω–æ, UA –Ω–µ—Ç - –¥–æ–±–∞–≤–ª—è–µ–º UA –≤ pending: {ua_url}")
            self.progress_tracker.add_to_pending(ua_url, 'ua', "auto_retry_missing_locale")
        
        return results
    
    async def _process_single_url_pass1(self, url: str, locale: str) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ URL –≤ –ø—Ä–æ—Ö–æ–¥–µ 1 —Å –±–µ–∑—É—Å–ª–æ–≤–Ω—ã–º —ç–∫—Å–ø–æ—Ä—Ç–æ–º"""
        try:
            logger.info(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {url} ({locale}) –≤ –ø—Ä–æ—Ö–æ–¥–µ 1")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback fetcher
            from src.fetcher.fallback_fetcher import FallbackFetcher
            from src.processing.safe_facts import SafeFactsExtractor
            
            async with FallbackFetcher(timeout=15, retries=2) as fetcher:
                html = await fetcher.fetch_single(url, locale)
                
                if html:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º HTML —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ —Ñ–∞–∫—Ç–∞–º–∏
                    result = await self._process_html_safe(html, url, locale, None)
                    
                    # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
                    self.progress_tracker.mark_processed(url, locale, result)
                    
                    return result
                else:
                    # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏–∑ –±–∞–∑–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
                    result = self._create_safe_result(url, locale, "network_failed_pass1")
                    
                    # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
                    self.progress_tracker.mark_processed(url, locale, result)
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –≤ pending –¥–ª—è –ø—Ä–æ—Ö–æ–¥–∞ 2
                    self.progress_tracker.add_to_pending(url, locale, "network_failed_pass1")
                    return result
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {url} ({locale}): {e}")
            
            # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            result = self._create_safe_result(url, locale, f"exception_pass1: {str(e)}")
            
            # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
            self.progress_tracker.mark_processed(url, locale, result)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ pending –¥–ª—è –ø—Ä–æ—Ö–æ–¥–∞ 2
            self.progress_tracker.add_to_pending(url, locale, f"exception_pass1: {str(e)}")
            return result
    
    async def _process_pass2(self) -> List[Dict[str, Any]]:
        """–ü—Ä–æ—Ö–æ–¥ 2: –¥–æ–±–∏–≤–∫–∞ pending"""
        results = []
        pending = self.progress_tracker.get_pending()
        
        if not pending:
            logger.info("‚úÖ –ù–µ—Ç pending –∑–∞–¥–∞—á –¥–ª—è –ø—Ä–æ—Ö–æ–¥–∞ 2")
            return results
        
        logger.info(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(pending)} pending –∑–∞–¥–∞—á")
        
        # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è pending
        tasks = []
        for item in pending:
            task = asyncio.create_task(self._process_pending_item(item))
            tasks.append(task)
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ pending –∑–∞–¥–∞—á–∏
        if tasks:
            task_results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for i, result in enumerate(task_results):
                if isinstance(result, Exception):
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ö–æ–¥–µ 2: {result}")
                else:
                    if result:
                        results.append(result)
        
        return results
    
    def _validate_and_fix_title_early(self, title: str, html: str, locale: str, url: str) -> str:
        """–†–∞–Ω–Ω—è—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
        try:
            from src.processing.title_generator import TitleGenerator
            title_generator = TitleGenerator()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤–∞–ª–∏–¥–µ–Ω –ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫
            if title_generator.validate_title(title, locale):
                logger.info(f"‚úÖ –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤–∞–ª–∏–¥–µ–Ω: {title}")
                return title
            
            logger.warning(f"‚ö†Ô∏è –ó–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–µ–≤–∞–ª–∏–¥–µ–Ω: {title}")
            
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑ H2 —Ç–µ–≥–∞
            h2_title = title_generator.extract_title_from_h2_tag(html, locale)
            if h2_title and title_generator.validate_title(h2_title, locale):
                logger.info(f"‚úÖ –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏–∑–≤–ª–µ—á–µ–Ω –∏–∑ H2: {h2_title}")
                return h2_title
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ñ–∞–∫—Ç–æ–≤ –∏–∑ HTML
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ñ–∞–∫—Ç—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            import re
            
            # –ò—â–µ–º –±—Ä–µ–Ω–¥
            brand_match = re.search(r'Epilax', html, re.IGNORECASE)
            brand = brand_match.group(0) if brand_match else 'Epilax'
            
            # –ò—â–µ–º –æ–±—ä–µ–º/–≤–µ—Å
            volume_match = re.search(r'(\d+)\s*(–º–ª|ml)', html, re.IGNORECASE)
            weight_match = re.search(r'(\d+)\s*(–≥|g)', html, re.IGNORECASE)
            
            size_info = ''
            if volume_match:
                size_info = f"{volume_match.group(1)} –º–ª"
            elif weight_match:
                size_info = f"{weight_match.group(1)} –≥"
            
            # –°–æ–∑–¥–∞–µ–º —Ñ–∞–∫—Ç—ã –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            facts = {
                'brand': brand,
                'volume': size_info if '–º–ª' in size_info else '',
                'weight': size_info if '–≥' in size_info else '',
                'product_type': '–¢–æ–≤–∞—Ä' if locale == 'ru' else '–¢–æ–≤–∞—Ä'
            }
            
            generated_title = title_generator.create_title_from_facts(facts, locale)
            logger.info(f"‚úÖ –ó–∞–≥–æ–ª–æ–≤–æ–∫ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –∏–∑ —Ñ–∞–∫—Ç–æ–≤: {generated_title}")
            return generated_title
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞: {e}")
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É –∑–∞–≥–æ–ª–æ–≤–∫—É
            return f"Epilax, 5 –º–ª" if locale == 'ru' else f"Epilax, 5 –º–ª"
    
    async def _process_pending_item(self, item: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ pending —ç–ª–µ–º–µ–Ω—Ç–∞"""
        url = item['url']
        locale = item['locale']
        retry_count = item.get('retry_count', 0)
        
        try:
            logger.info(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º pending {url} ({locale}) –≤ –ø—Ä–æ—Ö–æ–¥–µ 2")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback fetcher —Å —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
            from src.fetcher.fallback_fetcher import FallbackFetcher
            
            async with FallbackFetcher(timeout=30, retries=3) as fetcher:
                html = await fetcher.fetch_single(url, locale)
                
                if html:
                    # –°–æ–∑–¥–∞–µ–º —É—Å–ø–µ—à–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    result = {
                        'url': url,
                        'locale': locale,
                        'export_mode': 'full',
                        'flags': ['retry_success'],
                        'needs_review': False,
                        'consistency_fixes': [],
                        'html_length': len(html),
                        'processed': True,
                        'retries': retry_count,
                        'network_errors': 0,
                        'budget_violation': False
                    }
                    
                    # –£–¥–∞–ª—è–µ–º –∏–∑ pending
                    self.progress_tracker.remove_from_pending(url, locale)
                    # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
                    self.progress_tracker.mark_processed(url, locale, result)
                    return result
                else:
                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –ø–æ–ø—ã—Ç–æ–∫
                    retry_count += 1
                    
                    if retry_count >= 3:
                        # –°–æ–∑–¥–∞–µ–º fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç (NO-EXCLUDE —Ä–µ–∂–∏–º)
                        fallback_result = self._create_fallback_result(url, locale, "network_failed_max_retries", retry_count)
                        self.progress_tracker.remove_from_pending(url, locale)
                        # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π (–¥–∞–∂–µ –Ω–µ—É—Å–ø–µ—à–Ω—ã–π)
                        self.progress_tracker.mark_processed(url, locale, fallback_result)
                        return fallback_result
                    else:
                        # –û–±–Ω–æ–≤–ª—è–µ–º pending —Å –Ω–æ–≤—ã–º —Å—á–µ—Ç—á–∏–∫–æ–º
                        self.progress_tracker.add_to_pending(url, locale, f"network_retry_{retry_count}", retry_count)
                        return None
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ pending {url} ({locale}): {e}")
            retry_count += 1
            
            if retry_count >= 3:
                # –°–æ–∑–¥–∞–µ–º fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç (NO-EXCLUDE —Ä–µ–∂–∏–º)
                fallback_result = self._create_fallback_result(url, locale, f"exception_max_retries: {str(e)}", retry_count)
                self.progress_tracker.remove_from_pending(url, locale)
                # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π (–¥–∞–∂–µ –Ω–µ—É—Å–ø–µ—à–Ω—ã–π)
                self.progress_tracker.mark_processed(url, locale, fallback_result)
                return fallback_result
            else:
                # –û–±–Ω–æ–≤–ª—è–µ–º pending —Å –Ω–æ–≤—ã–º —Å—á–µ—Ç—á–∏–∫–æ–º
                self.progress_tracker.add_to_pending(url, locale, f"exception_retry_{retry_count}: {str(e)}", retry_count)
                return None
    
    async def _process_html_content(self, html: str, url: str, locale: str) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ HTML –∫–æ–Ω—Ç–µ–Ω—Ç–∞ (–∑–∞–≥–ª—É—à–∫–∞ - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–º–µ–Ω–µ–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É)"""
        # –ó–¥–µ—Å—å –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –æ—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ HTML
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
        return {
            'url': url,
            'locale': locale,
            'export_mode': 'full',
            'flags': [],
            'needs_review': False,
            'consistency_fixes': []
        }
    
    def _create_fallback_result(self, url: str, locale: str, reason: str, retries: int = 0) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç fallback —Ä–µ–∑—É–ª—å—Ç–∞—Ç (NO-EXCLUDE —Ä–µ–∂–∏–º)"""
        return {
            'url': url,
            'locale': locale,
            'export_mode': 'fallback',
            'flags': [reason],
            'needs_review': True,
            'consistency_fixes': [],
            'fallback_reason': reason,
            'html_length': 0,
            'processed': True,  # –í—Å–µ–≥–¥–∞ True –≤ no-exclude —Ä–µ–∂–∏–º–µ
            'retries': retries,
            'network_errors': retries,
            'budget_violation': False
        }
    
    async def _process_html_safe(self, html: str, url: str, locale: str, input_index: int = None) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç HTML —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ —Ñ–∞–∫—Ç–∞–º–∏"""
        from src.processing.safe_facts import SafeFactsExtractor
        from src.processing.safe_templates import SafeTemplates
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ (–∑–∞–≥–ª—É—à–∫–∞ - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–º–µ–Ω–µ–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É)
        h1 = self._extract_h1(html)
        
        # –†–∞–Ω–Ω—è—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –∑–∞–≥–æ–ª–æ–≤–∫–∞
        h1 = self._validate_and_fix_title_early(h1, html, locale, url)
        
        specs = self._extract_specs(html)
        mass_facts = self._extract_mass_facts(html)
        volume_facts = self._extract_volume_facts(html)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ —Ñ–∞–∫—Ç—ã
        safe_extractor = SafeFactsExtractor()
        safe_facts = safe_extractor.extract_safe_facts(specs, h1, mass_facts, volume_facts)
        
        # –£–¥–∞–ª—è–µ–º —Å–ø–æ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ HTML
        clean_html = safe_extractor.strip_controversial_numbers(html)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω–æ—Å—Ç—å (–±–µ–∑ –±–ª–æ–∫–∏—Ä–æ–≤–æ–∫)
        volume_check = self.consistency_guard.check_volume_consistency({'description': clean_html}, locale)
        mass_check = self.consistency_guard.check_mass_consistency({'description': clean_html}, locale)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —á–µ—Ä–µ–∑ LLM (–±–µ–∑ fallback)
        from src.llm.content_generator import LLMContentGenerator
        llm_generator = LLMContentGenerator()
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è LLM
        product_data = {
            'title': h1,
            'description': clean_html[:500],  # –ü–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤ HTML –∫–∞–∫ –æ–ø–∏—Å–∞–Ω–∏–µ
            'brand': safe_facts.get('brand', ''),
            'product_type': safe_facts.get('category', ''),
            'volume': safe_facts.get('pack', ''),
            'specs': specs  # –ü–µ—Ä–µ–¥–∞–µ–º –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        }
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —á–µ—Ä–µ–∑ LLM (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)
        try:
            llm_content = llm_generator.generate_content(product_data, locale)
            logger.info(f"‚úÖ LLM –∫–æ–Ω—Ç–µ–Ω—Ç —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –¥–ª—è {locale}")
            
            # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç
            from src.validation.guards import (
                faq_guard, specs_guard, description_guard, ValidationError,
                anti_placeholders_guard, locale_content_guard, structure_guard
            )
            
            try:
                # –û—Å–Ω–æ–≤–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è
                faq_guard(llm_content.get('faq', []))
                normalized_specs, specs_clamped = specs_guard(llm_content.get('specs', []), locale)
                description_guard(llm_content.get('description', ''))
                
                # –ê–Ω—Ç–∏-–∑–∞–≥–ª—É—à–∫–∏
                anti_placeholders_guard(llm_content.get('description', ''), 'description')
                anti_placeholders_guard(llm_content.get('note_buy', ''), 'note_buy')
                
                # –õ–æ–∫–∞–ª–∏–∑–∞—Ü–∏—è
                locale_content_guard(llm_content.get('description', ''), locale, 'description')
                locale_content_guard(llm_content.get('note_buy', ''), locale, 'note_buy')
                
                # –û–±–Ω–æ–≤–ª—è–µ–º specs —Å –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
                llm_content['specs'] = normalized_specs
                if specs_clamped:
                    llm_content['specs_clamped'] = True
                
                logger.info(f"‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –ø—Ä–æ—à–ª–∞ –¥–ª—è {locale}")
            except ValidationError as ve:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø—Ä–∏—á–∏–Ω—É –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏
                error_msg = str(ve)
                repair_reason = self._determine_repair_reason(error_msg, llm_content)
                
                # –ï—Å–ª–∏ —ç—Ç–æ –æ—à–∏–±–∫–∞ –æ–ø–∏—Å–∞–Ω–∏—è, –ø—ã—Ç–∞–µ–º—Å—è –æ—Ç—Ä–µ–º–æ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Å—Ä–∞–∑—É
                if repair_reason == "desc_too_short":
                    logger.info(f"üîß –ü–æ–ø—ã—Ç–∫–∞ —Ä–µ–º–æ–Ω—Ç–∞ –æ–ø–∏—Å–∞–Ω–∏—è –¥–ª—è {locale}")
                    try:
                        repaired_description = llm_generator.repair_description(product_data, locale)
                        llm_content['description'] = repaired_description
                        
                        # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –æ–ø–∏—Å–∞–Ω–∏—è
                        description_guard(repaired_description)
                        logger.info(f"‚úÖ –†–µ–º–æ–Ω—Ç –æ–ø–∏—Å–∞–Ω–∏—è —É—Å–ø–µ—à–µ–Ω –¥–ª—è {locale}")
                    except Exception as repair_error:
                        logger.error(f"‚ùå –†–µ–º–æ–Ω—Ç –æ–ø–∏—Å–∞–Ω–∏—è –Ω–µ —É–¥–∞–ª—Å—è –¥–ª—è {locale}: {repair_error}")
                        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å —Ä–µ–º–æ–Ω—Ç–∞
                        self._enqueue_repair(url, input_index, locale, repair_reason, llm_content, error_msg)
                        raise ve
                else:
                    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ –æ—á–µ—Ä–µ–¥—å —Ä–µ–º–æ–Ω—Ç–∞
                    self._enqueue_repair(url, input_index, locale, repair_reason, llm_content, error_msg)
                    logger.error(f"‚ùå –í–∞–ª–∏–¥–∞—Ü–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞ –¥–ª—è {locale}: {ve}")
                    raise ve
                
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –¥–ª—è {locale}: {e}")
            raise e  # –ù–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback, –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—à–∏–±–∫—É
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ñ–æ—Ä–º–∞—Ç –¥–ª—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤
        from src.processing.safe_templates import SafeTemplates
        templates = SafeTemplates()
        safe_blocks = templates.render_safe_blocks_from_llm(h1, llm_content, locale, clean_html)
        
        # –£–ª—É—á—à–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å ContentCritic –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º —Ñ–∞–∫—Ç—ã –∏ specs –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è
        facts = {
            'title': h1,
            'brand': safe_facts.get('brand', ''),
            'material': safe_facts.get('category', ''),
            'volume': safe_facts.get('pack', ''),
            'color': '',
            'purpose': ''
        }
        
        # –£–ª—É—á—à–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç —Å ContentCritic
        logger.info(f"üîß –í—ã–∑—ã–≤–∞–µ–º ContentCritic –¥–ª—è –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ {locale}")
        logger.info(f"üîß –î–æ—Å—Ç—É–ø–Ω—ã–µ –±–ª–æ–∫–∏: {list(safe_blocks.keys())}")
        
        # Heartbeat –¥–ª—è ContentCritic
        try:
            import sys
            if 'watchdog' in sys.modules:
                from scripts.universal_pipeline import watchdog
                watchdog.heartbeat("content_critic_start")
        except:
            pass
        
        enhanced_blocks = self.content_enhancer.enhance_product_with_critic(safe_blocks, locale, facts, specs)
        logger.info(f"üîß ContentCritic –≤–µ—Ä–Ω—É–ª: {list(enhanced_blocks.keys())}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        if '_quality_metrics' in enhanced_blocks:
            quality_metrics = enhanced_blocks['_quality_metrics']
            quality_score = quality_metrics.get('quality_score', 0)
            overall_status = quality_metrics.get('overall_status', 'UNKNOWN')
            logger.info(f"üìä ContentCritic –º–µ—Ç—Ä–∏–∫–∏: —Å—Ç–∞—Ç—É—Å={overall_status}, –æ—Ü–µ–Ω–∫–∞={quality_score:.2f}")
        
        # Heartbeat –¥–ª—è FAQ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
        try:
            import sys
            if 'watchdog' in sys.modules:
                from scripts.universal_pipeline import watchdog
                faq_count = len(enhanced_blocks.get('faq', []))
                watchdog.heartbeat(f"faq_generate_ok_count={faq_count}")
        except:
            pass
        
        # –û–±–Ω–æ–≤–ª—è–µ–º safe_blocks —Å —É–ª—É—á—à–µ–Ω–Ω—ã–º –∫–æ–Ω—Ç–µ–Ω—Ç–æ–º
        safe_blocks.update(enhanced_blocks)
        logger.info(f"üîß safe_blocks –æ–±–Ω–æ–≤–ª–µ–Ω: {list(safe_blocks.keys())}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–∏–∞–≥–Ω–æ—Å—Ç–∏—á–µ—Å–∫—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        enhancement_diagnostic = self.content_enhancer.get_enhancement_diagnostic(enhanced_blocks)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º –∑–∞–≥–æ–ª–æ–≤–æ–∫ –Ω–∞ —Å–º–µ—à–µ–Ω–∏–µ –ª–æ–∫–∞–ª–µ–π –∏ —Å–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        from src.validation.guards import locale_title_guard, note_buy_guard
        
        title_result = locale_title_guard(h1, locale, llm_content.get('specs', []))
        
        if not title_result['valid']:
            logger.error(f"‚ùå Title validation failed for {locale}: {title_result['issues']}")
            raise ValidationError(f"Title validation failed for {locale}: {'; '.join(title_result['issues'])}")
        
        # –ï—Å–ª–∏ –∑–∞–≥–æ–ª–æ–≤–æ–∫ –±—ã–ª —Å–∞–Ω–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω, –æ–±–Ω–æ–≤–ª—è–µ–º h1 –∏ –±–ª–æ–∫–∏
        if title_result.get('sanitized'):
            h1 = title_result['sanitized_content']
            safe_blocks['title'] = h1
            logger.info(f"‚úÖ Title sanitized for {locale}, source: {title_result['source']}")
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞
            title_sanitization_info = f"title_sanitized=true, title_source={title_result['source']}"
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º note-buy –Ω–∞ —Å–º–µ—à–µ–Ω–∏–µ –ª–æ–∫–∞–ª–µ–π –∏ —Å–∞–Ω–∏—Ç–∏–∑–∏—Ä—É–µ–º –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
        # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é note_buy –µ—Å–ª–∏ –æ–Ω –±—ã–ª —É–ª—É—á—à–µ–Ω ContentEnhancer
        if '_enhancement_diagnostic' not in safe_blocks or not safe_blocks.get('_enhancement_diagnostic', {}).get('note_buy_has_kupit_kupyty', False):
            note_buy_result = note_buy_guard(safe_blocks.get('note_buy', ''), locale, llm_content.get('specs', []), h1)
            
            if not note_buy_result['valid']:
                logger.error(f"‚ùå Note-buy validation failed for {locale}: {note_buy_result['issues']}")
                raise ValidationError(f"Note-buy validation failed for {locale}: {'; '.join(note_buy_result['issues'])}")
            
            # –ï—Å–ª–∏ note-buy –±—ã–ª —Å–∞–Ω–∏—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω, –æ–±–Ω–æ–≤–ª—è–µ–º –±–ª–æ–∫–∏
            if note_buy_result.get('sanitized'):
                safe_blocks['note_buy'] = note_buy_result['sanitized_content']
                logger.info(f"‚úÖ Note-buy sanitized for {locale}, source: {note_buy_result['source']}")
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏–∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
                note_buy_sanitization_info = f"note_buy_sanitized=true, note_buy_source={note_buy_result['source']}"
        else:
            logger.info(f"‚úÖ Note-buy –ø—Ä–æ–ø—É—â–µ–Ω –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ (—É–ª—É—á—à–µ–Ω ContentEnhancer)")
        
        # –°–æ–±–∏—Ä–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏–∏ –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        sanitization_parts = []
        if 'title_sanitization_info' in locals():
            sanitization_parts.append(title_sanitization_info)
        if 'note_buy_sanitization_info' in locals():
            sanitization_parts.append(note_buy_sanitization_info)
        
        sanitization_info = "; ".join(sanitization_parts) if sanitization_parts else ""
        
        # –û–¢–õ–ê–î–ö–ê: –ü—Ä–æ–≤–µ—Ä—è–µ–º, –¥–æ—Ö–æ–¥–∏–º –ª–∏ –º—ã –¥–æ —ç—Ç–æ–≥–æ –º–µ—Å—Ç–∞
        logger.info(f"üîß –û–¢–õ–ê–î–ö–ê: –î–æ—à–ª–∏ –¥–æ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ FAQ –¥–ª—è {locale}")
        logger.info(f"üîß –û–¢–õ–ê–î–ö–ê: safe_blocks —Å–æ–¥–µ—Ä–∂–∏—Ç: {list(safe_blocks.keys())}")
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º FAQ —á–µ—Ä–µ–∑ ContentEnhancer –ø–µ—Ä–µ–¥ —Ä–µ–Ω–¥–µ—Ä–æ–º HTML
        logger.info(f"üîß –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º FAQ –¥–ª—è {locale}")
        
        # Heartbeat –¥–ª—è FAQ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
        try:
            import sys
            if 'watchdog' in sys.modules:
                from scripts.universal_pipeline import watchdog
                watchdog.heartbeat("faq_generate_start")
        except:
            pass
        
        try:
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º FAQ —Å ContentCritic
            faq_result = self.content_enhancer.enhance_product_with_critic(safe_blocks, locale, facts, specs)
            if faq_result and 'faq' in faq_result:
                safe_blocks['faq'] = faq_result['faq']
                faq_count = len(faq_result['faq'])
                logger.info(f"‚úÖ FAQ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω: {faq_count} —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –¥–ª—è {locale}")
                
                # Heartbeat –¥–ª—è FAQ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                try:
                    import sys
                    if 'watchdog' in sys.modules:
                        from scripts.universal_pipeline import watchdog
                        watchdog.heartbeat(f"faq_generate_ok_count={faq_count}")
                except:
                    pass
            else:
                logger.warning(f"‚ö†Ô∏è FAQ –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω –¥–ª—è {locale}")
                safe_blocks['faq'] = []
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ FAQ –¥–ª—è {locale}: {e}")
            safe_blocks['faq'] = []
            
            # Heartbeat –¥–ª—è FAQ –æ—à–∏–±–∫–∏
            try:
                import sys
                if 'watchdog' in sys.modules:
                    from scripts.universal_pipeline import watchdog
                    watchdog.heartbeat(f"faq_generate_fail_{type(e).__name__}")
            except:
                pass
        
        # –†–µ–Ω–¥–µ—Ä–∏–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ —Å retry-–º–µ—Ö–∞–Ω–∏–∑–º–æ–º
        from src.processing.fragment_renderer import ProductFragmentRenderer
        fragment_renderer = ProductFragmentRenderer()
        
        # Retry-–º–µ—Ö–∞–Ω–∏–∑–º –¥–ª—è —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞
        max_retries = 3
        product_fragment = None
        
        for attempt in range(max_retries):
            try:
                logger.info(f"üîß –ü–æ–ø—ã—Ç–∫–∞ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ {attempt + 1}/{max_retries} –¥–ª—è {locale}")
                product_fragment = fragment_renderer.render_product_fragment(safe_blocks, locale)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –Ω–µ –ø–æ–ª—É—á–∏–ª–∏ –∑–∞–≥–ª—É—à–∫—É
                if 'error-message' in product_fragment:
                    logger.warning(f"‚ö†Ô∏è –ü–æ–ª—É—á–µ–Ω–∞ –∑–∞–≥–ª—É—à–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}, –ø–æ–≤—Ç–æ—Ä—è–µ–º...")
                    if attempt < max_retries - 1:
                        continue
                    else:
                        logger.error(f"‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–ª—è {locale}")
                        raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è {locale}")
                else:
                    logger.info(f"‚úÖ –†–µ–Ω–¥–µ—Ä–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1} –¥–ª—è {locale}")
                    break
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {e}")
                if attempt < max_retries - 1:
                    logger.info(f"üîÑ –ü–æ–≤—Ç–æ—Ä—è–µ–º —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥ –¥–ª—è {locale}")
                    continue
                else:
                    logger.error(f"‚ùå –í—Å–µ –ø–æ–ø—ã—Ç–∫–∏ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ –∏—Å—á–µ—Ä–ø–∞–Ω—ã –¥–ª—è {locale}")
                    raise
        
        if not product_fragment:
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–Ω—Ç –¥–ª—è {locale}")
        
        # –û—á–∏—â–∞–µ–º HTML –æ—Ç inline-—Å—Ç–∏–ª–µ–π
        clean_fragment = fragment_renderer.clean_html(product_fragment)
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º HTML-—Å—É—â–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        clean_fragment = fragment_renderer.decode_html_entities(clean_fragment)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º HTML-—Ç–µ–≥–∏
        if not fragment_renderer.validate_html_tags(clean_fragment):
            logger.warning(f"‚ö†Ô∏è HTML tags validation failed for {h1}")
        
        # –°–æ–±–∏—Ä–∞–µ–º —Ñ–ª–∞–≥–∏ –∏ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è
        flags = []
        consistency_fixes = []
        
        if volume_check.get('issues'):
            flags.extend(volume_check['issues'])
            consistency_fixes.extend(volume_check.get('fixes', []))
        
        if mass_check.get('issues'):
            flags.extend(mass_check['issues'])
            consistency_fixes.extend(mass_check.get('fixes', []))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –ø–æ –ª–æ–∫–∞–ª—è–º
        base_url = self._get_base_url(url)
        if base_url not in self.url_html_data:
            self.url_html_data[base_url] = {'ru_html': '', 'ua_html': ''}
        
        if locale == 'ru':
            self.url_html_data[base_url]['ru_html'] = clean_fragment
        else:
            self.url_html_data[base_url]['ua_html'] = clean_fragment
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Å–∞–Ω–∏—Ç–∏–∑–∞—Ü–∏–∏ note-buy –µ—Å–ª–∏ –±—ã–ª–∞
        if 'sanitization_info' in locals():
            flags.append(sanitization_info)
        
        return {
            'url': base_url,
            'locale': locale,
            'export_mode': 'full',
            'flags': flags,
            'needs_review': len(flags) > 0,
            'consistency_fixes': consistency_fixes,
            'html_length': len(clean_fragment),
            'processed': True,
            'retries': 0,
            'network_errors': 0,
            'budget_violation': False,
            'safe_facts_only': True,
            'controversial_data_removed': len(consistency_fixes) > 0,
            'safe_blocks': safe_blocks,
            'h1': h1,
            'safe_facts': safe_facts,
            'volume_consistent': volume_check.get('consistent', True),
            'enhancement_diagnostic': enhancement_diagnostic,
            'mass_consistent': mass_check.get('consistent', True),
            # –î–æ–±–∞–≤–ª—è–µ–º HTML —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –¥–ª—è conditional_exporter
            'RU_HTML': self.url_html_data[base_url]['ru_html'],
            'UA_HTML': self.url_html_data[base_url]['ua_html']
        }
    
    def _create_safe_result(self, url: str, locale: str, reason: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –Ω–µ—É—Å–ø–µ—à–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤"""
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–∞–∑–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ URL
        h1 = self._extract_h1_from_url(url)
        safe_facts = {'title': h1}
        
        # –°–æ–∑–¥–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç –¥–ª—è –Ω–µ—É—Å–ø–µ—à–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤
        from src.processing.safe_templates import SafeTemplates
        from src.processing.fragment_renderer import ProductFragmentRenderer
        
        templates = SafeTemplates()
        safe_blocks = templates.render_safe_blocks(h1, safe_facts, locale)
        
        fragment_renderer = ProductFragmentRenderer()
        product_fragment = fragment_renderer.render_product_fragment(safe_blocks, locale)
        clean_fragment = fragment_renderer.clean_html(product_fragment)
        
        # –î–µ–∫–æ–¥–∏—Ä—É–µ–º HTML-—Å—É—â–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
        clean_fragment = fragment_renderer.decode_html_entities(clean_fragment)
        
        # –í–∞–ª–∏–¥–∏—Ä—É–µ–º HTML-—Ç–µ–≥–∏
        if not fragment_renderer.validate_html_tags(clean_fragment):
            logger.warning(f"‚ö†Ô∏è HTML tags validation failed for {h1}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç –ø–æ –ª–æ–∫–∞–ª—è–º
        base_url = self._get_base_url(url)
        if base_url not in self.url_html_data:
            self.url_html_data[base_url] = {'ru_html': '', 'ua_html': ''}
        
        if locale == 'ru':
            self.url_html_data[base_url]['ru_html'] = clean_fragment
        else:
            self.url_html_data[base_url]['ua_html'] = clean_fragment
        
        return {
            'url': base_url,
            'locale': locale,
            'export_mode': 'specs_only',
            'flags': [reason],
            'needs_review': True,
            'consistency_fixes': [],
            'html_length': len(clean_fragment),
            'processed': True,
            'retries': 1,
            'network_errors': 1,
            'budget_violation': False,
            'fallback_reason': reason,
            'safe_facts_only': True,
            'controversial_data_removed': True
        }
    
    def _extract_h1(self, html: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç H1 –∏–∑ HTML (–∑–∞–≥–ª—É—à–∫–∞)"""
        import re
        match = re.search(r'<h1[^>]*>(.*?)</h1>', html, re.DOTALL | re.IGNORECASE)
        if match:
            return re.sub(r'<[^>]+>', '', match.group(1)).strip()
        return "–¢–æ–≤–∞—Ä"
    
    def _extract_h1_from_url(self, url: str) -> str:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç H1 –∏–∑ URL (–∑–∞–≥–ª—É—à–∫–∞)"""
        # –ü—Ä–æ—Å—Ç–∞—è –ª–æ–≥–∏–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏—è –∏–∑ URL
        parts = url.split('/')[-1].split('-')
        return ' '.join(parts).title()
    
    def _extract_specs(self, html: str) -> List[Dict[str, str]]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ HTML —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Å–µ–ª–µ–∫—Ç–æ—Ä–∞–º–∏"""
        from bs4 import BeautifulSoup
        import re
        
        soup = BeautifulSoup(html, 'html.parser')
        specs = []
        seen = set()
        
        # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Å–µ–ª–µ–∫—Ç–æ—Ä—ã –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫
        selectors = [
            'ul.specs li',
            'div.specs .spec-item', 
            'table.specs tr',
            'dl.specs dt, dl.specs dd',
            '.product-specs li',
            '.characteristics li',
            '.spec-list li',
            'table tr td:first-child',
            'dl dt',
            '.spec-item'
        ]
        
        for selector in selectors:
            try:
                elements = soup.select(selector)
                for element in elements:
                    label, value = self._extract_kv_from_element(element)
                    if label and value and (label, value) not in seen:
                        seen.add((label, value))
                        specs.append({'name': label, 'value': value})
            except Exception as e:
                logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –ø–æ —Å–µ–ª–µ–∫—Ç–æ—Ä—É {selector}: {e}")
                continue
        
        # –ï—Å–ª–∏ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –º–∞–ª–æ, –ø—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –∏–∑ —Ç–∞–±–ª–∏—Ü
        if len(specs) < 8:
            tables = soup.find_all('table')
            for table in tables:
                rows = table.find_all('tr')
                for row in rows:
                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 2:
                        label = cells[0].get_text(strip=True)
                        value = cells[1].get_text(strip=True)
                        if label and value and (label, value) not in seen:
                            seen.add((label, value))
                            specs.append({'name': label, 'value': value})
        
        logger.info(f"–ò–∑–≤–ª–µ—á–µ–Ω–æ {len(specs)} —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑ HTML")
        return specs[:12]  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –º–∞–∫—Å–∏–º—É–º 12 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏
    
    def _extract_kv_from_element(self, element) -> tuple:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∫–ª—é—á-–∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞"""
        try:
            # –ò—â–µ–º span —Å –ª–µ–π–±–ª–æ–º
            label_span = element.find('span')
            if label_span:
                label = label_span.get_text(strip=True).rstrip(':').strip()
                # –ü–æ–ª—É—á–∞–µ–º —Ç–µ–∫—Å—Ç –±–µ–∑ –ª–µ–π–±–ª–∞
                element_text = element.get_text(strip=True)
                value = element_text.replace(label_span.get_text(), '', 1).strip()
                return label, value
            
            # –ï—Å–ª–∏ –Ω–µ—Ç span, –∏—â–µ–º –ø–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ dt/dd
            if element.name == 'dt':
                dd = element.find_next_sibling('dd')
                if dd:
                    return element.get_text(strip=True), dd.get_text(strip=True)
            
            # –ï—Å–ª–∏ —ç—Ç–æ td –≤ —Ç–∞–±–ª–∏—Ü–µ
            if element.name == 'td':
                parent = element.parent
                if parent:
                    cells = parent.find_all(['td', 'th'])
                    if len(cells) >= 2 and element == cells[0]:
                        return element.get_text(strip=True), cells[1].get_text(strip=True)
            
            # –û–±—â–∏–π —Å–ª—É—á–∞–π - —Ä–∞–∑–±–∏–≤–∞–µ–º –ø–æ –¥–≤–æ–µ—Ç–æ—á–∏—é
            text = element.get_text(strip=True)
            if ':' in text:
                parts = text.split(':', 1)
                if len(parts) == 2:
                    return parts[0].strip(), parts[1].strip()
            
            return '', ''
            
        except Exception as e:
            logger.debug(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ KV –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞: {e}")
            return '', ''
    
    def _extract_mass_facts(self, html: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∞–∫—Ç—ã –º–∞—Å—Å—ã –∏–∑ HTML (–∑–∞–≥–ª—É—à–∫–∞)"""
        # –ó–∞–≥–ª—É—à–∫–∞ - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–º–µ–Ω–µ–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É
        return []
    
    def _extract_volume_facts(self, html: str) -> List[str]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∞–∫—Ç—ã –æ–±—ä—ë–º–∞ –∏–∑ HTML (–∑–∞–≥–ª—É—à–∫–∞)"""
        # –ó–∞–≥–ª—É—à–∫–∞ - –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å –∑–∞–º–µ–Ω–µ–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –ª–æ–≥–∏–∫—É
        return []
    
    def _get_base_url(self, url: str) -> str:
        """–ü–æ–ª—É—á–∞–µ—Ç –±–∞–∑–æ–≤—ã–π URL –±–µ–∑ –ª–æ–∫–∞–ª–∏"""
        if '/ru/' in url:
            return url.replace('/ru/', '/')
        return url
    
    def _write_final_results(self):
        """–ó–∞–ø–∏—Å—ã–≤–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å HTML –ø–æ –ª–æ–∫–∞–ª—è–º"""
        logger.info(f"üìù –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è {len(self.url_html_data)} URL")
        
        for base_url, html_data in self.url_html_data.items():
            result = {
                'url': base_url,
                'RU_HTML': html_data.get('ru_html', ''),
                'UA_HTML': html_data.get('ua_html', ''),
                'flags': [],  # –ü—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫ —Ñ–ª–∞–≥–æ–≤ –¥–ª—è –≤–∞–ª–∏–¥–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
                'needs_review': False
            }
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤ —ç–∫—Å–ø–æ—Ä—Ç
            self.conditional_exporter.add_result(result)
            logger.info(f"‚úÖ –ó–∞–ø–∏—Å–∞–Ω —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {base_url}")
    
    def _to_ru_url(self, ua_url: str) -> str:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç UA URL –≤ RU URL"""
        if '/ru/' in ua_url:
            return ua_url
        return ua_url.replace('prorazko.com/', 'prorazko.com/ru/')
    
    def _determine_repair_reason(self, error_msg: str, llm_content: Dict[str, Any]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø—Ä–∏—á–∏–Ω—É –æ—à–∏–±–∫–∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –¥–ª—è –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤ —Ä–µ–º–æ–Ω—Ç"""
        error_lower = error_msg.lower()
        
        if "description must contain at least 4 sentences" in error_lower:
            return "desc_too_short"
        elif "volume" in error_lower and ("conflict" in error_lower or "controversial" in error_lower):
            return "volume_conflict"
        elif "mass" in error_lower and ("conflict" in error_lower or "controversial" in error_lower):
            return "mass_conflict"
        elif "locale" in error_lower and ("mixing" in error_lower or "validation" in error_lower):
            return "locale_mixing"
        elif "specs" in error_lower and ("invalid" in error_lower or "validation" in error_lower):
            return "specs_invalid"
        elif "faq" in error_lower and ("invalid" in error_lower or "validation" in error_lower):
            return "faq_invalid"
        elif "placeholder" in error_lower or "anti-placeholder" in error_lower:
            return "anti_placeholders"
        elif "structure" in error_lower and ("invalid" in error_lower or "validation" in error_lower):
            return "structure_invalid"
        else:
            return "unknown"
    
    def _enqueue_repair(self, url: str, input_index: int, locale: str, reason: str, 
                       llm_content: Dict[str, Any], error_details: str) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç URL –≤ –æ—á–µ—Ä–µ–¥—å —Ä–µ–º–æ–Ω—Ç–∞"""
        from src.repair.repair_queue import RepairReason
        
        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç—Ä–æ–∫–æ–≤—É—é –ø—Ä–∏—á–∏–Ω—É –≤ enum
        try:
            repair_reason = RepairReason(reason)
        except ValueError:
            repair_reason = RepairReason.DESC_TOO_SHORT  # Fallback
        
        self.repair_queue.enqueue_repair(
            url=url,
            input_index=input_index,
            failing_locale=locale,
            reason=repair_reason,
            original_result=llm_content,
            error_details=error_details
        )
        
        logger.info(f"üîß URL –¥–æ–±–∞–≤–ª–µ–Ω –≤ –æ—á–µ—Ä–µ–¥—å —Ä–µ–º–æ–Ω—Ç–∞: {url} (–∏–Ω–¥–µ–∫—Å: {input_index}, –ª–æ–∫–∞–ª—å: {locale}, –ø—Ä–∏—á–∏–Ω–∞: {reason})")
    
    def get_repair_queue(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ—á–µ—Ä–µ–¥—å —Ä–µ–º–æ–Ω—Ç–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        return self.repair_queue
    
    async def _process_url_locale_with_index(self, url: str, locale: str, index: int) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ URL –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ª–æ–∫–∞–ª–∏ —Å –∏–Ω–¥–µ–∫—Å–æ–º –¥–ª—è —Å–∏—Å—Ç–µ–º—ã —Ä–µ–º–æ–Ω—Ç–∞"""
        try:
            logger.info(f"üîÑ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {url} ({locale}) —Å –∏–Ω–¥–µ–∫—Å–æ–º {index}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback fetcher
            from src.fetcher.fallback_fetcher import FallbackFetcher
            from src.processing.safe_facts import SafeFactsExtractor
            
            async with FallbackFetcher(timeout=15, retries=2) as fetcher:
                html = await fetcher.fetch_single(url, locale)
                
                if html:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º HTML —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ —Ñ–∞–∫—Ç–∞–º–∏
                    result = await self._process_html_safe(html, url, locale, index)
                    
                    # –û—Ç–º–µ—á–∞–µ–º –∫–∞–∫ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π
                    self.progress_tracker.mark_processed(url, locale, result)
                    
                    return {
                        'html': result.get('RU_HTML', '') if locale == 'ru' else result.get('UA_HTML', ''),
                        'flags': result.get('flags', []),
                        'needs_review': result.get('needs_review', False),
                        'export_mode': result.get('export_mode', 'unknown')
                    }
                else:
                    logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å HTML –¥–ª—è {url} ({locale})")
                    return None
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {url} ({locale}): {e}")
            return None
