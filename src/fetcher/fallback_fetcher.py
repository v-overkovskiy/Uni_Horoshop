"""
Fetcher —Å fallback –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–π URL –ø—Ä–∏ 404
"""
import asyncio
import logging
from typing import Optional
import httpx
from src.normalize.url_normalize import _fix_scheme, _fix_path_issues

logger = logging.getLogger(__name__)

class FallbackFetcher:
    """HTTP –∫–ª–∏–µ–Ω—Ç —Å fallback –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–π URL"""
    
    def __init__(self, timeout: int = 15, retries: int = 2):
        self.timeout = timeout
        self.retries = retries
        self.session = None
    
    async def __aenter__(self):
        self.session = httpx.AsyncClient(timeout=self.timeout)
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        if self.session:
            await self.session.aclose()
    
    async def fetch_with_fallback(self, raw_url: str, locale: str = 'ru') -> Optional[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç URL —Å fallback –Ω–∞ –∏—Å—Ö–æ–¥–Ω—ã–π –ø—Ä–∏ 4xx/—Ç–∞–π–º-–∞—É—Ç–µ"""
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º URL
        normalized_url = self._normalize_url(raw_url)
        
        # –õ–æ–≥–∏—Ä—É–µ–º –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—é
        if normalized_url != raw_url:
            logger.info(f"üîß URL –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω: '{raw_url}' ‚Üí '{normalized_url}'")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–µ—Ñ–∏—Å–æ–≤ (–∑–∞—â–∏—Ç–∞ –æ—Ç —Ä–µ–≥—Ä–µ—Å—Å–∏–∏)
        original_dashes = raw_url.count('-')
        normalized_dashes = normalized_url.count('-')
        
        if normalized_dashes < original_dashes:
            logger.warning(f"‚ö†Ô∏è –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —É–¥–∞–ª–∏–ª–∞ –¥–µ—Ñ–∏—Å—ã! –ò—Å—Ö–æ–¥–Ω—ã–π: {original_dashes}, –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π: {normalized_dashes}")
            logger.warning(f"   –ò—Å—Ö–æ–¥–Ω—ã–π: {raw_url}")
            logger.warning(f"   –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π: {normalized_url}")
        
        # –ü—Ä–æ–±—É–µ–º –æ–±–∞ URL (–Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π, –∑–∞—Ç–µ–º raw)
        urls_to_try = [normalized_url, raw_url]
        
        last_exception = None
        
        for attempt, url in enumerate(urls_to_try):
            try:
                logger.info(f"üîÑ –ü–æ–ø—ã—Ç–∫–∞ {attempt + 1}: {url}")
                
                # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ª–æ–∫–∞–ª–∏
                headers = self._get_locale_headers(locale)
                
                response = await self.session.get(url, headers=headers)
                
                if response.status_code == 200:
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {url} (locale: {locale})")
                    return response.text
                else:
                    logger.warning(f"‚ö†Ô∏è HTTP {response.status_code} –¥–ª—è {url}")
                    # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É URL –ø—Ä–∏ 4xx/5xx
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ {url}: {e}")
                last_exception = e
                # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ —Å–ª–µ–¥—É—é—â–µ–º—É URL –ø—Ä–∏ —Ç–∞–π–º-–∞—É—Ç–µ/—Å–µ—Ç–µ–≤—ã—Ö –æ—à–∏–±–∫–∞—Ö
        
        # –ï—Å–ª–∏ –¥–æ—à–ª–∏ —Å—é–¥–∞, –≤—Å–µ URL –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏
        if last_exception:
            logger.error(f"‚ùå –í—Å–µ URL –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏. –ü–æ—Å–ª–µ–¥–Ω—è—è –æ—à–∏–±–∫–∞: {last_exception}")
        else:
            logger.error(f"‚ùå –í—Å–µ URL –≤–µ—Ä–Ω—É–ª–∏ –Ω–µ-200 —Å—Ç–∞—Ç—É—Å")
        
        return None
    
    def _get_locale_headers(self, locale: str) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ HTTP –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ª–æ–∫–∞–ª–∏"""
        if locale == 'ua':
            return {
                'Accept-Language': 'uk,ru;q=0.3',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
        else:  # ru
            return {
                'Accept-Language': 'ru,uk;q=0.3',
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
    
    def _normalize_url(self, url: str) -> str:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è URL —Å –∂—ë—Å—Ç–∫–æ–π —Å—Ö–µ–º–æ–π"""
        # –ñ—ë—Å—Ç–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ö–µ–º—ã
        url = self._normalize_scheme_strict(url)
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ø—Ä–æ–±–ª–µ–º—ã –≤ –ø—É—Ç–∏ (–ë–ï–ó —É–¥–∞–ª–µ–Ω–∏—è –¥–µ—Ñ–∏—Å–æ–≤)
        url = _fix_path_issues(url)
        
        return url
    
    def _normalize_scheme_strict(self, url: str) -> str:
        """–ñ—ë—Å—Ç–∫–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ö–µ–º—ã - –∏—Å–ø—Ä–∞–≤–ª—è–µ—Ç htttps –∏ –ª—é–±—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã"""
        import re
        original = url
        url = url.strip()
        
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã htttps
        url = re.sub(r'^h+t+t+tps?://', 'https://', url, flags=re.I)
        
        # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ https –¥–ª—è prorazko.com
        if url.startswith("http://") and "prorazko.com" in url:
            url = "https://" + url[len("http://"):]
        
        if original != url:
            logger.info(f"üîß URL —Å—Ö–µ–º–∞ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∞: '{original}' ‚Üí '{url}'")
        
        return url
    
    async def fetch_single(self, url: str, locale: str = 'ru') -> Optional[str]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–¥–∏–Ω URL —Å fallback"""
        return await self.fetch_with_fallback(url, locale)

