"""
–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ FAQ –∏ JSON-LD
"""
import asyncio
import httpx
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime
import sys
import os
from dotenv import load_dotenv

# –ó–∞–≥—Ä—É–∂–∞–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è
load_dotenv()

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from src.core.async_product_processor import AsyncProductProcessor
from src.export.async_exporter import AsyncExporter
from src.monitoring.progress_monitor import ProgressMonitor
from src.processing.json_ld_generator import JsonLdGenerator

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# –≠–ö–°–ü–ï–†–ò–ú–ï–ù–¢–ê–õ–¨–ù–ê–Ø –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
CONCURRENT_PRODUCTS = 8   # –ê–≥—Ä–µ—Å—Å–∏–≤–Ω—ã–π –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º
LLM_CONCURRENCY = 16      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ LLM –∑–∞–ø—Ä–æ—Å–æ–≤
TIMEOUT = 45             # –£–≤–µ–ª–∏—á–µ–Ω–æ –¥–ª—è –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏
MAX_RETRIES = 2          # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–ø—ã—Ç–æ–∫ –ø—Ä–∏ –æ—à–∏–±–∫–∞—Ö

class EnhancedAsyncPipeline:
    """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –ø–∞–π–ø–ª–∞–π–Ω —Å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ FAQ"""
    
    def __init__(self):
        self.processor = AsyncProductProcessor()
        self.exporter = AsyncExporter()
        self.monitor = None  # –ë—É–¥–µ—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω –ø–æ–∑–∂–µ
        self.json_ld_gen = JsonLdGenerator()
        
        # –°–µ–º–∞—Ñ–æ—Ä—ã –¥–ª—è –∫–æ–Ω—Ç—Ä–æ–ª—è –Ω–∞–≥—Ä—É–∑–∫–∏
        self.llm_semaphore = asyncio.Semaphore(LLM_CONCURRENCY)
        self.product_semaphore = asyncio.Semaphore(CONCURRENT_PRODUCTS)
        
        self.results = []
        self.errors = []
        
    async def load_urls_from_file(self, filename: str = "urls.txt") -> List[str]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ URL –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                urls = [line.strip() for line in f if line.strip()]
            logger.info(f"üìã –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(urls)} URL –∏–∑ —Ñ–∞–π–ª–∞ {filename}")
            return urls
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ URL: {e}")
            return []
    
    async def process_product_worker(
        self,
        product_url: str,
        input_index: int,
        client: httpx.AsyncClient, 
        llm_semaphore: asyncio.Semaphore, 
        exporter: AsyncExporter,
        monitor: ProgressMonitor = None
    ) -> Optional[Dict[str, Any]]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —Ç–æ–≤–∞—Ä–∞ —Å –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ FAQ"""
        async with self.product_semaphore:
            try:
                logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É: {product_url}")
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä —á–µ—Ä–µ–∑ AsyncProductProcessor —Å –≤–∞–ª–∏–¥–∞—Ü–∏–µ–π
                write_lock = asyncio.Lock()
                result = await self.processor.process_product_with_validation(
                    product_url, 
                    client, 
                    llm_semaphore, 
                    write_lock
                )
                
                if result and result.get('status') == 'success':
                    # –î–æ–±–∞–≤–ª—è–µ–º input_index –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É
                    result['input_index'] = input_index
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º JSON-LD —Ä–∞–∑–º–µ—Ç–∫—É –¥–ª—è FAQ
                    await self._add_json_ld_to_result(result)
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                    await exporter.add_result(result)
                    
                    if monitor:
                        monitor.update_progress(1)
                    
                    logger.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω: {product_url} (index {input_index})")
                    return result
                else:
                    error_msg = result.get('error', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞') if result else '–ù–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞'
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {product_url}: {error_msg}")
                    self.errors.append({
                        'url': product_url,
                        'input_index': input_index,
                        'error': error_msg,
                        'timestamp': datetime.now().isoformat()
                    })
                    return None
                    
            except Exception as e:
                logger.error(f"‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {product_url} (index {input_index}): {e}")
                self.errors.append({
                    'url': product_url,
                    'input_index': input_index,
                    'error': str(e),
                    'timestamp': datetime.now().isoformat()
                })
                return None
    
    async def _add_json_ld_to_result(self, result: Dict[str, Any]) -> None:
        """–î–æ–±–∞–≤–ª—è–µ—Ç JSON-LD —Ä–∞–∑–º–µ—Ç–∫—É –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É"""
        try:
            # –ò–∑–≤–ª–µ–∫–∞–µ–º FAQ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            ru_faq = result.get('ru_content', {}).get('faq', [])
            ua_faq = result.get('ua_content', {}).get('faq', [])
            
            ru_title = result.get('ru_content', {}).get('title', '')
            ua_title = result.get('ua_content', {}).get('title', '')
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º JSON-LD –¥–ª—è RU
            if ru_faq and ru_title:
                ru_json_ld = self.json_ld_gen.generate_faq_schema(
                    faq_list=ru_faq,
                    product_name=ru_title,
                    locale='ru'
                )
                if ru_json_ld:
                    result['ru_json_ld'] = ru_json_ld
                    logger.info(f"‚úÖ JSON-LD –¥–æ–±–∞–≤–ª–µ–Ω –¥–ª—è RU: {len(ru_json_ld)} —Å–∏–º–≤–æ–ª–æ–≤")
            
            # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º JSON-LD –¥–ª—è UA
            if ua_faq and ua_title:
                ua_json_ld = self.json_ld_gen.generate_faq_schema(
                    faq_list=ua_faq,
                    product_name=ua_title,
                    locale='ua'
                )
                if ua_json_ld:
                    result['ua_json_ld'] = ua_json_ld
                    logger.info(f"‚úÖ JSON-LD –¥–æ–±–∞–≤–ª–µ–Ω –¥–ª—è UA: {len(ua_json_ld)} —Å–∏–º–≤–æ–ª–æ–≤")
                    
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è JSON-LD: {e}")
    
    async def process_urls(self, urls: List[str]) -> List[Dict[str, Any]]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–∏—Å–∫–∞ URL —Å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ–º"""
        logger.info(f"üöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É {len(urls)} —Ç–æ–≤–∞—Ä–æ–≤")
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –∫–æ—Ä—Ç–µ–∂–µ–π (input_index, url) –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞
        indexed_urls = [(i + 1, url) for i, url in enumerate(urls)]
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –º–æ–Ω–∏—Ç–æ—Ä —Å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º —Ç–æ–≤–∞—Ä–æ–≤
        self.monitor = ProgressMonitor(total_products=len(indexed_urls))
        
        # –°–æ–∑–¥–∞–µ–º HTTP –∫–ª–∏–µ–Ω—Ç —Å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
        timeout = httpx.Timeout(TIMEOUT, connect=10.0)
        limits = httpx.Limits(max_keepalive_connections=20, max_connections=100)
        
        async with httpx.AsyncClient(timeout=timeout, limits=limits) as client:
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏
            tasks = []
            for input_index, url in indexed_urls:
                task = asyncio.create_task(
                    self.process_product_worker(
                        product_url=url,
                        input_index=input_index,
                        client=client,
                        llm_semaphore=self.llm_semaphore,
                        exporter=self.exporter,
                        monitor=self.monitor
                    )
                )
                tasks.append(task)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            logger.info(f"‚ö° –ó–∞–ø—É—Å–∫–∞–µ–º {len(tasks)} –∑–∞–¥–∞—á –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å –∏–Ω–¥–µ–∫—Å–∞–º–∏")
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—É—Å–ø–µ—à–Ω—ã–µ + –æ—à–∏–±–æ—á–Ω—ã–µ) –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ–º input_index
            all_results = []
            successful_results = []
            
            for i, result in enumerate(results):
                input_index = indexed_urls[i][0]
                url = indexed_urls[i][1]
                
                if isinstance(result, Exception):
                    logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –≤ –∑–∞–¥–∞—á–µ {i} (index {input_index}): {result}")
                    error_data = {
                        'url': url,
                        'input_index': input_index,
                        'error': str(result),
                        'timestamp': datetime.now().isoformat(),
                        'status': 'error',
                        'ru_html': '',
                        'ua_html': '',
                        'ru_title': '',
                        'ua_title': '',
                        'ru_hero_image': '',
                        'ua_hero_image': '',
                        'processing_time': 0.0,
                        'errors': str(result),
                        'budget_stats': '',
                        'adapter_version': '2.0',
                        'hero_quality': 0.0,
                        'calls_per_locale': 0,
                        'canonical_slug': '',
                        'ru_valid': False,
                        'ua_valid': False
                    }
                    all_results.append(error_data)
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–≤–∞—Ä —Å –æ—à–∏–±–∫–æ–π –≤ —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä
                    await self.exporter.add_result(error_data)
                    self.errors.append({
                        'url': url,
                        'input_index': input_index,
                        'error': str(result),
                        'timestamp': datetime.now().isoformat()
                    })
                elif result is not None:
                    # –î–æ–±–∞–≤–ª—è–µ–º input_index –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –∏ –æ—Ç–º–µ—á–∞–µ–º –∫–∞–∫ —É—Å–ø–µ—à–Ω—ã–π
                    result['input_index'] = input_index
                    result['status'] = 'success'
                    all_results.append(result)
                    successful_results.append(result)
                else:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª—É—á–∞–π, –∫–æ–≥–¥–∞ result is None
                    logger.error(f"‚ùå –†–µ–∑—É–ª—å—Ç–∞—Ç None –¥–ª—è –∑–∞–¥–∞—á–∏ {i} (index {input_index}): {url}")
                    error_data = {
                        'url': url,
                        'input_index': input_index,
                        'error': '–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–≤–µ–Ω None',
                        'timestamp': datetime.now().isoformat(),
                        'status': 'error',
                        'ru_html': '',
                        'ua_html': '',
                        'ru_title': '',
                        'ua_title': '',
                        'ru_hero_image': '',
                        'ua_hero_image': '',
                        'processing_time': 0.0,
                        'errors': '–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–≤–µ–Ω None',
                        'budget_stats': '',
                        'adapter_version': '2.0',
                        'hero_quality': 0.0,
                        'calls_per_locale': 0,
                        'canonical_slug': '',
                        'ru_valid': False,
                        'ua_valid': False
                    }
                    all_results.append(error_data)
                    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–≤–∞—Ä —Å –æ—à–∏–±–∫–æ–π –≤ —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä
                    await self.exporter.add_result(error_data)
                    self.errors.append({
                        'url': url,
                        'input_index': input_index,
                        'error': '–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–∞–≤–µ–Ω None',
                        'timestamp': datetime.now().isoformat()
                    })
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ input_index –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ø–æ—Ä—è–¥–∫–∞
            all_results.sort(key=lambda x: x.get('input_index', 0))
            successful_results.sort(key=lambda x: x.get('input_index', 0))
            
            self.results = all_results  # –¢–µ–ø–µ—Ä—å —Ö—Ä–∞–Ω–∏–º –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(successful_results)} —É—Å–ø–µ—à–Ω—ã—Ö –∏–∑ {len(all_results)} —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤, –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø–æ input_index")
            return all_results  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –≤–∫–ª—é—á–∞—è –æ—à–∏–±–∫–∏
    
    def print_statistics(self) -> None:
        """–í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        total_processed = len(self.results)
        total_errors = len(self.errors)
        # –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –ª–æ–≥–∏–∫—É –ø–æ–¥—Å—á–µ—Ç–∞ - –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ URL —ç—Ç–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        total_urls = total_processed
        
        logger.info("=" * 60)
        logger.info("üìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò")
        logger.info("=" * 60)
        # –°—á–∏—Ç–∞–µ–º —É—Å–ø–µ—à–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (—Å —Å—Ç–∞—Ç—É—Å–æ–º 'success')
        successful_count = sum(1 for r in self.results if r.get('status') == 'success')
        error_count = sum(1 for r in self.results if r.get('status') == 'error')
        
        logger.info(f"–í—Å–µ–≥–æ URL: {total_urls}")
        logger.info(f"–£—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {successful_count}")
        logger.info(f"–û—à–∏–±–æ–∫: {error_count}")
        logger.info(f"–ü—Ä–æ—Ü–µ–Ω—Ç —É—Å–ø–µ—Ö–∞: {(successful_count/total_urls*100):.1f}%" if total_urls > 0 else "0%")
        
        if self.errors:
            logger.info("\n‚ùå –û–®–ò–ë–ö–ò:")
            for error in self.errors:
                logger.info(f"  - {error['url']}: {error['error']}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ FAQ
        total_faq_ru = sum(len(r.get('ru_content', {}).get('faq', [])) for r in self.results)
        total_faq_ua = sum(len(r.get('ua_content', {}).get('faq', [])) for r in self.results)
        logger.info(f"\nüìù FAQ –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"  RU FAQ: {total_faq_ru} –≤–æ–ø—Ä–æ—Å–æ–≤")
        logger.info(f"  UA FAQ: {total_faq_ua} –≤–æ–ø—Ä–æ—Å–æ–≤")
        logger.info(f"  –í—Å–µ–≥–æ FAQ: {total_faq_ru + total_faq_ua} –≤–æ–ø—Ä–æ—Å–æ–≤")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ JSON-LD
        json_ld_count = sum(1 for r in self.results if r.get('ru_json_ld') or r.get('ua_json_ld'))
        logger.info(f"\nüè∑Ô∏è JSON-LD –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
        logger.info(f"  –¢–æ–≤–∞—Ä–æ–≤ —Å JSON-LD: {json_ld_count}")
        logger.info(f"  –ü–æ–∫—Ä—ã—Ç–∏–µ JSON-LD: {(json_ld_count/total_processed*100):.1f}%" if total_processed > 0 else "0%")

async def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞"""
    start_time = datetime.now()
    
    # –°–æ–∑–¥–∞–µ–º –ø–∞–π–ø–ª–∞–π–Ω
    pipeline = EnhancedAsyncPipeline()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º URL
    urls = await pipeline.load_urls_from_file("urls.txt")
    if not urls:
        logger.error("‚ùå –ù–µ—Ç URL –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        return
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –í–°–ï —Ç–æ–≤–∞—Ä—ã –∏–∑ urls.txt
    test_urls = urls  # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –≤—Å–µ —Ç–æ–≤–∞—Ä—ã
    logger.info(f"üöÄ –ü–æ–ª–Ω–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞: –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º {len(test_urls)} —Ç–æ–≤–∞—Ä–æ–≤")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–≤–∞—Ä—ã
    results = await pipeline.process_urls(test_urls)
    
    # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    pipeline.print_statistics()
    
    # ‚úÖ –ù–û–í–û–ï: –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ Smart Routing
    try:
        # –ü–æ–ª—É—á–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä SmartLLMClient –∏–∑ –ª—é–±–æ–≥–æ –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞
        if hasattr(pipeline.processor, 'content_generator') and hasattr(pipeline.processor.content_generator, 'llm'):
            llm_client = pipeline.processor.content_generator.llm
            
            # –í—ã–≤–æ–¥–∏–º –¥–µ—Ç–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            llm_client.print_stats()
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ª–æ–≥-—Ñ–∞–π–ª
            stats = llm_client.get_stats()
            
            import json
            with open('llm_usage_stats.json', 'w', encoding='utf-8') as f:
                json.dump(stats, f, indent=2, ensure_ascii=False)
            
            logger.info("üìÅ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ Smart Routing —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ llm_usage_stats.json")
        else:
            logger.warning("‚ö†Ô∏è SmartLLMClient –Ω–µ –Ω–∞–π–¥–µ–Ω –¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏")
            
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–≤–µ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É Smart Routing: {e}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ Excel
    if results:
        main_file = "descriptions.xlsx"
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –≤ —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–µ –¥–ª—è –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏
        pipeline.exporter.output_file = main_file
        # –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–ø–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞–µ–º —Ñ–∞–π–ª)
        export_result = await pipeline.exporter.export_all()
        
        if export_result.get('success'):
            logger.info(f"üíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω—ã –≤ {main_file}")
        else:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {export_result.get('error', 'Unknown error')}")
    
    end_time = datetime.now()
    total_time = (end_time - start_time).total_seconds()
    logger.info(f"‚è±Ô∏è –û–±—â–µ–µ –≤—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {total_time:.2f} —Å–µ–∫—É–Ω–¥")
    logger.info(f"‚ö° –°—Ä–µ–¥–Ω—è—è —Å–∫–æ—Ä–æ—Å—Ç—å: {len(urls)/total_time:.2f} —Ç–æ–≤–∞—Ä–æ–≤/—Å–µ–∫")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–µ—Ä–≤–∞–Ω–æ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {e}")
        import traceback
        traceback.print_exc()
